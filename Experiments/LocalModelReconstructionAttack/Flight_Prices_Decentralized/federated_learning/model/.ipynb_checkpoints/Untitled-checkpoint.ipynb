{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/privacy-preserving-fl/break_model_privacy_in_fl_PhD/federated_learning/model'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/privacy-preserving-fl/break_model_privacy_in_fl_PhD\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting lime\n",
      "  Using cached lime-0.2.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.12.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.20.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.28.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.48.2\n",
      "  Using cached grpcio-1.54.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.23.5)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.38.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (65.6.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.8/site-packages (from lime) (1.2.1)\n",
      "Collecting scikit-image>=0.12\n",
      "  Using cached scikit_image-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from lime) (1.10.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from lime) (4.64.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from lime) (3.7.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.5.3)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.14)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (5.10.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (2.25.1)\n",
      "Collecting lazy_loader>=0.1\n",
      "  Using cached lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.12->lime) (3.0)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Using cached tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.13.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tifffile, tensorboard-data-server, scipy, PyWavelets, pyasn1-modules, oauthlib, lazy_loader, grpcio, cachetools, absl-py, scikit-image, requests-oauthlib, markdown, google-auth, lime, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.0\n",
      "    Uninstalling scipy-1.10.0:\n",
      "      Successfully uninstalled scipy-1.10.0\n",
      "Successfully installed PyWavelets-1.4.1 absl-py-1.4.0 cachetools-5.3.0 google-auth-2.18.1 google-auth-oauthlib-1.0.0 grpcio-1.54.2 lazy_loader-0.2 lime-0.2.0.1 markdown-3.4.3 oauthlib-3.2.2 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 scikit-image-0.20.0 scipy-1.9.1 tensorboard-2.13.0 tensorboard-data-server-0.7.0 tifffile-2023.4.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard lime seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[2023-05-19 12:06:13.873 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:144 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-19 12:06:14.008 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:144 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "/root/privacy-preserving-fl/break_model_privacy_in_fl_PhD/federated_learning/model/neural_network_regression.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=self.device)\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:-inf, test_acc:-inf\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.420674888847116, test_acc:0.42928038971475785\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.356655641369534, test_acc:0.34022368603054326\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.15368757888831602, test_acc:0.15148187266437893\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:27084.265625, test_acc:27795.91796875, Extrac_acc:106782.4609375\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:14354.1064453125, test_acc:15332.630859375, Extrac_acc:46050.90625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:118538.71875, test_acc:117082.3359375, Extrac_acc:124949.7421875\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:113287.109375, test_acc:111255.5390625, Extrac_acc:229013.28125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:56902.33203125, test_acc:63521.03515625, Extrac_acc:94171.3828125\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:57252.171875, test_acc:63945.69140625, Extrac_acc:86208.90625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:57448.08984375, test_acc:56250.13671875, Extrac_acc:89913.3515625\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:56480.34375, test_acc:55304.0, Extrac_acc:70127.78125\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96, 109, 110, 127, 139, 143, 158, 162, 171, 185, 190]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 49187479552.0 || Test loss: 4839061504.0\n",
      "Epoch: 1000 | | Train Loss: 49151172608.0 || Test loss: 4835797504.0\n",
      "Epoch: 2000 | | Train Loss: 49113808896.0 || Test loss: 4832951296.0\n",
      "Epoch: 3000 | | Train Loss: 49072197632.0 || Test loss: 4829857792.0\n",
      "Client 0 prediction: mean tensor([ 0.0309, -0.0501, -0.0173,  ...,  0.1024,  0.2122,  0.3592],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0198, 0.0778, 0.0668,  ..., 1.0420, 2.3579, 2.6514],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([-1.6034e-03, -2.5420e-02, -7.7486e-05,  ...,  5.9138e+02,\n",
      "         6.3644e+02,  1.1714e+02]), std tensor([9.8666e-03, 6.3876e-02, 3.1653e-04,  ..., 3.6266e+02, 3.5965e+02,\n",
      "        1.0454e+02])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94, 101, 114, 124, 134, 142, 156, 167, 174, 181, 191]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 78793596928.0 || Test loss: 10175936512.0\n",
      "Epoch: 1000 | | Train Loss: 78745542656.0 || Test loss: 10170646528.0\n",
      "Epoch: 2000 | | Train Loss: 78719746048.0 || Test loss: 10168182784.0\n",
      "Epoch: 3000 | | Train Loss: 78677008384.0 || Test loss: 10164059136.0\n",
      "Client 1 prediction: mean tensor([-0.0010,  0.0246,  0.0275,  ..., -0.1118, -0.0014, -0.0002],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0437, 0.0422, 0.0112,  ..., 2.5800, 2.4817, 2.4121],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([-1.0461e-03, -7.6152e-03, -3.7104e-04,  ..., -1.2193e+03,\n",
      "        -1.2136e+03, -3.4770e+02]), std tensor([2.2836e-03, 2.3434e-02, 7.1798e-04,  ..., 4.1480e+02, 4.0718e+02,\n",
      "        1.2888e+02])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96, 101, 112, 123, 131, 143, 151, 160, 178, 184, 191]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 3918513408.0 || Test loss: 309968576.0\n",
      "Epoch: 1000 | | Train Loss: 3903195136.0 || Test loss: 308883008.0\n",
      "Epoch: 2000 | | Train Loss: 3887494144.0 || Test loss: 308256960.0\n",
      "Epoch: 3000 | | Train Loss: 3869078016.0 || Test loss: 307251136.0\n",
      "Client 2 prediction: mean tensor([-0.0547, -0.0035,  0.0046,  ..., -0.1485, -0.2336, -0.0937],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0379, 0.0848, 0.0669,  ..., 2.5737, 3.9569, 2.5628],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([-1.1364e-02, -4.7584e-02, -2.8372e-03,  ..., -2.2421e+02,\n",
      "        -2.0714e+02, -1.0444e+02]), std tensor([1.3324e-02, 6.3800e-02, 4.4661e-03,  ..., 2.6997e+02, 2.7201e+02,\n",
      "        1.0100e+02])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90, 109, 115, 122, 131, 143, 157, 164, 173, 180, 198]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 7178700288.0 || Test loss: 549273600.0\n",
      "Epoch: 1000 | | Train Loss: 7161583616.0 || Test loss: 547641280.0\n",
      "Epoch: 2000 | | Train Loss: 7144284672.0 || Test loss: 546751936.0\n",
      "Epoch: 3000 | | Train Loss: 7124412416.0 || Test loss: 545491520.0\n",
      "Client 3 prediction: mean tensor([ 0.0022, -0.1115,  0.0050,  ...,  0.1849,  0.3273,  0.1328],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0450, 0.0796, 0.0197,  ..., 2.1276, 3.4120, 2.1911],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([-9.6142e-03, -2.9793e-02, -1.5587e-03,  ...,  3.1473e+01,\n",
      "         6.6259e+01, -2.5912e+01]), std tensor([1.5569e-02, 6.9349e-02, 3.3603e-03,  ..., 3.0300e+02, 3.0226e+02,\n",
      "        1.0601e+02])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:27084.27, Test accuracy:27795.92, Extraction Accuracy:106782.46\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:14354.11, Test accuracy:15332.63, Extraction Accuracy:46050.91\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:-inf, Test accuracy:-inf\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 16039.5918, Training accuracy: 14354.10, Test Accuracy: 15332.62\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 10752.2764, Training accuracy: 14348.59, Test Accuracy: 15324.00\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 7207.1123, Training accuracy: 14343.67, Test Accuracy: 15322.81\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 4831.3125, Training accuracy: 14338.69, Test Accuracy: 15321.32\n",
      "Best: Gradient norm:4831.3125\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:49071296512.00, Test loss: 4829708800.00,Training accuracy: 14338.69, Test accuracy: 15321.32, Extraction accuracy: 45771.99\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:118538.72, Test accuracy:117082.34, Extraction Accuracy:124949.74\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:113287.11, Test accuracy:111255.54, Extraction Accuracy:229013.28\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.42, Test accuracy:0.43\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 7128.8442, Training accuracy: 113287.05, Test Accuracy: 111255.48\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 4791.4634, Training accuracy: 113240.16, Test Accuracy: 111210.12\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 3218.0696, Training accuracy: 113200.05, Test Accuracy: 111171.34\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 2164.7402, Training accuracy: 113170.81, Test Accuracy: 111143.23\n",
      "Best: Gradient norm:2164.7402\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:78647918592.00, Test loss: 10160353280.00,Training accuracy: 113170.81, Test accuracy: 111143.23, Extraction accuracy: 227050.58\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:56902.33, Test accuracy:63521.04, Extraction Accuracy:94171.38\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:57252.17, Test accuracy:63945.69, Extraction Accuracy:86208.91\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.36, Test accuracy:0.34\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 2496.7139, Training accuracy: 57252.15, Test Accuracy: 63945.68\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1677.9868, Training accuracy: 57194.24, Test Accuracy: 63879.69\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1128.8224, Training accuracy: 57137.45, Test Accuracy: 63814.04\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 760.6917, Training accuracy: 57094.54, Test Accuracy: 63763.72\n",
      "Best: Gradient norm:760.6917\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:3868848128.00, Test loss: 307183712.00,Training accuracy: 57094.54, Test accuracy: 63763.72, Extraction accuracy: 88867.65\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:57448.09, Test accuracy:56250.14, Extraction Accuracy:89913.35\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:56480.34, Test accuracy:55304.00, Extraction Accuracy:70127.78\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.15, Test accuracy:0.15\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 13217.4854, Training accuracy: 56480.34, Test Accuracy: 55304.00\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 8868.7441, Training accuracy: 56480.52, Test Accuracy: 55304.24\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 5951.3027, Training accuracy: 56494.86, Test Accuracy: 55318.18\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 3997.5286, Training accuracy: 56510.23, Test Accuracy: 55333.12\n",
      "Best: Gradient norm:3997.5286\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:7124319744.00, Test loss: 545481728.00,Training accuracy: 56510.23, Test accuracy: 55333.12, Extraction accuracy: 69178.49\n",
      "rm logs/none/experiment_flightPrices_bz_128_lr_5e-05_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 4 --num_rounds 200 --bz 128 --num_local_steps 1 --device \"cpu\" --gnetwork_num_epochs 3001 --num_trials_to_decode 1 --lr 0.00005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 128 --start_point global_model --decoded_epochs 3001 --model neuralReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "[2023-05-19 12:34:47.926 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:3916 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-19 12:34:48.061 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:3916 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "/root/privacy-preserving-fl/break_model_privacy_in_fl_PhD/federated_learning/model/neural_network_regression.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=self.device)\n",
      "\t Round: 1 |Train Loss: 286336.269 | Train evalMetric: -153.49%\n",
      "\t Round: 2 |Train Loss: 278851.901 | Train evalMetric: -146.83%\n",
      "\t Round: 3 |Train Loss: 269675.810 | Train evalMetric: -137.96%\n",
      "\t Round: 4 |Train Loss: 259592.287 | Train evalMetric: -129.03%\n",
      "\t Round: 5 |Train Loss: 247102.260 | Train evalMetric: -117.55%\n",
      "\t Round: 6 |Train Loss: 231832.912 | Train evalMetric: -103.22%\n",
      "\t Round: 7 |Train Loss: 216835.193 | Train evalMetric: -88.67%\n",
      "\t Round: 8 |Train Loss: 201726.359 | Train evalMetric: -75.41%\n",
      "\t Round: 9 |Train Loss: 188056.849 | Train evalMetric: -62.42%\n",
      "\t Round: 10 |Train Loss: 178161.299 | Train evalMetric: -53.39%\n",
      "\t Round: 11 |Train Loss: 171155.606 | Train evalMetric: -46.84%\n",
      "\t Round: 12 |Train Loss: 164362.788 | Train evalMetric: -40.84%\n",
      "\t Round: 13 |Train Loss: 161125.096 | Train evalMetric: -37.93%\n",
      "\t Round: 14 |Train Loss: 161188.889 | Train evalMetric: -38.04%\n",
      "\t Round: 15 |Train Loss: 159832.141 | Train evalMetric: -36.70%\n",
      "\t Round: 16 |Train Loss: 158223.783 | Train evalMetric: -35.35%\n",
      "\t Round: 17 |Train Loss: 157515.279 | Train evalMetric: -34.76%\n",
      "\t Round: 18 |Train Loss: 158516.413 | Train evalMetric: -35.66%\n",
      "\t Round: 19 |Train Loss: 158039.464 | Train evalMetric: -35.04%\n",
      "\t Round: 20 |Train Loss: 158355.407 | Train evalMetric: -35.36%\n",
      "\t Round: 21 |Train Loss: 159643.590 | Train evalMetric: -36.59%\n",
      "\t Round: 22 |Train Loss: 157805.772 | Train evalMetric: -35.13%\n",
      "\t Round: 23 |Train Loss: 157167.531 | Train evalMetric: -34.35%\n",
      "\t Round: 24 |Train Loss: 158671.556 | Train evalMetric: -35.64%\n",
      "\t Round: 25 |Train Loss: 156226.749 | Train evalMetric: -33.49%\n",
      "\t Round: 26 |Train Loss: 154336.585 | Train evalMetric: -31.79%\n",
      "\t Round: 27 |Train Loss: 156070.069 | Train evalMetric: -33.37%\n",
      "\t Round: 28 |Train Loss: 157271.407 | Train evalMetric: -34.41%\n",
      "\t Round: 29 |Train Loss: 156063.042 | Train evalMetric: -33.43%\n",
      "\t Round: 30 |Train Loss: 154820.891 | Train evalMetric: -32.25%\n",
      "\t Round: 31 |Train Loss: 155305.558 | Train evalMetric: -32.89%\n",
      "\t Round: 32 |Train Loss: 155024.385 | Train evalMetric: -32.32%\n",
      "\t Round: 33 |Train Loss: 155336.086 | Train evalMetric: -32.68%\n",
      "\t Round: 34 |Train Loss: 156399.335 | Train evalMetric: -33.51%\n",
      "\t Round: 35 |Train Loss: 156206.861 | Train evalMetric: -33.37%\n",
      "\t Round: 36 |Train Loss: 154746.289 | Train evalMetric: -32.16%\n",
      "\t Round: 37 |Train Loss: 155476.716 | Train evalMetric: -32.82%\n",
      "\t Round: 38 |Train Loss: 155231.225 | Train evalMetric: -32.49%\n",
      "\t Round: 39 |Train Loss: 152752.289 | Train evalMetric: -30.14%\n",
      "\t Round: 40 |Train Loss: 153913.038 | Train evalMetric: -31.32%\n",
      "\t Round: 41 |Train Loss: 154383.644 | Train evalMetric: -31.79%\n",
      "\t Round: 42 |Train Loss: 153300.218 | Train evalMetric: -30.83%\n",
      "\t Round: 43 |Train Loss: 155190.711 | Train evalMetric: -32.48%\n",
      "\t Round: 44 |Train Loss: 153519.193 | Train evalMetric: -31.00%\n",
      "\t Round: 45 |Train Loss: 152434.026 | Train evalMetric: -30.18%\n",
      "\t Round: 46 |Train Loss: 152087.326 | Train evalMetric: -29.73%\n",
      "\t Round: 47 |Train Loss: 153167.665 | Train evalMetric: -30.62%\n",
      "\t Round: 48 |Train Loss: 151934.632 | Train evalMetric: -29.68%\n",
      "\t Round: 49 |Train Loss: 151920.979 | Train evalMetric: -29.47%\n",
      "\t Round: 50 |Train Loss: 150781.725 | Train evalMetric: -28.63%\n",
      "\t Round: 51 |Train Loss: 153276.785 | Train evalMetric: -30.70%\n",
      "\t Round: 52 |Train Loss: 151769.489 | Train evalMetric: -29.44%\n",
      "\t Round: 53 |Train Loss: 154567.267 | Train evalMetric: -31.77%\n",
      "\t Round: 54 |Train Loss: 151653.479 | Train evalMetric: -29.22%\n",
      "\t Round: 55 |Train Loss: 152823.678 | Train evalMetric: -30.45%\n",
      "\t Round: 56 |Train Loss: 152414.616 | Train evalMetric: -30.08%\n",
      "\t Round: 57 |Train Loss: 151804.421 | Train evalMetric: -29.53%\n",
      "\t Round: 58 |Train Loss: 152439.386 | Train evalMetric: -29.97%\n",
      "\t Round: 59 |Train Loss: 151612.322 | Train evalMetric: -29.23%\n",
      "\t Round: 60 |Train Loss: 151254.123 | Train evalMetric: -29.05%\n",
      "\t Round: 61 |Train Loss: 149619.682 | Train evalMetric: -27.46%\n",
      "\t Round: 62 |Train Loss: 148246.253 | Train evalMetric: -26.24%\n",
      "\t Round: 63 |Train Loss: 148039.234 | Train evalMetric: -26.00%\n",
      "\t Round: 64 |Train Loss: 147120.744 | Train evalMetric: -25.23%\n",
      "\t Round: 65 |Train Loss: 148227.327 | Train evalMetric: -26.15%\n",
      "\t Round: 66 |Train Loss: 150163.606 | Train evalMetric: -27.87%\n",
      "\t Round: 67 |Train Loss: 147640.512 | Train evalMetric: -25.76%\n",
      "\t Round: 68 |Train Loss: 148130.172 | Train evalMetric: -26.04%\n",
      "\t Round: 69 |Train Loss: 149174.462 | Train evalMetric: -27.00%\n",
      "\t Round: 70 |Train Loss: 148080.854 | Train evalMetric: -26.13%\n",
      "\t Round: 71 |Train Loss: 147190.147 | Train evalMetric: -25.39%\n",
      "\t Round: 72 |Train Loss: 147526.449 | Train evalMetric: -25.53%\n",
      "\t Round: 73 |Train Loss: 146248.560 | Train evalMetric: -24.42%\n",
      "\t Round: 74 |Train Loss: 146980.075 | Train evalMetric: -25.06%\n",
      "\t Round: 75 |Train Loss: 147415.017 | Train evalMetric: -25.41%\n",
      "\t Round: 76 |Train Loss: 145645.336 | Train evalMetric: -23.83%\n",
      "\t Round: 77 |Train Loss: 146560.514 | Train evalMetric: -24.53%\n",
      "\t Round: 78 |Train Loss: 145209.946 | Train evalMetric: -23.40%\n",
      "\t Round: 79 |Train Loss: 145196.744 | Train evalMetric: -23.41%\n",
      "\t Round: 80 |Train Loss: 145196.554 | Train evalMetric: -23.33%\n",
      "\t Round: 81 |Train Loss: 144818.610 | Train evalMetric: -23.02%\n",
      "\t Round: 82 |Train Loss: 145746.587 | Train evalMetric: -23.91%\n",
      "\t Round: 83 |Train Loss: 144081.928 | Train evalMetric: -22.34%\n",
      "\t Round: 84 |Train Loss: 143123.741 | Train evalMetric: -21.51%\n",
      "\t Round: 85 |Train Loss: 143199.516 | Train evalMetric: -21.64%\n",
      "\t Round: 86 |Train Loss: 143827.407 | Train evalMetric: -22.13%\n",
      "\t Round: 87 |Train Loss: 143752.362 | Train evalMetric: -22.03%\n",
      "\t Round: 88 |Train Loss: 143651.918 | Train evalMetric: -22.02%\n",
      "\t Round: 89 |Train Loss: 144182.464 | Train evalMetric: -22.49%\n",
      "\t Round: 90 |Train Loss: 142422.282 | Train evalMetric: -20.90%\n",
      "\t Round: 91 |Train Loss: 141595.006 | Train evalMetric: -20.06%\n",
      "\t Round: 92 |Train Loss: 141300.226 | Train evalMetric: -19.91%\n",
      "\t Round: 93 |Train Loss: 141877.983 | Train evalMetric: -20.25%\n",
      "\t Round: 94 |Train Loss: 138557.301 | Train evalMetric: -17.46%\n",
      "\t Round: 95 |Train Loss: 139378.126 | Train evalMetric: -18.07%\n",
      "\t Round: 96 |Train Loss: 139375.873 | Train evalMetric: -18.02%\n",
      "\t Round: 97 |Train Loss: 137756.351 | Train evalMetric: -16.71%\n",
      "\t Round: 98 |Train Loss: 139600.138 | Train evalMetric: -18.31%\n",
      "\t Round: 99 |Train Loss: 138385.311 | Train evalMetric: -17.20%\n",
      "\t Round: 100 |Train Loss: 139357.947 | Train evalMetric: -18.06%\n",
      "\t Round: 101 |Train Loss: 138962.446 | Train evalMetric: -17.64%\n",
      "\t Round: 102 |Train Loss: 137649.217 | Train evalMetric: -16.59%\n",
      "\t Round: 103 |Train Loss: 136600.349 | Train evalMetric: -15.51%\n",
      "\t Round: 104 |Train Loss: 135295.712 | Train evalMetric: -14.45%\n",
      "\t Round: 105 |Train Loss: 135968.177 | Train evalMetric: -14.94%\n",
      "\t Round: 106 |Train Loss: 135356.115 | Train evalMetric: -14.45%\n",
      "\t Round: 107 |Train Loss: 134436.162 | Train evalMetric: -13.66%\n",
      "\t Round: 108 |Train Loss: 134766.801 | Train evalMetric: -13.92%\n",
      "\t Round: 109 |Train Loss: 135877.854 | Train evalMetric: -14.95%\n",
      "\t Round: 110 |Train Loss: 134088.829 | Train evalMetric: -13.31%\n",
      "\t Round: 111 |Train Loss: 133786.422 | Train evalMetric: -13.03%\n",
      "\t Round: 112 |Train Loss: 133057.823 | Train evalMetric: -12.34%\n",
      "\t Round: 113 |Train Loss: 133969.861 | Train evalMetric: -13.18%\n",
      "\t Round: 114 |Train Loss: 133692.129 | Train evalMetric: -12.93%\n",
      "\t Round: 115 |Train Loss: 132025.690 | Train evalMetric: -11.42%\n",
      "\t Round: 116 |Train Loss: 132171.230 | Train evalMetric: -11.52%\n",
      "\t Round: 117 |Train Loss: 130060.301 | Train evalMetric: -9.65%\n",
      "\t Round: 118 |Train Loss: 129674.809 | Train evalMetric: -9.37%\n",
      "\t Round: 119 |Train Loss: 130899.073 | Train evalMetric: -10.31%\n",
      "\t Round: 120 |Train Loss: 128347.638 | Train evalMetric: -8.12%\n",
      "\t Round: 121 |Train Loss: 130126.646 | Train evalMetric: -9.69%\n",
      "\t Round: 122 |Train Loss: 130363.644 | Train evalMetric: -9.85%\n",
      "\t Round: 123 |Train Loss: 131592.568 | Train evalMetric: -10.90%\n",
      "\t Round: 124 |Train Loss: 131454.393 | Train evalMetric: -10.80%\n",
      "\t Round: 125 |Train Loss: 129676.735 | Train evalMetric: -9.23%\n",
      "\t Round: 126 |Train Loss: 129672.877 | Train evalMetric: -9.14%\n",
      "\t Round: 127 |Train Loss: 128581.225 | Train evalMetric: -8.23%\n",
      "\t Round: 128 |Train Loss: 127841.120 | Train evalMetric: -7.62%\n",
      "\t Round: 129 |Train Loss: 128584.168 | Train evalMetric: -8.23%\n",
      "\t Round: 130 |Train Loss: 124774.369 | Train evalMetric: -4.92%\n",
      "\t Round: 131 |Train Loss: 125948.773 | Train evalMetric: -5.90%\n",
      "\t Round: 132 |Train Loss: 124518.079 | Train evalMetric: -4.64%\n",
      "\t Round: 133 |Train Loss: 124783.860 | Train evalMetric: -4.81%\n",
      "\t Round: 134 |Train Loss: 122753.411 | Train evalMetric: -3.09%\n",
      "\t Round: 135 |Train Loss: 122405.443 | Train evalMetric: -2.77%\n",
      "\t Round: 136 |Train Loss: 121417.141 | Train evalMetric: -1.89%\n",
      "\t Round: 137 |Train Loss: 124863.879 | Train evalMetric: -4.83%\n",
      "\t Round: 138 |Train Loss: 123956.916 | Train evalMetric: -4.04%\n",
      "\t Round: 139 |Train Loss: 125311.112 | Train evalMetric: -5.27%\n",
      "\t Round: 140 |Train Loss: 124982.695 | Train evalMetric: -4.93%\n",
      "\t Round: 141 |Train Loss: 122449.318 | Train evalMetric: -2.69%\n",
      "\t Round: 142 |Train Loss: 121685.220 | Train evalMetric: -2.02%\n",
      "\t Round: 143 |Train Loss: 122020.763 | Train evalMetric: -2.29%\n",
      "\t Round: 144 |Train Loss: 120652.942 | Train evalMetric: -1.09%\n",
      "\t Round: 145 |Train Loss: 121141.676 | Train evalMetric: -1.52%\n",
      "\t Round: 146 |Train Loss: 121208.981 | Train evalMetric: -1.52%\n",
      "\t Round: 147 |Train Loss: 118936.600 | Train evalMetric: 0.46%\n",
      "\t Round: 148 |Train Loss: 118121.470 | Train evalMetric: 1.17%\n",
      "\t Round: 149 |Train Loss: 121334.544 | Train evalMetric: -1.65%\n",
      "\t Round: 150 |Train Loss: 121956.946 | Train evalMetric: -2.18%\n",
      "\t Round: 151 |Train Loss: 118150.559 | Train evalMetric: 1.18%\n",
      "\t Round: 152 |Train Loss: 116735.164 | Train evalMetric: 2.46%\n",
      "\t Round: 153 |Train Loss: 116692.059 | Train evalMetric: 2.41%\n",
      "\t Round: 154 |Train Loss: 117132.937 | Train evalMetric: 2.14%\n",
      "\t Round: 155 |Train Loss: 116505.244 | Train evalMetric: 2.67%\n",
      "\t Round: 156 |Train Loss: 116935.511 | Train evalMetric: 2.31%\n",
      "\t Round: 157 |Train Loss: 117353.561 | Train evalMetric: 1.90%\n",
      "\t Round: 158 |Train Loss: 112711.302 | Train evalMetric: 6.01%\n",
      "\t Round: 159 |Train Loss: 115003.310 | Train evalMetric: 3.99%\n",
      "\t Round: 160 |Train Loss: 113756.316 | Train evalMetric: 5.09%\n",
      "\t Round: 161 |Train Loss: 114972.326 | Train evalMetric: 4.03%\n",
      "\t Round: 162 |Train Loss: 111993.017 | Train evalMetric: 6.70%\n",
      "\t Round: 163 |Train Loss: 113080.900 | Train evalMetric: 5.71%\n",
      "\t Round: 164 |Train Loss: 114551.299 | Train evalMetric: 4.35%\n",
      "\t Round: 165 |Train Loss: 111394.453 | Train evalMetric: 7.18%\n",
      "\t Round: 166 |Train Loss: 114246.204 | Train evalMetric: 4.75%\n",
      "\t Round: 167 |Train Loss: 108638.980 | Train evalMetric: 9.56%\n",
      "\t Round: 168 |Train Loss: 111758.133 | Train evalMetric: 6.92%\n",
      "\t Round: 169 |Train Loss: 112404.730 | Train evalMetric: 6.35%\n",
      "\t Round: 170 |Train Loss: 105337.258 | Train evalMetric: 12.37%\n",
      "\t Round: 171 |Train Loss: 116660.501 | Train evalMetric: 2.60%\n",
      "\t Round: 172 |Train Loss: 110420.834 | Train evalMetric: 8.09%\n",
      "\t Round: 173 |Train Loss: 113350.729 | Train evalMetric: 5.52%\n",
      "\t Round: 174 |Train Loss: 111575.903 | Train evalMetric: 7.06%\n",
      "\t Round: 175 |Train Loss: 104594.846 | Train evalMetric: 13.13%\n",
      "\t Round: 176 |Train Loss: 109500.438 | Train evalMetric: 8.98%\n",
      "\t Round: 177 |Train Loss: 107174.125 | Train evalMetric: 10.94%\n",
      "\t Round: 178 |Train Loss: 108369.720 | Train evalMetric: 9.96%\n",
      "\t Round: 179 |Train Loss: 104721.008 | Train evalMetric: 13.02%\n",
      "\t Round: 180 |Train Loss: 106153.919 | Train evalMetric: 11.90%\n",
      "\t Round: 181 |Train Loss: 105934.621 | Train evalMetric: 12.05%\n",
      "\t Round: 182 |Train Loss: 109102.838 | Train evalMetric: 9.28%\n",
      "\t Round: 183 |Train Loss: 103402.519 | Train evalMetric: 14.29%\n",
      "\t Round: 184 |Train Loss: 106401.956 | Train evalMetric: 11.76%\n",
      "\t Round: 185 |Train Loss: 108321.910 | Train evalMetric: 10.01%\n",
      "\t Round: 186 |Train Loss: 104399.123 | Train evalMetric: 13.40%\n",
      "\t Round: 187 |Train Loss: 107531.056 | Train evalMetric: 10.73%\n",
      "\t Round: 188 |Train Loss: 104437.122 | Train evalMetric: 13.43%\n",
      "\t Round: 189 |Train Loss: 105445.428 | Train evalMetric: 12.54%\n",
      "\t Round: 190 |Train Loss: 105409.623 | Train evalMetric: 12.54%\n",
      "\t Round: 191 |Train Loss: 101888.290 | Train evalMetric: 15.60%\n",
      "\t Round: 192 |Train Loss: 104483.678 | Train evalMetric: 13.40%\n",
      "\t Round: 193 |Train Loss: 103997.295 | Train evalMetric: 13.82%\n",
      "\t Round: 194 |Train Loss: 106200.603 | Train evalMetric: 11.92%\n",
      "\t Round: 195 |Train Loss: 101396.368 | Train evalMetric: 16.05%\n",
      "\t Round: 196 |Train Loss: 105207.107 | Train evalMetric: 12.74%\n",
      "\t Round: 197 |Train Loss: 102599.175 | Train evalMetric: 15.09%\n",
      "\t Round: 198 |Train Loss: 99247.299 | Train evalMetric: 17.96%\n",
      "\t Round: 199 |Train Loss: 100544.102 | Train evalMetric: 16.74%\n",
      "\t Round: 200 |Train Loss: 102959.257 | Train evalMetric: 14.75%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_128_lr_5e-05_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_128_lr_5e-05_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_128_lr_5e-05_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_128_lr_5e-05_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:-inf, test_acc:-inf\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.420674888847116, test_acc:0.42928038971475785\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.356655641369534, test_acc:0.34022368603054326\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.15368757888831602, test_acc:0.15148187266437893\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:27084.265625, test_acc:27795.91796875, Extrac_acc:106782.4609375\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:14354.1044921875, test_acc:15332.6298828125, Extrac_acc:46050.90625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:118538.71875, test_acc:117082.3359375, Extrac_acc:124949.75\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:113287.109375, test_acc:111255.5234375, Extrac_acc:229013.28125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:56902.32421875, test_acc:63521.03125, Extrac_acc:94171.3828125\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:57252.171875, test_acc:63945.6953125, Extrac_acc:86208.90625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:57448.08984375, test_acc:56250.13671875, Extrac_acc:89913.3359375\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:56480.34375, test_acc:55304.0, Extrac_acc:70127.78125\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96, 109, 110, 127, 139, 143, 158, 162, 171, 185, 190]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 49184878592.0 || Test loss: 4838794240.0\n",
      "Epoch: 1000 | | Train Loss: 30026280960.0 || Test loss: 3028171264.0\n",
      "Epoch: 2000 | | Train Loss: 9733312512.0 || Test loss: 1006867968.0\n",
      "Epoch: 3000 | | Train Loss: 2911445248.0 || Test loss: 268141152.0\n",
      "Client 0 prediction: mean tensor([ -1.3550,   1.6533,   1.1976,  ..., 636.5802, 675.9254, 123.4772],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.2792e-01, 2.5780e-01, 1.2849e-01,  ..., 2.4206e+02, 2.4124e+02,\n",
      "        9.2136e+01], grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([-1.6034e-03, -2.5420e-02, -7.7486e-05,  ...,  5.9138e+02,\n",
      "         6.3644e+02,  1.1714e+02]), std tensor([9.8666e-03, 6.3876e-02, 3.1653e-04,  ..., 3.6266e+02, 3.5965e+02,\n",
      "        1.0454e+02])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94, 101, 114, 124, 134, 142, 156, 167, 174, 181, 191]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 78793080832.0 || Test loss: 10175882240.0\n",
      "Epoch: 1000 | | Train Loss: 48691453952.0 || Test loss: 6670729216.0\n",
      "Epoch: 2000 | | Train Loss: 19931893760.0 || Test loss: 3077256192.0\n",
      "Epoch: 3000 | | Train Loss: 10040780800.0 || Test loss: 1718098816.0\n",
      "Client 1 prediction: mean tensor([-4.6177e-02, -3.3554e-02,  1.2619e-01,  ..., -1.1183e+03,\n",
      "        -1.1244e+03, -3.7276e+02], grad_fn=<StdMeanBackward0>), std tensor([3.9016e-02, 1.2613e-02, 1.1340e-01,  ..., 1.1340e+02, 1.1026e+02,\n",
      "        8.1014e+01], grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([-1.0461e-03, -7.6152e-03, -3.7104e-04,  ..., -1.2193e+03,\n",
      "        -1.2136e+03, -3.4770e+02]), std tensor([2.2836e-03, 2.3434e-02, 7.1798e-04,  ..., 4.1480e+02, 4.0718e+02,\n",
      "        1.2888e+02])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96, 101, 112, 123, 131, 143, 151, 160, 178, 184, 191]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 3918608640.0 || Test loss: 309982880.0\n",
      "Epoch: 1000 | | Train Loss: 1741631488.0 || Test loss: 129809528.0\n",
      "Epoch: 2000 | | Train Loss: 1377778176.0 || Test loss: 121239568.0\n",
      "Epoch: 3000 | | Train Loss: 1580568064.0 || Test loss: 168335456.0\n",
      "Client 2 prediction: mean tensor([ 5.6604e-02,  2.6689e-01,  1.7626e-01,  ..., -1.5355e+02,\n",
      "        -1.3687e+02, -8.5424e+01], grad_fn=<StdMeanBackward0>), std tensor([1.0938e-01, 1.7386e-01, 6.1045e-02,  ..., 2.2701e+02, 2.2650e+02,\n",
      "        8.9690e+01], grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([-1.1364e-02, -4.7584e-02, -2.8372e-03,  ..., -2.2421e+02,\n",
      "        -2.0714e+02, -1.0444e+02]), std tensor([1.3324e-02, 6.3800e-02, 4.4661e-03,  ..., 2.6997e+02, 2.7201e+02,\n",
      "        1.0100e+02])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90, 109, 115, 122, 131, 143, 157, 164, 173, 180, 198]\n",
      "2561 128 torch.Size([180, 2561]) torch.Size([180, 2561]) torch.Size([20, 2561]) torch.Size([20, 2561])\n",
      "Epoch: 0 | | Train Loss: 7178141696.0 || Test loss: 549221888.0\n",
      "Epoch: 1000 | | Train Loss: 3442692096.0 || Test loss: 251929536.0\n",
      "Epoch: 2000 | | Train Loss: 2717372160.0 || Test loss: 240861776.0\n",
      "Epoch: 3000 | | Train Loss: 2559273728.0 || Test loss: 246571968.0\n",
      "Client 3 prediction: mean tensor([ -0.1582,   0.0463,   0.4818,  ...,  10.1969,  40.3275, -45.6876],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.4093e-01, 8.4807e-02, 3.4114e-02,  ..., 2.4134e+02, 2.3919e+02,\n",
      "        9.0994e+01], grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([-9.6142e-03, -2.9793e-02, -1.5587e-03,  ...,  3.1473e+01,\n",
      "         6.6259e+01, -2.5912e+01]), std tensor([1.5569e-02, 6.9349e-02, 3.3603e-03,  ..., 3.0300e+02, 3.0226e+02,\n",
      "        1.0601e+02])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:27084.27, Test accuracy:27795.92, Extraction Accuracy:106782.46\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:14354.10, Test accuracy:15332.63, Extraction Accuracy:46050.91\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:-inf, Test accuracy:-inf\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 9115115.0000, Training accuracy: 14354.08, Test Accuracy: 15332.59\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 570455.4375, Training accuracy: 12713.73, Test Accuracy: 13536.20\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 569208.5000, Training accuracy: 12620.30, Test Accuracy: 13417.98\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 568723.6250, Training accuracy: 12615.86, Test Accuracy: 13400.89\n",
      "Best: Gradient norm:568723.6250\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:2343832064.00, Test loss: 278237664.00,Training accuracy: 12615.86, Test accuracy: 13400.89, Extraction accuracy: 50376.59\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:118538.72, Test accuracy:117082.34, Extraction Accuracy:124949.75\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:113287.11, Test accuracy:111255.52, Extraction Accuracy:229013.28\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.42, Test accuracy:0.43\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 19462862.0000, Training accuracy: 113287.19, Test Accuracy: 111255.60\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1172465.0000, Training accuracy: 206247.75, Test Accuracy: 207196.34\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1126971.3750, Training accuracy: 303272.94, Test Accuracy: 307388.53\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 1116898.5000, Training accuracy: 320939.28, Test Accuracy: 325668.25\n",
      "Best: Gradient norm:1116840.8750\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:8722945024.00, Test loss: 1442654976.00,Training accuracy: 320939.28, Test accuracy: 325668.25, Extraction accuracy: 750949.62\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:56902.32, Test accuracy:63521.03, Extraction Accuracy:94171.38\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:57252.17, Test accuracy:63945.70, Extraction Accuracy:86208.91\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.36, Test accuracy:0.34\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 16963478.0000, Training accuracy: 57252.05, Test Accuracy: 63945.55\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 23147.0488, Training accuracy: 56979.77, Test Accuracy: 63517.60\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 22700.5840, Training accuracy: 56975.58, Test Accuracy: 63519.39\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 22605.3223, Training accuracy: 56973.38, Test Accuracy: 63519.87\n",
      "Best: Gradient norm:22605.3223\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:1245434880.00, Test loss: 104965184.00,Training accuracy: 56973.38, Test accuracy: 63519.87, Extraction accuracy: 101514.95\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:57448.09, Test accuracy:56250.14, Extraction Accuracy:89913.34\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:56480.34, Test accuracy:55304.00, Extraction Accuracy:70127.78\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.15, Test accuracy:0.15\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 2561])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 16221357.0000, Training accuracy: 56480.32, Test Accuracy: 55303.98\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 292189.2500, Training accuracy: 56018.52, Test Accuracy: 54838.90\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 289116.2188, Training accuracy: 55865.93, Test Accuracy: 54688.59\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 286486.0625, Training accuracy: 55785.46, Test Accuracy: 54608.58\n",
      "Best: Gradient norm:286486.0625\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:2425418496.00, Test loss: 232539904.00,Training accuracy: 55785.46, Test accuracy: 54608.58, Extraction accuracy: 65316.29\n",
      "rm logs/none/experiment_flightPrices_bz_128_lr_5e-05_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 4 --num_rounds 200 --bz 128 --num_local_steps 1 --device \"cpu\" --gnetwork_num_epochs 3001 --num_trials_to_decode 1 --lr 0.00005 --adv_lr 0.001 --sigma 0.1 --gnetwork_features 128 --start_point global_model --decoded_epochs 3001 --model neuralReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-19 14:52:29.793 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:8852 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-19 14:52:29.928 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:8852 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\t Round: 1 |Train Loss: 198768.478 | Train evalMetric: -67.65%\n",
      "\t Round: 2 |Train Loss: 125997.367 | Train evalMetric: -5.48%\n",
      "\t Round: 3 |Train Loss: 86130.991 | Train evalMetric: 28.02%\n",
      "\t Round: 4 |Train Loss: 119141.846 | Train evalMetric: 0.27%\n",
      "\t Round: 5 |Train Loss: 108419.689 | Train evalMetric: 9.39%\n",
      "\t Round: 6 |Train Loss: 172196.706 | Train evalMetric: -45.16%\n",
      "\t Round: 7 |Train Loss: 96998.570 | Train evalMetric: 19.03%\n",
      "\t Round: 8 |Train Loss: 103091.861 | Train evalMetric: 13.82%\n",
      "\t Round: 9 |Train Loss: 83484.475 | Train evalMetric: 30.30%\n",
      "\t Round: 10 |Train Loss: 178946.337 | Train evalMetric: -51.09%\n",
      "\t Round: 11 |Train Loss: 183935.433 | Train evalMetric: -55.36%\n",
      "\t Round: 12 |Train Loss: 73449.635 | Train evalMetric: 38.87%\n",
      "\t Round: 13 |Train Loss: 114289.078 | Train evalMetric: 4.15%\n",
      "\t Round: 14 |Train Loss: 100107.068 | Train evalMetric: 16.25%\n",
      "\t Round: 15 |Train Loss: 72107.687 | Train evalMetric: 40.05%\n",
      "\t Round: 16 |Train Loss: 105468.177 | Train evalMetric: 11.55%\n",
      "\t Round: 17 |Train Loss: 157270.535 | Train evalMetric: -32.62%\n",
      "\t Round: 18 |Train Loss: 102695.694 | Train evalMetric: 13.99%\n",
      "\t Round: 19 |Train Loss: 156254.302 | Train evalMetric: -31.59%\n",
      "\t Round: 20 |Train Loss: 59538.125 | Train evalMetric: 50.68%\n",
      "\t Round: 21 |Train Loss: 84055.826 | Train evalMetric: 29.86%\n",
      "\t Round: 22 |Train Loss: 58129.854 | Train evalMetric: 51.70%\n",
      "\t Round: 23 |Train Loss: 104821.587 | Train evalMetric: 12.25%\n",
      "\t Round: 24 |Train Loss: 86931.504 | Train evalMetric: 27.45%\n",
      "\t Round: 25 |Train Loss: 65704.615 | Train evalMetric: 45.31%\n",
      "\t Round: 26 |Train Loss: 98779.801 | Train evalMetric: 17.28%\n",
      "\t Round: 27 |Train Loss: 134045.684 | Train evalMetric: -12.75%\n",
      "\t Round: 28 |Train Loss: 113440.330 | Train evalMetric: 4.74%\n",
      "\t Round: 29 |Train Loss: 96349.537 | Train evalMetric: 19.45%\n",
      "\t Round: 30 |Train Loss: 61762.491 | Train evalMetric: 48.74%\n",
      "\t Round: 31 |Train Loss: 61455.465 | Train evalMetric: 48.95%\n",
      "\t Round: 32 |Train Loss: 75968.070 | Train evalMetric: 36.73%\n",
      "\t Round: 33 |Train Loss: 78607.442 | Train evalMetric: 34.50%\n",
      "\t Round: 34 |Train Loss: 114553.241 | Train evalMetric: 3.85%\n",
      "\t Round: 35 |Train Loss: 70861.737 | Train evalMetric: 40.95%\n",
      "\t Round: 36 |Train Loss: 56795.579 | Train evalMetric: 52.80%\n",
      "\t Round: 37 |Train Loss: 77358.042 | Train evalMetric: 35.44%\n",
      "\t Round: 38 |Train Loss: 80477.200 | Train evalMetric: 32.82%\n",
      "\t Round: 39 |Train Loss: 50855.469 | Train evalMetric: 57.87%\n",
      "\t Round: 40 |Train Loss: 63417.681 | Train evalMetric: 47.17%\n",
      "\t Round: 41 |Train Loss: 56803.448 | Train evalMetric: 52.89%\n",
      "\t Round: 42 |Train Loss: 52717.054 | Train evalMetric: 56.22%\n",
      "\t Round: 43 |Train Loss: 63031.326 | Train evalMetric: 47.63%\n",
      "\t Round: 44 |Train Loss: 47143.013 | Train evalMetric: 60.83%\n",
      "\t Round: 45 |Train Loss: 68999.633 | Train evalMetric: 42.51%\n",
      "\t Round: 46 |Train Loss: 100555.383 | Train evalMetric: 15.74%\n",
      "\t Round: 47 |Train Loss: 62269.005 | Train evalMetric: 48.22%\n",
      "\t Round: 48 |Train Loss: 48041.632 | Train evalMetric: 60.13%\n",
      "\t Round: 49 |Train Loss: 65301.980 | Train evalMetric: 45.72%\n",
      "\t Round: 50 |Train Loss: 62556.503 | Train evalMetric: 48.02%\n",
      "\t Round: 51 |Train Loss: 80798.550 | Train evalMetric: 32.58%\n",
      "\t Round: 52 |Train Loss: 74428.937 | Train evalMetric: 37.98%\n",
      "\t Round: 53 |Train Loss: 68113.001 | Train evalMetric: 43.28%\n",
      "\t Round: 54 |Train Loss: 47889.373 | Train evalMetric: 60.40%\n",
      "\t Round: 55 |Train Loss: 61356.662 | Train evalMetric: 48.91%\n",
      "\t Round: 56 |Train Loss: 72391.509 | Train evalMetric: 39.63%\n",
      "\t Round: 57 |Train Loss: 47519.868 | Train evalMetric: 60.57%\n",
      "\t Round: 58 |Train Loss: 50966.168 | Train evalMetric: 57.73%\n",
      "\t Round: 59 |Train Loss: 56526.637 | Train evalMetric: 53.08%\n",
      "\t Round: 60 |Train Loss: 48120.507 | Train evalMetric: 60.15%\n",
      "\t Round: 61 |Train Loss: 53081.320 | Train evalMetric: 55.93%\n",
      "\t Round: 62 |Train Loss: 51796.357 | Train evalMetric: 57.16%\n",
      "\t Round: 63 |Train Loss: 55425.315 | Train evalMetric: 54.02%\n",
      "\t Round: 64 |Train Loss: 65582.016 | Train evalMetric: 45.34%\n",
      "\t Round: 65 |Train Loss: 51411.702 | Train evalMetric: 57.31%\n",
      "\t Round: 66 |Train Loss: 78379.476 | Train evalMetric: 34.48%\n",
      "\t Round: 67 |Train Loss: 56567.301 | Train evalMetric: 52.99%\n",
      "\t Round: 68 |Train Loss: 55709.216 | Train evalMetric: 53.74%\n",
      "\t Round: 69 |Train Loss: 57297.535 | Train evalMetric: 52.32%\n",
      "\t Round: 70 |Train Loss: 56623.544 | Train evalMetric: 53.04%\n",
      "\t Round: 71 |Train Loss: 78778.214 | Train evalMetric: 34.13%\n",
      "\t Round: 72 |Train Loss: 44943.273 | Train evalMetric: 62.66%\n",
      "\t Round: 73 |Train Loss: 61048.940 | Train evalMetric: 49.29%\n",
      "\t Round: 74 |Train Loss: 47909.036 | Train evalMetric: 60.27%\n",
      "\t Round: 75 |Train Loss: 46290.720 | Train evalMetric: 61.63%\n",
      "\t Round: 76 |Train Loss: 44910.813 | Train evalMetric: 62.71%\n",
      "\t Round: 77 |Train Loss: 53341.681 | Train evalMetric: 55.72%\n",
      "\t Round: 78 |Train Loss: 67158.311 | Train evalMetric: 44.06%\n",
      "\t Round: 79 |Train Loss: 57764.952 | Train evalMetric: 51.97%\n",
      "\t Round: 80 |Train Loss: 52794.862 | Train evalMetric: 56.17%\n",
      "\t Round: 81 |Train Loss: 46381.236 | Train evalMetric: 61.55%\n",
      "\t Round: 82 |Train Loss: 64805.494 | Train evalMetric: 46.03%\n",
      "\t Round: 83 |Train Loss: 62507.055 | Train evalMetric: 47.98%\n",
      "\t Round: 84 |Train Loss: 49302.833 | Train evalMetric: 59.12%\n",
      "\t Round: 85 |Train Loss: 46018.158 | Train evalMetric: 61.88%\n",
      "\t Round: 86 |Train Loss: 71816.205 | Train evalMetric: 40.08%\n",
      "\t Round: 87 |Train Loss: 48241.626 | Train evalMetric: 59.99%\n",
      "\t Round: 88 |Train Loss: 51807.635 | Train evalMetric: 56.92%\n",
      "\t Round: 89 |Train Loss: 57452.378 | Train evalMetric: 52.30%\n",
      "\t Round: 90 |Train Loss: 52499.918 | Train evalMetric: 56.44%\n",
      "\t Round: 91 |Train Loss: 82471.716 | Train evalMetric: 31.07%\n",
      "\t Round: 92 |Train Loss: 57122.423 | Train evalMetric: 52.70%\n",
      "\t Round: 93 |Train Loss: 44564.601 | Train evalMetric: 63.01%\n",
      "\t Round: 94 |Train Loss: 61635.088 | Train evalMetric: 48.73%\n",
      "\t Round: 95 |Train Loss: 48849.318 | Train evalMetric: 59.41%\n",
      "\t Round: 96 |Train Loss: 47466.198 | Train evalMetric: 60.69%\n",
      "\t Round: 97 |Train Loss: 44549.993 | Train evalMetric: 63.01%\n",
      "\t Round: 98 |Train Loss: 43933.314 | Train evalMetric: 63.58%\n",
      "\t Round: 99 |Train Loss: 44102.412 | Train evalMetric: 63.36%\n",
      "\t Round: 100 |Train Loss: 52835.463 | Train evalMetric: 56.24%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.7596261129125038, test_acc:0.7658278292902603\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.6827545483584119, test_acc:0.6755237801135654\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.7396128372247713, test_acc:0.6943736815984489\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.8239668298311591, test_acc:0.8312954559409771\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.7074005862047131, test_acc:0.7030322437130411\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:0.5190848527457104, test_acc:0.5073622644588511\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.8474498374667494, test_acc:0.8379920834406809\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.317207211216958, test_acc:0.37179659073495325\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.7648400647499982, test_acc:0.7762558349202388\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7561964442660332, test_acc:0.7825918893544793\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:114201.6015625, test_acc:116022.0625, Extrac_acc:236248.359375\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:17220.75, test_acc:18035.173828125, Extrac_acc:51353.03515625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:143666.859375, test_acc:142279.8125, Extrac_acc:221718.5625\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:175130.984375, test_acc:174861.171875, Extrac_acc:299445.40625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:71983.390625, test_acc:78490.0234375, Extrac_acc:108298.5\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:84484.9140625, test_acc:90840.5, Extrac_acc:127353.0390625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:70279.5390625, test_acc:68842.203125, Extrac_acc:96729.7109375\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:93913.984375, test_acc:91889.75, Extrac_acc:129947.7109375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:404977.5, test_acc:419643.6875, Extrac_acc:402190.03125\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:588671.625, test_acc:604138.0625, Extrac_acc:973910.8125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:46025.359375, test_acc:47729.95703125, Extrac_acc:182858.359375\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:28463.490234375, test_acc:30768.611328125, Extrac_acc:114617.96875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:802072.25, test_acc:830013.125, Extrac_acc:483864.15625\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:975569.1875, test_acc:1016373.0625, Extrac_acc:108250.1875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:120253.625, test_acc:122670.703125, Extrac_acc:332381.09375\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:73835.4375, test_acc:73575.5625, Extrac_acc:188683.171875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:166880.65625, test_acc:163470.734375, Extrac_acc:444698.53125\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:151770.046875, test_acc:149182.84375, Extrac_acc:420564.5\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:71013.171875, test_acc:71121.9453125, Extrac_acc:213881.765625\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:52505.50390625, test_acc:52311.89453125, Extrac_acc:133623.734375\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 4342290055168.0 || Test loss: 426769481728.0\n",
      "Epoch: 1000 | | Train Loss: 4340675772416.0 || Test loss: 426656399360.0\n",
      "Epoch: 2000 | | Train Loss: 4338254348288.0 || Test loss: 426494918656.0\n",
      "Epoch: 3000 | | Train Loss: 4336066756608.0 || Test loss: 426340876288.0\n",
      "Client 0 prediction: mean tensor([ 0.1580, -0.1214, -0.0114,  ...,  0.0112,  0.0097,  0.0079],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.6582, 1.7649, 0.0187,  ..., 0.0101, 0.0118, 0.0276],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([ 3.1805e-01, -4.2873e+00,  3.6061e-03,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00]), std tensor([1.4386, 8.6669, 0.0452,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[9, 10, 27, 39, 43, 58, 62, 71, 85, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 8844648382464.0 || Test loss: 792612765696.0\n",
      "Epoch: 1000 | | Train Loss: 8842514530304.0 || Test loss: 792576720896.0\n",
      "Epoch: 2000 | | Train Loss: 8839666597888.0 || Test loss: 792533663744.0\n",
      "Epoch: 3000 | | Train Loss: 8837099683840.0 || Test loss: 792465899520.0\n",
      "Client 1 prediction: mean tensor([ 0.0530,  0.2421,  0.0675,  ...,  0.0461, -0.0477,  0.0242],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.2040, 2.0662, 0.1263,  ..., 0.0167, 0.0263, 0.0198],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([ 0.9246, 13.7820,  0.2948,  ...,  0.0000,  0.0000,  0.0000]), std tensor([ 1.2542, 13.6805,  0.5540,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 3509605629952.0 || Test loss: 375484252160.0\n",
      "Epoch: 1000 | | Train Loss: 3508394262528.0 || Test loss: 375422189568.0\n",
      "Epoch: 2000 | | Train Loss: 3506592284672.0 || Test loss: 375321690112.0\n",
      "Epoch: 3000 | | Train Loss: 3504958603264.0 || Test loss: 375218733056.0\n",
      "Client 2 prediction: mean tensor([ 0.1485,  0.2446,  0.1989,  ...,  0.0038, -0.0266,  0.0055],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.2747, 1.3350, 0.4400,  ..., 0.0196, 0.0184, 0.0606],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([ 6.9394, 45.8187,  2.2249,  ...,  0.0000,  0.0000,  0.0000]), std tensor([ 7.5654, 38.4287,  2.1293,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 14, 24, 34, 42, 56, 67, 74, 81, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 4193211121664.0 || Test loss: 471045996544.0\n",
      "Epoch: 1000 | | Train Loss: 4192175652864.0 || Test loss: 470932717568.0\n",
      "Epoch: 2000 | | Train Loss: 4190497406976.0 || Test loss: 470719627264.0\n",
      "Epoch: 3000 | | Train Loss: 4188903571456.0 || Test loss: 470539075584.0\n",
      "Client 3 prediction: mean tensor([0.4494, 0.3408, 0.2333,  ..., 0.1116, 0.0132, 0.0275],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([2.4980, 2.7848, 1.5077,  ..., 0.0188, 0.0377, 0.2408],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([19.0387, 87.6522,  4.1412,  ...,  0.0000,  0.0000,  0.0000]), std tensor([12.4908, 50.4023,  2.5200,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 4:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 11679411732480.0 || Test loss: 2306784624640.0\n",
      "Epoch: 1000 | | Train Loss: 11677130031104.0 || Test loss: 2306146304000.0\n",
      "Epoch: 2000 | | Train Loss: 11674191921152.0 || Test loss: 2305242431488.0\n",
      "Epoch: 3000 | | Train Loss: 11670894149632.0 || Test loss: 2304463863808.0\n",
      "Client 4 prediction: mean tensor([-0.1951,  0.0967, -0.1928,  ...,  0.1000,  0.0159,  0.1349],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.3436, 2.3543, 0.1539,  ..., 0.0202, 0.0338, 0.0324],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 4 y: mean tensor([ -2.1398, -11.2406,  -0.6921,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 0.7236, 17.0482,  0.2655,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 5:\n",
      "[1, 12, 23, 31, 43, 51, 60, 78, 84, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 2022755663872.0 || Test loss: 197600788480.0\n",
      "Epoch: 1000 | | Train Loss: 2021207965696.0 || Test loss: 197448712192.0\n",
      "Epoch: 2000 | | Train Loss: 2018957328384.0 || Test loss: 197218975744.0\n",
      "Epoch: 3000 | | Train Loss: 2016993869824.0 || Test loss: 197020483584.0\n",
      "Client 5 prediction: mean tensor([ 0.1676,  0.0967,  0.0379,  ...,  0.0398, -0.0807, -0.0297],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.2176, 1.5670, 0.0501,  ..., 0.0098, 0.0113, 0.0136],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 5 y: mean tensor([0.6257, 1.6376, 0.1171,  ..., 0.0000, 0.0000, 0.0000]), std tensor([1.0277, 6.1029, 0.2055,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 6:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 85266953928704.0 || Test loss: 8516491280384.0\n",
      "Epoch: 1000 | | Train Loss: 85259387404288.0 || Test loss: 8515844833280.0\n",
      "Epoch: 2000 | | Train Loss: 85245680418816.0 || Test loss: 8514733867008.0\n",
      "Epoch: 3000 | | Train Loss: 85235102384128.0 || Test loss: 8513853063168.0\n",
      "Client 6 prediction: mean tensor([ 0.0397, -0.0974, -0.2889,  ...,  0.1424, -0.3307, -0.2104],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.0276, 2.7101, 0.4303,  ..., 0.0161, 0.0137, 0.0436],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 6 y: mean tensor([-4.1604, -0.1331, -1.3044,  ...,  0.0000,  0.0000,  0.0000]), std tensor([ 2.2361, 11.0538,  0.9163,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 7:\n",
      "[9, 15, 22, 31, 43, 57, 64, 73, 80, 98]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 2102566584320.0 || Test loss: 195170926592.0\n",
      "Epoch: 1000 | | Train Loss: 2101020721152.0 || Test loss: 195048226816.0\n",
      "Epoch: 2000 | | Train Loss: 2098622627840.0 || Test loss: 194849341440.0\n",
      "Epoch: 3000 | | Train Loss: 2096370548736.0 || Test loss: 194636824576.0\n",
      "Client 7 prediction: mean tensor([-0.0824,  0.1067,  0.0755,  ...,  0.1187,  0.1451,  0.0305],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0394, 0.0442, 0.0373,  ..., 0.0371, 0.0156, 0.0298],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 7 y: mean tensor([0.2605, 0.1420, 0.0075,  ..., 0.0000, 0.0000, 0.0000]), std tensor([0.1654, 0.1190, 0.0575,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 8:\n",
      "[6, 13, 25, 31, 45, 53, 67, 73, 85, 93]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 2557674782720.0 || Test loss: 237793722368.0\n",
      "Epoch: 1000 | | Train Loss: 2556289089536.0 || Test loss: 237685145600.0\n",
      "Epoch: 2000 | | Train Loss: 2554369933312.0 || Test loss: 237541261312.0\n",
      "Epoch: 3000 | | Train Loss: 2552745164800.0 || Test loss: 237413466112.0\n",
      "Client 8 prediction: mean tensor([ 0.3269,  0.1768, -0.2072,  ...,  0.1261, -0.0834,  0.0699],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0207, 1.4826, 0.1217,  ..., 0.0159, 0.0262, 0.0147],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 8 y: mean tensor([-0.0630, -7.8711, -0.4452,  ...,  0.0000,  0.0000,  0.0000]), std tensor([0.0482, 5.4241, 0.2866,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 9:\n",
      "[5, 10, 22, 39, 42, 53, 69, 72, 88, 95]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 3870328619008.0 || Test loss: 240115515392.0\n",
      "Epoch: 1000 | | Train Loss: 3868314566656.0 || Test loss: 240034955264.0\n",
      "Epoch: 2000 | | Train Loss: 3865239093248.0 || Test loss: 239899344896.0\n",
      "Epoch: 3000 | | Train Loss: 3862582001664.0 || Test loss: 239778021376.0\n",
      "Client 9 prediction: mean tensor([ 0.1252, -0.1912, -0.0626,  ..., -0.0290,  0.0050,  0.0437],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.4098, 3.1552, 0.2165,  ..., 0.0081, 0.0176, 0.0357],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 9 y: mean tensor([  1.0145, -11.6147,  -0.2789,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 2.3688, 35.6724,  0.7159,  ...,  0.0000,  0.0000,  0.0000])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:114201.60, Test accuracy:116022.06, Extraction Accuracy:236248.36\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:17220.75, Test accuracy:18035.17, Extraction Accuracy:51353.04\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:0.76, Test accuracy:0.77\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1896811.8750, Training accuracy: 17220.75, Test Accuracy: 18035.17\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1261404.1250, Training accuracy: 18348.76, Test Accuracy: 19324.90\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 835979.8750, Training accuracy: 24998.99, Test Accuracy: 26092.88\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 552003.6875, Training accuracy: 28191.61, Test Accuracy: 29289.03\n",
      "Best: Gradient norm:552003.6875\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:4333037420544.00, Test loss: 425888219136.00,Training accuracy: 28191.61, Test accuracy: 29289.03, Extraction accuracy: 4966.71\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:143666.86, Test accuracy:142279.81, Extraction Accuracy:221718.56\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:175130.98, Test accuracy:174861.17, Extraction Accuracy:299445.41\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.68, Test accuracy:0.68\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 65532.4336, Training accuracy: 175130.89, Test Accuracy: 174861.06\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 44255.9180, Training accuracy: 173324.58, Test Accuracy: 172989.39\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 29941.2285, Training accuracy: 171821.66, Test Accuracy: 171431.30\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 20348.2344, Training accuracy: 170619.80, Test Accuracy: 170185.16\n",
      "Best: Gradient norm:20348.2344\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:8836821811200.00, Test loss: 792435425280.00,Training accuracy: 170619.80, Test accuracy: 170185.16, Extraction accuracy: 283947.56\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:71983.39, Test accuracy:78490.02, Extraction Accuracy:108298.50\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:84484.91, Test accuracy:90840.50, Extraction Accuracy:127353.04\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.74, Test accuracy:0.69\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1403584.7500, Training accuracy: 84484.91, Test Accuracy: 90840.50\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 903944.9375, Training accuracy: 78709.34, Test Accuracy: 86055.11\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 586083.7500, Training accuracy: 610662.94, Test Accuracy: 605777.44\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 474062.4062, Training accuracy: 2199873.75, Test Accuracy: 2168383.50\n",
      "Best: Gradient norm:474062.4062\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:3504453713920.00, Test loss: 375020912640.00,Training accuracy: 2199873.75, Test accuracy: 2168383.50, Extraction accuracy: 2996397.75\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:70279.54, Test accuracy:68842.20, Extraction Accuracy:96729.71\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:93913.98, Test accuracy:91889.75, Extraction Accuracy:129947.71\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.82, Test accuracy:0.83\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 2580819.0000, Training accuracy: 93913.98, Test Accuracy: 91889.75\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 16784320.0000, Training accuracy: 69779.03, Test Accuracy: 68213.18\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 11521683.0000, Training accuracy: 77673.17, Test Accuracy: 76862.95\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 7987824.0000, Training accuracy: 97023.52, Test Accuracy: 96406.63\n",
      "Best: Gradient norm:2580819.0000\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:4185541312512.00, Test loss: 470188752896.00,Training accuracy: 97023.52, Test accuracy: 96406.63, Extraction accuracy: 3524.67\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:4, Training accuracy:404977.50, Test accuracy:419643.69, Extraction Accuracy:402190.03\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:4, Training accuracy:588671.62, Test accuracy:604138.06, Extraction Accuracy:973910.81\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:4, Training accuracy:0.71, Test accuracy:0.70\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 14693700.0000, Training accuracy: 588670.94, Test Accuracy: 604137.38\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 9859248.0000, Training accuracy: 586610.62, Test Accuracy: 602056.00\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 6613774.5000, Training accuracy: 584688.69, Test Accuracy: 600112.81\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 4437012.0000, Training accuracy: 582999.88, Test Accuracy: 598404.75\n",
      "Best: Gradient norm:4437012.0000\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:4, Used Gradient Network Train loss:11670289121280.00, Test loss: 2304428998656.00,Training accuracy: 582999.88, Test accuracy: 598404.75, Extraction accuracy: 961949.94\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:5, Training accuracy:46025.36, Test accuracy:47729.96, Extraction Accuracy:182858.36\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:5, Training accuracy:28463.49, Test accuracy:30768.61, Extraction Accuracy:114617.97\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:5, Training accuracy:0.52, Test accuracy:0.51\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 4673463.0000, Training accuracy: 28463.49, Test Accuracy: 30768.61\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 3120186.7500, Training accuracy: 48005.59, Test Accuracy: 49530.79\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 2080688.5000, Training accuracy: 1139334.75, Test Accuracy: 1118001.00\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 1387097.1250, Training accuracy: 5761633.50, Test Accuracy: 5656800.50\n",
      "Best: Gradient norm:1387097.1250\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:5, Used Gradient Network Train loss:2014104125440.00, Test loss: 196761239552.00,Training accuracy: 5761633.50, Test accuracy: 5656800.50, Extraction accuracy: 7228875.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:6, Training accuracy:802072.25, Test accuracy:830013.12, Extraction Accuracy:483864.16\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:6, Training accuracy:975569.19, Test accuracy:1016373.06, Extraction Accuracy:108250.19\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:6, Training accuracy:0.85, Test accuracy:0.84\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 6681206.0000, Training accuracy: 975569.19, Test Accuracy: 1016373.06\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 4822206.0000, Training accuracy: 982420.25, Test Accuracy: 1023669.38\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 3354976.7500, Training accuracy: 975012.44, Test Accuracy: 1015642.19\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 2321525.7500, Training accuracy: 958572.00, Test Accuracy: 998081.69\n",
      "Best: Gradient norm:2321525.7500\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:6, Used Gradient Network Train loss:85232459972608.00, Test loss: 8512937656320.00,Training accuracy: 958572.00, Test accuracy: 998081.69, Extraction accuracy: 122255.51\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:7, Training accuracy:120253.62, Test accuracy:122670.70, Extraction Accuracy:332381.09\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:7, Training accuracy:73835.44, Test accuracy:73575.56, Extraction Accuracy:188683.17\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:7, Training accuracy:0.32, Test accuracy:0.37\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 3520569.2500, Training accuracy: 73835.44, Test Accuracy: 73575.56\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 2357223.0000, Training accuracy: 80864.56, Test Accuracy: 80664.84\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1567812.7500, Training accuracy: 355324.72, Test Accuracy: 349639.62\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 1042322.1250, Training accuracy: 1341786.00, Test Accuracy: 1304095.50\n",
      "Best: Gradient norm:1042322.1250\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:7, Used Gradient Network Train loss:2092791496704.00, Test loss: 194008268800.00,Training accuracy: 1341786.00, Test accuracy: 1304095.50, Extraction accuracy: 2251763.25\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:8, Training accuracy:166880.66, Test accuracy:163470.73, Extraction Accuracy:444698.53\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:8, Training accuracy:151770.05, Test accuracy:149182.84, Extraction Accuracy:420564.50\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:8, Training accuracy:0.76, Test accuracy:0.78\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 76820.9609, Training accuracy: 151770.03, Test Accuracy: 149182.81\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 51736.7109, Training accuracy: 151686.86, Test Accuracy: 149113.91\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 34895.5312, Training accuracy: 151640.34, Test Accuracy: 149072.98\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 23607.6191, Training accuracy: 151601.53, Test Accuracy: 149036.91\n",
      "Best: Gradient norm:23607.6191\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:8, Used Gradient Network Train loss:2552745164800.00, Test loss: 237413466112.00,Training accuracy: 151601.53, Test accuracy: 149036.91, Extraction accuracy: 419648.78\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:9, Training accuracy:71013.17, Test accuracy:71121.95, Extraction Accuracy:213881.77\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:9, Training accuracy:52505.50, Test accuracy:52311.89, Extraction Accuracy:133623.73\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:9, Training accuracy:0.76, Test accuracy:0.78\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 4691820.5000, Training accuracy: 52505.50, Test Accuracy: 52311.89\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 3137950.2500, Training accuracy: 57677.43, Test Accuracy: 57122.13\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 2095823.8750, Training accuracy: 128374.67, Test Accuracy: 127308.78\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 1399824.6250, Training accuracy: 148150.80, Test Accuracy: 147060.09\n",
      "Best: Gradient norm:1399824.6250\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:9, Used Gradient Network Train loss:3861960982528.00, Test loss: 239364177920.00,Training accuracy: 148150.80, Test accuracy: 147060.09, Extraction accuracy: 573.47\n",
      "rm logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 512 --num_local_steps 1 --device \"cpu\" --gnetwork_num_epochs 3001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 128 --start_point global_model --decoded_epochs 3001 --model neuralReg --fit_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-19 20:20:28.917 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:12156 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-19 20:20:29.051 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:12156 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\t Round: 1 |Train Loss: 193018.745 | Train evalMetric: -62.63%\n",
      "\t Round: 2 |Train Loss: 142276.457 | Train evalMetric: -19.63%\n",
      "\t Round: 3 |Train Loss: 197050.706 | Train evalMetric: -66.76%\n",
      "\t Round: 4 |Train Loss: 97337.727 | Train evalMetric: 18.54%\n",
      "\t Round: 5 |Train Loss: 63328.711 | Train evalMetric: 47.42%\n",
      "\t Round: 6 |Train Loss: 71332.302 | Train evalMetric: 40.54%\n",
      "\t Round: 7 |Train Loss: 52287.782 | Train evalMetric: 56.71%\n",
      "\t Round: 8 |Train Loss: 83111.380 | Train evalMetric: 30.54%\n",
      "\t Round: 9 |Train Loss: 108010.101 | Train evalMetric: 9.31%\n",
      "\t Round: 10 |Train Loss: 116213.189 | Train evalMetric: 2.28%\n",
      "\t Round: 11 |Train Loss: 49019.680 | Train evalMetric: 59.12%\n",
      "\t Round: 12 |Train Loss: 62943.648 | Train evalMetric: 47.68%\n",
      "\t Round: 13 |Train Loss: 48746.703 | Train evalMetric: 59.60%\n",
      "\t Round: 14 |Train Loss: 88937.070 | Train evalMetric: 25.59%\n",
      "\t Round: 15 |Train Loss: 50952.197 | Train evalMetric: 57.73%\n",
      "\t Round: 16 |Train Loss: 66204.965 | Train evalMetric: 44.88%\n",
      "\t Round: 17 |Train Loss: 55776.363 | Train evalMetric: 53.80%\n",
      "\t Round: 18 |Train Loss: 53515.824 | Train evalMetric: 55.68%\n",
      "\t Round: 19 |Train Loss: 46382.268 | Train evalMetric: 61.51%\n",
      "\t Round: 20 |Train Loss: 49812.723 | Train evalMetric: 58.70%\n",
      "\t Round: 21 |Train Loss: 54452.303 | Train evalMetric: 54.90%\n",
      "\t Round: 22 |Train Loss: 49544.010 | Train evalMetric: 58.97%\n",
      "\t Round: 23 |Train Loss: 55935.965 | Train evalMetric: 53.69%\n",
      "\t Round: 24 |Train Loss: 45339.523 | Train evalMetric: 62.41%\n",
      "\t Round: 25 |Train Loss: 61851.162 | Train evalMetric: 48.60%\n",
      "\t Round: 26 |Train Loss: 50043.612 | Train evalMetric: 58.58%\n",
      "\t Round: 27 |Train Loss: 50017.654 | Train evalMetric: 58.62%\n",
      "\t Round: 28 |Train Loss: 65338.144 | Train evalMetric: 45.67%\n",
      "\t Round: 29 |Train Loss: 45892.891 | Train evalMetric: 61.95%\n",
      "\t Round: 30 |Train Loss: 70264.779 | Train evalMetric: 41.52%\n",
      "\t Round: 31 |Train Loss: 47514.782 | Train evalMetric: 60.66%\n",
      "\t Round: 32 |Train Loss: 59905.090 | Train evalMetric: 50.17%\n",
      "\t Round: 33 |Train Loss: 48522.933 | Train evalMetric: 59.86%\n",
      "\t Round: 34 |Train Loss: 55061.339 | Train evalMetric: 54.31%\n",
      "\t Round: 35 |Train Loss: 45897.359 | Train evalMetric: 61.97%\n",
      "\t Round: 36 |Train Loss: 48203.446 | Train evalMetric: 60.04%\n",
      "\t Round: 37 |Train Loss: 44762.418 | Train evalMetric: 62.82%\n",
      "\t Round: 38 |Train Loss: 43979.212 | Train evalMetric: 63.53%\n",
      "\t Round: 39 |Train Loss: 55481.629 | Train evalMetric: 54.00%\n",
      "\t Round: 40 |Train Loss: 43361.993 | Train evalMetric: 64.01%\n",
      "\t Round: 41 |Train Loss: 44131.054 | Train evalMetric: 63.42%\n",
      "\t Round: 42 |Train Loss: 43512.356 | Train evalMetric: 63.94%\n",
      "\t Round: 43 |Train Loss: 44890.677 | Train evalMetric: 62.85%\n",
      "\t Round: 44 |Train Loss: 46118.716 | Train evalMetric: 61.81%\n",
      "\t Round: 45 |Train Loss: 43955.896 | Train evalMetric: 63.55%\n",
      "\t Round: 46 |Train Loss: 50560.311 | Train evalMetric: 58.05%\n",
      "\t Round: 47 |Train Loss: 43784.194 | Train evalMetric: 63.77%\n",
      "\t Round: 48 |Train Loss: 44502.153 | Train evalMetric: 63.10%\n",
      "\t Round: 49 |Train Loss: 43165.586 | Train evalMetric: 64.14%\n",
      "\t Round: 50 |Train Loss: 42688.376 | Train evalMetric: 64.60%\n",
      "\t Round: 51 |Train Loss: 44245.690 | Train evalMetric: 63.31%\n",
      "\t Round: 52 |Train Loss: 43319.706 | Train evalMetric: 63.93%\n",
      "\t Round: 53 |Train Loss: 41990.767 | Train evalMetric: 65.10%\n",
      "\t Round: 54 |Train Loss: 42337.867 | Train evalMetric: 64.82%\n",
      "\t Round: 55 |Train Loss: 49153.551 | Train evalMetric: 59.26%\n",
      "\t Round: 56 |Train Loss: 58506.845 | Train evalMetric: 51.37%\n",
      "\t Round: 57 |Train Loss: 42565.825 | Train evalMetric: 64.70%\n",
      "\t Round: 58 |Train Loss: 43421.666 | Train evalMetric: 64.03%\n",
      "\t Round: 59 |Train Loss: 43185.503 | Train evalMetric: 64.22%\n",
      "\t Round: 60 |Train Loss: 43089.420 | Train evalMetric: 64.31%\n",
      "\t Round: 61 |Train Loss: 41747.835 | Train evalMetric: 65.36%\n",
      "\t Round: 62 |Train Loss: 42228.976 | Train evalMetric: 64.91%\n",
      "\t Round: 63 |Train Loss: 41978.062 | Train evalMetric: 65.08%\n",
      "\t Round: 64 |Train Loss: 46280.558 | Train evalMetric: 61.64%\n",
      "\t Round: 65 |Train Loss: 42978.211 | Train evalMetric: 64.10%\n",
      "\t Round: 66 |Train Loss: 41777.860 | Train evalMetric: 65.27%\n",
      "\t Round: 67 |Train Loss: 41843.731 | Train evalMetric: 65.20%\n",
      "\t Round: 68 |Train Loss: 42567.489 | Train evalMetric: 64.59%\n",
      "\t Round: 69 |Train Loss: 41932.714 | Train evalMetric: 65.21%\n",
      "\t Round: 70 |Train Loss: 42713.623 | Train evalMetric: 64.46%\n",
      "\t Round: 71 |Train Loss: 41786.427 | Train evalMetric: 65.28%\n",
      "\t Round: 72 |Train Loss: 41380.637 | Train evalMetric: 65.56%\n",
      "\t Round: 73 |Train Loss: 46019.214 | Train evalMetric: 61.82%\n",
      "\t Round: 74 |Train Loss: 44291.360 | Train evalMetric: 63.22%\n",
      "\t Round: 75 |Train Loss: 44914.249 | Train evalMetric: 62.84%\n",
      "\t Round: 76 |Train Loss: 45315.799 | Train evalMetric: 62.50%\n",
      "\t Round: 77 |Train Loss: 42436.224 | Train evalMetric: 64.76%\n",
      "\t Round: 78 |Train Loss: 42369.366 | Train evalMetric: 64.61%\n",
      "\t Round: 79 |Train Loss: 42083.429 | Train evalMetric: 65.03%\n",
      "\t Round: 80 |Train Loss: 42771.855 | Train evalMetric: 64.49%\n",
      "\t Round: 81 |Train Loss: 41340.026 | Train evalMetric: 65.62%\n",
      "\t Round: 82 |Train Loss: 41882.564 | Train evalMetric: 65.10%\n",
      "\t Round: 83 |Train Loss: 41767.295 | Train evalMetric: 65.16%\n",
      "\t Round: 84 |Train Loss: 41994.126 | Train evalMetric: 65.12%\n",
      "\t Round: 85 |Train Loss: 41256.114 | Train evalMetric: 65.70%\n",
      "\t Round: 86 |Train Loss: 41251.578 | Train evalMetric: 65.62%\n",
      "\t Round: 87 |Train Loss: 41174.628 | Train evalMetric: 65.85%\n",
      "\t Round: 88 |Train Loss: 41220.196 | Train evalMetric: 65.66%\n",
      "\t Round: 89 |Train Loss: 40938.676 | Train evalMetric: 65.93%\n",
      "\t Round: 90 |Train Loss: 45786.594 | Train evalMetric: 62.06%\n",
      "\t Round: 91 |Train Loss: 41615.661 | Train evalMetric: 65.53%\n",
      "\t Round: 92 |Train Loss: 41222.880 | Train evalMetric: 65.73%\n",
      "\t Round: 93 |Train Loss: 41032.955 | Train evalMetric: 65.84%\n",
      "\t Round: 94 |Train Loss: 41192.039 | Train evalMetric: 65.73%\n",
      "\t Round: 95 |Train Loss: 44949.276 | Train evalMetric: 62.78%\n",
      "\t Round: 96 |Train Loss: 41524.470 | Train evalMetric: 65.47%\n",
      "\t Round: 97 |Train Loss: 42020.086 | Train evalMetric: 65.18%\n",
      "\t Round: 98 |Train Loss: 41103.530 | Train evalMetric: 65.83%\n",
      "\t Round: 99 |Train Loss: 41481.605 | Train evalMetric: 65.55%\n",
      "\t Round: 100 |Train Loss: 41176.405 | Train evalMetric: 65.67%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_4_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.8340672389735218, test_acc:0.8515487511952718\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.6559125886095581, test_acc:0.6509120786448451\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.7614949281717881, test_acc:0.7095715766806819\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.8391438433731259, test_acc:0.8454874611672564\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.3268776599666901, test_acc:0.3178630488110007\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:0.5458354412657522, test_acc:0.5229283046189964\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.8747340320952871, test_acc:0.8746020680562063\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.4807887647581601, test_acc:0.5291196999526756\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.8140929939831004, test_acc:0.8007103664000896\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7796386828059086, test_acc:0.80599068210223\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:105845.375, test_acc:106890.7734375, Extrac_acc:223336.8125\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:15576.900390625, test_acc:16686.490234375, Extrac_acc:48619.73828125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:145858.546875, test_acc:144887.59375, Extrac_acc:213613.125\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:189152.375, test_acc:189639.96875, Extrac_acc:342557.0625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:68767.015625, test_acc:75298.4765625, Extrac_acc:107803.71875\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:84362.8671875, test_acc:91024.6953125, Extrac_acc:105840.4921875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:65972.2421875, test_acc:64696.2421875, Extrac_acc:94664.0703125\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:97156.8671875, test_acc:96096.65625, Extrac_acc:132777.609375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:416756.125, test_acc:430893.90625, Extrac_acc:452045.09375\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:417973.90625, test_acc:433542.28125, Extrac_acc:381862.75\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:44563.265625, test_acc:46375.51171875, Extrac_acc:177422.625\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:27629.36328125, test_acc:30116.021484375, Extrac_acc:116297.4921875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:810959.875, test_acc:839172.6875, Extrac_acc:532886.75\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:1710713.0, test_acc:1740279.0, Extrac_acc:2637714.75\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:126963.890625, test_acc:128929.59375, Extrac_acc:343066.375\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:75439.9921875, test_acc:74673.8515625, Extrac_acc:187653.328125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:163383.796875, test_acc:159395.421875, Extrac_acc:395812.90625\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:152580.453125, test_acc:148609.65625, Extrac_acc:368872.09375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:72395.90625, test_acc:72295.515625, Extrac_acc:217279.6875\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:56203.140625, test_acc:55860.453125, Extrac_acc:164587.828125\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 512 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 6916562485248.0 || Test loss: 801024901120.0\n",
      "Epoch: 1000 | | Train Loss: 6910571970560.0 || Test loss: 800469876736.0\n",
      "Epoch: 2000 | | Train Loss: 6901377531904.0 || Test loss: 799532711936.0\n",
      "Epoch: 3000 | | Train Loss: 6893538377728.0 || Test loss: 798742085632.0\n",
      "Client 0 prediction: mean tensor([-0.8696, -0.8150, -0.4381,  ...,  0.0243, -0.0269, -0.0203],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([10.4132,  7.8668,  1.2958,  ...,  0.0230,  0.0127,  0.0204],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([ -94.6490, -923.1872,   -3.6002,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([176.2777, 788.8880,   5.8505,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[9, 10, 27, 39, 43, 58, 62, 71, 85, 90]\n",
      "134657 512 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 17753721274368.0 || Test loss: 1132328255488.0\n",
      "Epoch: 1000 | | Train Loss: 17741792673792.0 || Test loss: 1132313051136.0\n",
      "Epoch: 2000 | | Train Loss: 17722417086464.0 || Test loss: 1131815895040.0\n",
      "Epoch: 3000 | | Train Loss: 17706233364480.0 || Test loss: 1131429756928.0\n",
      "Client 1 prediction: mean tensor([ 0.0594,  0.0316,  0.0614,  ...,  0.0471,  0.0193, -0.0755],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([8.0145e+00, 8.7477e+00, 7.9791e+00,  ..., 4.8769e-03, 1.6550e-02,\n",
      "        1.6191e-02], grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([220.0397, 822.3224,  55.8626,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 635.1788, 1550.8232,  121.0505,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94]\n",
      "134657 512 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 8317538140160.0 || Test loss: 735328796672.0\n",
      "Epoch: 1000 | | Train Loss: 8308107247616.0 || Test loss: 735171313664.0\n",
      "Epoch: 2000 | | Train Loss: 8296253620224.0 || Test loss: 734995546112.0\n",
      "Epoch: 3000 | | Train Loss: 8285014458368.0 || Test loss: 734750638080.0\n",
      "Client 2 prediction: mean tensor([-0.2205,  0.2401, -0.2693,  ..., -0.0055, -0.0119, -0.0031],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([5.5495e+00, 7.2499e+00, 4.3944e+00,  ..., 7.9812e-03, 6.5352e-03,\n",
      "        5.8457e-03], grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([ -57.3924, 2083.5701,  -26.2696,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([ 117.3424, 1384.0424,   45.1819,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 14, 24, 34, 42, 56, 67, 74, 81, 91]\n",
      "134657 512 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 7759804235776.0 || Test loss: 1221254316032.0\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 512 --num_local_steps 4 --device \"cpu\" --gnetwork_num_epochs 3001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 512 --start_point global_model --decoded_epochs 3001 --model neuralReg --fit_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-20 10:29:08.362 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:25420 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-20 10:29:08.496 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:25420 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\t Round: 1 |Train Loss: 129042.908 | Train evalMetric: -8.14%\n",
      "\t Round: 2 |Train Loss: 128355.599 | Train evalMetric: -7.61%\n",
      "\t Round: 3 |Train Loss: 141672.527 | Train evalMetric: -19.11%\n",
      "\t Round: 4 |Train Loss: 57102.750 | Train evalMetric: 52.59%\n",
      "\t Round: 5 |Train Loss: 213969.871 | Train evalMetric: -81.27%\n",
      "\t Round: 6 |Train Loss: 188402.238 | Train evalMetric: -58.92%\n",
      "\t Round: 7 |Train Loss: 113241.939 | Train evalMetric: 4.97%\n",
      "\t Round: 8 |Train Loss: 148697.385 | Train evalMetric: -25.36%\n",
      "\t Round: 9 |Train Loss: 89697.444 | Train evalMetric: 25.03%\n",
      "\t Round: 10 |Train Loss: 124080.169 | Train evalMetric: -4.20%\n",
      "\t Round: 11 |Train Loss: 126600.035 | Train evalMetric: -6.47%\n",
      "\t Round: 12 |Train Loss: 101504.777 | Train evalMetric: 15.02%\n",
      "\t Round: 13 |Train Loss: 52494.103 | Train evalMetric: 56.46%\n",
      "\t Round: 14 |Train Loss: 123360.369 | Train evalMetric: -3.79%\n",
      "\t Round: 15 |Train Loss: 98339.736 | Train evalMetric: 17.60%\n",
      "\t Round: 16 |Train Loss: 78533.444 | Train evalMetric: 34.38%\n",
      "\t Round: 17 |Train Loss: 79867.138 | Train evalMetric: 33.24%\n",
      "\t Round: 18 |Train Loss: 60770.287 | Train evalMetric: 49.56%\n",
      "\t Round: 19 |Train Loss: 114067.281 | Train evalMetric: 4.13%\n",
      "\t Round: 20 |Train Loss: 65644.850 | Train evalMetric: 45.46%\n",
      "\t Round: 21 |Train Loss: 59469.315 | Train evalMetric: 50.59%\n",
      "\t Round: 22 |Train Loss: 56761.561 | Train evalMetric: 52.91%\n",
      "\t Round: 23 |Train Loss: 67534.512 | Train evalMetric: 43.77%\n",
      "\t Round: 24 |Train Loss: 75693.981 | Train evalMetric: 36.85%\n",
      "\t Round: 25 |Train Loss: 50766.648 | Train evalMetric: 57.95%\n",
      "\t Round: 26 |Train Loss: 56165.559 | Train evalMetric: 53.34%\n",
      "\t Round: 27 |Train Loss: 80307.388 | Train evalMetric: 33.00%\n",
      "\t Round: 28 |Train Loss: 66724.392 | Train evalMetric: 44.49%\n",
      "\t Round: 29 |Train Loss: 51092.084 | Train evalMetric: 57.67%\n",
      "\t Round: 30 |Train Loss: 48294.405 | Train evalMetric: 59.99%\n",
      "\t Round: 31 |Train Loss: 50678.924 | Train evalMetric: 57.98%\n",
      "\t Round: 32 |Train Loss: 50843.618 | Train evalMetric: 57.87%\n",
      "\t Round: 33 |Train Loss: 64991.909 | Train evalMetric: 45.89%\n",
      "\t Round: 34 |Train Loss: 46817.482 | Train evalMetric: 61.19%\n",
      "\t Round: 35 |Train Loss: 111444.160 | Train evalMetric: 6.35%\n",
      "\t Round: 36 |Train Loss: 47605.773 | Train evalMetric: 60.57%\n",
      "\t Round: 37 |Train Loss: 75281.171 | Train evalMetric: 37.19%\n",
      "\t Round: 38 |Train Loss: 46792.224 | Train evalMetric: 61.22%\n",
      "\t Round: 39 |Train Loss: 50224.047 | Train evalMetric: 58.39%\n",
      "\t Round: 40 |Train Loss: 47897.494 | Train evalMetric: 60.29%\n",
      "\t Round: 41 |Train Loss: 54891.115 | Train evalMetric: 54.48%\n",
      "\t Round: 42 |Train Loss: 61936.048 | Train evalMetric: 48.50%\n",
      "\t Round: 43 |Train Loss: 57748.713 | Train evalMetric: 52.10%\n",
      "\t Round: 44 |Train Loss: 44758.019 | Train evalMetric: 62.85%\n",
      "\t Round: 45 |Train Loss: 48270.101 | Train evalMetric: 60.06%\n",
      "\t Round: 46 |Train Loss: 43938.878 | Train evalMetric: 63.50%\n",
      "\t Round: 47 |Train Loss: 49152.193 | Train evalMetric: 59.29%\n",
      "\t Round: 48 |Train Loss: 72804.503 | Train evalMetric: 39.32%\n",
      "\t Round: 49 |Train Loss: 45155.863 | Train evalMetric: 62.59%\n",
      "\t Round: 50 |Train Loss: 51237.031 | Train evalMetric: 57.39%\n",
      "\t Round: 51 |Train Loss: 47397.634 | Train evalMetric: 60.72%\n",
      "\t Round: 52 |Train Loss: 53042.885 | Train evalMetric: 55.95%\n",
      "\t Round: 53 |Train Loss: 45312.795 | Train evalMetric: 62.50%\n",
      "\t Round: 54 |Train Loss: 52598.288 | Train evalMetric: 56.26%\n",
      "\t Round: 55 |Train Loss: 46049.306 | Train evalMetric: 61.83%\n",
      "\t Round: 56 |Train Loss: 49524.222 | Train evalMetric: 58.89%\n",
      "\t Round: 57 |Train Loss: 44059.973 | Train evalMetric: 63.31%\n",
      "\t Round: 58 |Train Loss: 61678.056 | Train evalMetric: 48.68%\n",
      "\t Round: 59 |Train Loss: 49319.586 | Train evalMetric: 59.07%\n",
      "\t Round: 60 |Train Loss: 50958.569 | Train evalMetric: 57.88%\n",
      "\t Round: 61 |Train Loss: 51316.371 | Train evalMetric: 57.48%\n",
      "\t Round: 62 |Train Loss: 44109.969 | Train evalMetric: 63.47%\n",
      "\t Round: 63 |Train Loss: 44495.063 | Train evalMetric: 63.16%\n",
      "\t Round: 64 |Train Loss: 44441.442 | Train evalMetric: 63.19%\n",
      "\t Round: 65 |Train Loss: 52729.344 | Train evalMetric: 56.27%\n",
      "\t Round: 66 |Train Loss: 48472.976 | Train evalMetric: 59.82%\n",
      "\t Round: 67 |Train Loss: 43942.060 | Train evalMetric: 63.60%\n",
      "\t Round: 68 |Train Loss: 62459.127 | Train evalMetric: 48.10%\n",
      "\t Round: 69 |Train Loss: 43147.613 | Train evalMetric: 64.19%\n",
      "\t Round: 70 |Train Loss: 60990.306 | Train evalMetric: 49.23%\n",
      "\t Round: 71 |Train Loss: 44952.084 | Train evalMetric: 62.76%\n",
      "\t Round: 72 |Train Loss: 53808.934 | Train evalMetric: 55.43%\n",
      "\t Round: 73 |Train Loss: 50406.747 | Train evalMetric: 58.27%\n",
      "\t Round: 74 |Train Loss: 48799.536 | Train evalMetric: 59.60%\n",
      "\t Round: 75 |Train Loss: 42578.154 | Train evalMetric: 64.71%\n",
      "\t Round: 76 |Train Loss: 42676.592 | Train evalMetric: 64.61%\n",
      "\t Round: 77 |Train Loss: 49715.811 | Train evalMetric: 58.89%\n",
      "\t Round: 78 |Train Loss: 42896.760 | Train evalMetric: 64.49%\n",
      "\t Round: 79 |Train Loss: 52426.776 | Train evalMetric: 56.40%\n",
      "\t Round: 80 |Train Loss: 46309.222 | Train evalMetric: 61.63%\n",
      "\t Round: 81 |Train Loss: 43726.373 | Train evalMetric: 63.71%\n",
      "\t Round: 82 |Train Loss: 50144.009 | Train evalMetric: 58.30%\n",
      "\t Round: 83 |Train Loss: 45063.158 | Train evalMetric: 62.65%\n",
      "\t Round: 84 |Train Loss: 49614.990 | Train evalMetric: 58.88%\n",
      "\t Round: 85 |Train Loss: 45771.888 | Train evalMetric: 62.10%\n",
      "\t Round: 86 |Train Loss: 42854.909 | Train evalMetric: 64.48%\n",
      "\t Round: 87 |Train Loss: 43039.790 | Train evalMetric: 64.32%\n",
      "\t Round: 88 |Train Loss: 42646.283 | Train evalMetric: 64.63%\n",
      "\t Round: 89 |Train Loss: 42550.392 | Train evalMetric: 64.64%\n",
      "\t Round: 90 |Train Loss: 48022.007 | Train evalMetric: 60.14%\n",
      "\t Round: 91 |Train Loss: 43930.505 | Train evalMetric: 63.57%\n",
      "\t Round: 92 |Train Loss: 43575.331 | Train evalMetric: 63.92%\n",
      "\t Round: 93 |Train Loss: 45398.999 | Train evalMetric: 62.37%\n",
      "\t Round: 94 |Train Loss: 52777.852 | Train evalMetric: 56.20%\n",
      "\t Round: 95 |Train Loss: 44950.842 | Train evalMetric: 62.76%\n",
      "\t Round: 96 |Train Loss: 49641.655 | Train evalMetric: 58.86%\n",
      "\t Round: 97 |Train Loss: 46078.735 | Train evalMetric: 61.88%\n",
      "\t Round: 98 |Train Loss: 42245.378 | Train evalMetric: 64.89%\n",
      "\t Round: 99 |Train Loss: 47420.419 | Train evalMetric: 60.81%\n",
      "\t Round: 100 |Train Loss: 44130.477 | Train evalMetric: 63.38%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.8075719074070712, test_acc:0.8199054606782155\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.6936138421431287, test_acc:0.6879044891976726\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.7447234273439386, test_acc:0.6958893023113584\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.8260739546683534, test_acc:0.8338927186508076\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.7663479219547071, test_acc:0.7663847887520777\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:0.3805102662650996, test_acc:0.3850342242356861\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.8918167565812606, test_acc:0.8881019893236659\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.46015033246028614, test_acc:0.5132378422578433\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.8114649095535278, test_acc:0.8043069009756658\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7859631009204938, test_acc:0.814997327925707\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:79401.671875, test_acc:80013.2890625, Extrac_acc:177765.890625\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:14797.171875, test_acc:15706.75, Extrac_acc:48175.9765625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:140842.484375, test_acc:139648.015625, Extrac_acc:177089.875\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:174960.671875, test_acc:174993.109375, Extrac_acc:276304.96875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:69724.296875, test_acc:76395.3046875, Extrac_acc:86881.6171875\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:89527.34375, test_acc:95776.28125, Extrac_acc:146872.0625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:65413.015625, test_acc:64274.8046875, Extrac_acc:73719.0859375\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:90892.7578125, test_acc:89587.953125, Extrac_acc:106090.8984375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:397842.03125, test_acc:412852.84375, Extrac_acc:337410.84375\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:405240.4375, test_acc:420512.6875, Extrac_acc:351335.78125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:34405.0859375, test_acc:36681.63671875, Extrac_acc:132159.96875\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:28069.138671875, test_acc:30516.5546875, Extrac_acc:117982.3046875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:808386.875, test_acc:837711.3125, Extrac_acc:403058.625\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:1284163.75, test_acc:1311131.125, Extrac_acc:1935413.5\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:100576.921875, test_acc:101628.1796875, Extrac_acc:263317.21875\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:72138.9921875, test_acc:71483.796875, Extrac_acc:184662.546875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:157121.140625, test_acc:155715.921875, Extrac_acc:332999.71875\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:148116.984375, test_acc:145469.0625, Extrac_acc:380546.875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:60392.03515625, test_acc:60380.4375, Extrac_acc:168611.15625\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:56926.98828125, test_acc:56769.2109375, Extrac_acc:155250.953125\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 6443762188288.0 || Test loss: 667689615360.0\n",
      "Epoch: 1000 | | Train Loss: 6446712356864.0 || Test loss: 668039577600.0\n",
      "Client 0 prediction: mean tensor([-1.7353, -1.7402, -2.7374,  ...,  0.0042,  3.5026, -2.6786],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.3366, 0.8069, 0.2632,  ..., 0.0912, 0.3362, 0.1600],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([ -1.0039, -21.0557,  -0.0409,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 1.8875, 12.3824,  0.0601,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[9, 10, 27, 39, 43, 58, 62, 71, 85, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 12879799517184.0 || Test loss: 885154840576.0\n",
      "Epoch: 1000 | | Train Loss: 12877267206144.0 || Test loss: 885113749504.0\n",
      "Client 1 prediction: mean tensor([ 0.0739,  0.0544,  0.0084,  ...,  0.0153,  0.0007, -0.0680],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0652, 0.6837, 0.0500,  ..., 0.0403, 0.0740, 0.0134],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([ 0.6424, 21.2410,  0.0716,  ...,  0.0000,  0.0000,  0.0000]), std tensor([ 1.9165, 18.3770,  0.8246,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 4593591779328.0 || Test loss: 469161410560.0\n",
      "Epoch: 1000 | | Train Loss: 4591934504960.0 || Test loss: 469080571904.0\n",
      "Client 2 prediction: mean tensor([ 0.2634,  0.6374,  0.5171,  ..., -0.1561,  0.2236, -0.1726],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.0922, 0.8999, 0.5849,  ..., 0.0213, 0.0181, 0.2549],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([ 3.7649, 62.9434,  2.6594,  ...,  0.0000,  0.0000,  0.0000]), std tensor([11.7287, 50.4038,  2.8258,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 14, 24, 34, 42, 56, 67, 74, 81, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 5941990260736.0 || Test loss: 809893167104.0\n",
      "Epoch: 1000 | | Train Loss: 5940141621248.0 || Test loss: 809706979328.0\n",
      "Client 3 prediction: mean tensor([ 0.0851,  0.1184,  0.0571,  ...,  0.0016,  0.0063, -0.0705],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.8488, 1.2163, 0.8563,  ..., 0.0153, 0.0897, 0.0427],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([ 32.5420, 171.5612,   7.8275,  ...,   0.0000,   0.0000,   0.0000]), std tensor([14.5540, 49.8717,  2.6166,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 4:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 19640371642368.0 || Test loss: 3398339133440.0\n",
      "Epoch: 1000 | | Train Loss: 19636701626368.0 || Test loss: 3397817991168.0\n",
      "Client 4 prediction: mean tensor([-0.6022, -0.5433, -0.4196,  ...,  0.2284,  0.0486,  0.3502],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.1666, 0.4778, 0.3852,  ..., 0.0398, 0.0954, 0.2347],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 4 y: mean tensor([ -9.4151, -44.9004,  -2.6706,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 3.1853, 34.8973,  0.8464,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 5:\n",
      "[1, 12, 23, 31, 43, 51, 60, 78, 84, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 2332531621888.0 || Test loss: 332329648128.0\n",
      "Epoch: 1000 | | Train Loss: 2328598675456.0 || Test loss: 332006293504.0\n",
      "Client 5 prediction: mean tensor([-2.7058, -4.6003, -4.0995,  ...,  1.2665,  4.9073, -1.5935],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.2809, 1.1484, 0.2007,  ..., 0.0445, 0.2922, 0.0853],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 5 y: mean tensor([ 0.1346, -1.5505,  0.0199,  ...,  0.0000,  0.0000,  0.0000]), std tensor([1.4510, 8.1648, 0.2825,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 6:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 81500921921536.0 || Test loss: 6893616496640.0\n",
      "Epoch: 1000 | | Train Loss: 81492088717312.0 || Test loss: 6893309263872.0\n",
      "Client 6 prediction: mean tensor([-0.3640,  0.2017, -0.0328,  ...,  0.3721,  0.3954,  0.6671],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.9102, 0.3214, 0.1367,  ..., 0.0828, 0.1535, 0.1129],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 6 y: mean tensor([-13.5050,  11.7917,  -3.9160,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 6.3752, 28.8717,  2.5137,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 7:\n",
      "[9, 15, 22, 31, 43, 57, 64, 73, 80, 98]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 3872768131072.0 || Test loss: 345993445376.0\n",
      "Epoch: 1000 | | Train Loss: 3873320730624.0 || Test loss: 346198245376.0\n",
      "Client 7 prediction: mean tensor([-2.9838, -3.0074, -2.5527,  ...,  0.1172,  3.1344, -2.5028],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.1577, 0.2342, 0.1493,  ..., 0.0140, 0.2042, 0.1570],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 7 y: mean tensor([ 0.6702,  0.3586, -0.0363,  ...,  0.0000,  0.0000,  0.0000]), std tensor([0.1943, 0.1854, 0.1076,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 8:\n",
      "[6, 13, 25, 31, 45, 53, 67, 73, 85, 93]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 4158401544192.0 || Test loss: 362670063616.0\n",
      "Epoch: 1000 | | Train Loss: 4156479504384.0 || Test loss: 362554327040.0\n",
      "Client 8 prediction: mean tensor([-0.4031, -0.2797, -0.4244,  ...,  0.1246, -0.1227,  0.2056],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.1127, 0.0553, 0.1444,  ..., 0.0557, 0.0242, 0.2872],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 8 y: mean tensor([ -0.1959, -18.9686,  -1.0923,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 0.1093, 10.3760,  0.5598,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 9:\n",
      "[5, 10, 22, 39, 42, 53, 69, 72, 88, 95]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 5138435014656.0 || Test loss: 373295382528.0\n",
      "Epoch: 1000 | | Train Loss: 5138466471936.0 || Test loss: 373487370240.0\n",
      "Client 9 prediction: mean tensor([-2.2852, -2.0777, -2.8834,  ...,  0.6539,  3.1630, -2.2069],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.7926, 1.2067, 0.4078,  ..., 0.0528, 0.0356, 0.0432],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 9 y: mean tensor([ -0.9617, -40.0041,  -0.8532,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 3.5635, 51.3920,  1.1200,  ...,  0.0000,  0.0000,  0.0000])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:79401.67, Test accuracy:80013.29, Extraction Accuracy:177765.89\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:14797.17, Test accuracy:15706.75, Extraction Accuracy:48175.98\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:0.81, Test accuracy:0.82\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 88359.6562, Training accuracy: 14797.61, Test Accuracy: 15707.17\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 59333.7422, Training accuracy: 15387.71, Test Accuracy: 16275.14\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 39878.5664, Training accuracy: 15954.71, Test Accuracy: 16824.96\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 26838.6465, Training accuracy: 16475.74, Test Accuracy: 17332.41\n",
      "Best: Gradient norm:26838.6465\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:6442012639232.00, Test loss: 667527086080.00,Training accuracy: 16475.74, Test accuracy: 17332.41, Extraction accuracy: 55692.71\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:140842.48, Test accuracy:139648.02, Extraction Accuracy:177089.88\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:174960.67, Test accuracy:174993.11, Extraction Accuracy:276304.97\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.69, Test accuracy:0.69\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 523026.2188, Training accuracy: 174960.67, Test Accuracy: 174993.11\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 173380.9844, Training accuracy: 160493.03, Test Accuracy: 159973.06\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 113827.1172, Training accuracy: 157127.23, Test Accuracy: 156478.08\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 74216.7422, Training accuracy: 153494.39, Test Accuracy: 152709.81\n",
      "Best: Gradient norm:74216.7422\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:12876980944896.00, Test loss: 884953710592.00,Training accuracy: 153494.39, Test accuracy: 152709.81, Extraction accuracy: 215366.73\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:69724.30, Test accuracy:76395.30, Extraction Accuracy:86881.62\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:89527.34, Test accuracy:95776.28, Extraction Accuracy:146872.06\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.74, Test accuracy:0.70\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1134744.6250, Training accuracy: 89527.34, Test Accuracy: 95776.28\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1676274.5000, Training accuracy: 74925.41, Test Accuracy: 81937.53\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1123518.7500, Training accuracy: 84324.79, Test Accuracy: 91617.26\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 753075.8125, Training accuracy: 96775.52, Test Accuracy: 104207.55\n",
      "Best: Gradient norm:753075.8125\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:4589523304448.00, Test loss: 468789428224.00,Training accuracy: 96775.52, Test accuracy: 104207.55, Extraction accuracy: 12215.42\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:65413.02, Test accuracy:64274.80, Extraction Accuracy:73719.09\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:90892.76, Test accuracy:89587.95, Extraction Accuracy:106090.90\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.83, Test accuracy:0.83\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 842035.2500, Training accuracy: 90892.76, Test Accuracy: 89587.95\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 399839.8125, Training accuracy: 90472.50, Test Accuracy: 90269.47\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 262536.9062, Training accuracy: 160608.73, Test Accuracy: 159622.08\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 172516.1875, Training accuracy: 7445501.50, Test Accuracy: 7273097.00\n",
      "Best: Gradient norm:172516.1875\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:5937539055616.00, Test loss: 809422618624.00,Training accuracy: 7445501.50, Test accuracy: 7273097.00, Extraction accuracy: 8578185.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:4, Training accuracy:397842.03, Test accuracy:412852.84, Extraction Accuracy:337410.84\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:4, Training accuracy:405240.44, Test accuracy:420512.69, Extraction Accuracy:351335.78\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:4, Training accuracy:0.77, Test accuracy:0.77\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1749210.3750, Training accuracy: 405240.44, Test Accuracy: 420512.69\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1135184.1250, Training accuracy: 427542.25, Test Accuracy: 444750.91\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 730307.3750, Training accuracy: 435320.84, Test Accuracy: 452510.66\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 489609.0625, Training accuracy: 12168009.00, Test Accuracy: 12637233.00\n",
      "Best: Gradient norm:468278.1875\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:4, Used Gradient Network Train loss:19631339208704.00, Test loss: 3397135106048.00,Training accuracy: 12168009.00, Test accuracy: 12637233.00, Extraction accuracy: 16967912.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:5, Training accuracy:34405.09, Test accuracy:36681.64, Extraction Accuracy:132159.97\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:5, Training accuracy:28069.14, Test accuracy:30516.55, Extraction Accuracy:117982.30\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:5, Training accuracy:0.38, Test accuracy:0.39\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1778252.0000, Training accuracy: 28069.14, Test Accuracy: 30516.55\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1272602.5000, Training accuracy: 55414.99, Test Accuracy: 57365.94\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 852552.4375, Training accuracy: 75775.14, Test Accuracy: 77421.33\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 571165.8750, Training accuracy: 88783.85, Test Accuracy: 90282.52\n",
      "Best: Gradient norm:571165.8750\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:5, Used Gradient Network Train loss:2328598675456.00, Test loss: 332006293504.00,Training accuracy: 88783.85, Test accuracy: 90282.52, Extraction accuracy: 4338.96\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:6, Training accuracy:808386.88, Test accuracy:837711.31, Extraction Accuracy:403058.62\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:6, Training accuracy:1284163.75, Test accuracy:1311131.12, Extraction Accuracy:1935413.50\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:6, Training accuracy:0.89, Test accuracy:0.89\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1761257.6250, Training accuracy: 1284163.75, Test Accuracy: 1311131.12\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1225638.7500, Training accuracy: 1324529.75, Test Accuracy: 1351732.38\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 828241.0625, Training accuracy: 1425676.00, Test Accuracy: 1454289.00\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 514537.5312, Training accuracy: 1556546.38, Test Accuracy: 1586979.00\n",
      "Best: Gradient norm:514537.5312\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:6, Used Gradient Network Train loss:81485344276480.00, Test loss: 6892545376256.00,Training accuracy: 1556546.38, Test accuracy: 1586979.00, Extraction accuracy: 2510538.50\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:7, Training accuracy:100576.92, Test accuracy:101628.18, Extraction Accuracy:263317.22\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:7, Training accuracy:72138.99, Test accuracy:71483.80, Extraction Accuracy:184662.55\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:7, Training accuracy:0.46, Test accuracy:0.51\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 15146.4756, Training accuracy: 72138.99, Test Accuracy: 71483.80\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 10261.2617, Training accuracy: 72494.93, Test Accuracy: 71872.13\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 6987.3413, Training accuracy: 72799.63, Test Accuracy: 72203.52\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 4793.0137, Training accuracy: 73058.02, Test Accuracy: 72483.86\n",
      "Best: Gradient norm:4793.0137\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:7, Used Gradient Network Train loss:3870709252096.00, Test loss: 345869778944.00,Training accuracy: 73058.02, Test accuracy: 72483.86, Extraction accuracy: 190512.59\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:8, Training accuracy:157121.14, Test accuracy:155715.92, Extraction Accuracy:332999.72\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:8, Training accuracy:148116.98, Test accuracy:145469.06, Extraction Accuracy:380546.88\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:8, Training accuracy:0.81, Test accuracy:0.80\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1747595.0000, Training accuracy: 148116.98, Test Accuracy: 145469.06\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1782914.0000, Training accuracy: 226117.42, Test Accuracy: 231898.58\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1194943.5000, Training accuracy: 296589.22, Test Accuracy: 303963.84\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 800892.3125, Training accuracy: 336536.75, Test Accuracy: 344484.03\n",
      "Best: Gradient norm:800892.3125\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:8, Used Gradient Network Train loss:4153896861696.00, Test loss: 362288054272.00,Training accuracy: 336536.75, Test accuracy: 344484.03, Extraction accuracy: 20894.77\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:9, Training accuracy:60392.04, Test accuracy:60380.44, Extraction Accuracy:168611.16\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:9, Training accuracy:56926.99, Test accuracy:56769.21, Extraction Accuracy:155250.95\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:9, Training accuracy:0.79, Test accuracy:0.81\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 3313.7251, Training accuracy: 56926.99, Test Accuracy: 56769.21\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 2351.9780, Training accuracy: 57826.11, Test Accuracy: 57670.35\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1707.3981, Training accuracy: 58678.39, Test Accuracy: 58524.14\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 1275.5326, Training accuracy: 59424.82, Test Accuracy: 59271.99\n",
      "Best: Gradient norm:1275.5326\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:9, Used Gradient Network Train loss:5135793651712.00, Test loss: 373199306752.00,Training accuracy: 59424.82, Test accuracy: 59271.99, Extraction accuracy: 168842.30\n",
      "rm logs/none/experiment_flightPrices_bz_510_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_2_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 510 --num_local_steps 2 --device \"cpu\" --gnetwork_num_epochs 1001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 128 --start_point global_model --decoded_epochs 3001 --model neuralReg --fit_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-20 14:24:50.427 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:30685 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-20 14:24:50.563 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:30685 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\t Round: 1 |Train Loss: 133537.961 | Train evalMetric: -12.32%\n",
      "\t Round: 2 |Train Loss: 137843.698 | Train evalMetric: -16.09%\n",
      "\t Round: 3 |Train Loss: 115689.478 | Train evalMetric: 2.93%\n",
      "\t Round: 4 |Train Loss: 114816.501 | Train evalMetric: 3.67%\n",
      "\t Round: 5 |Train Loss: 114885.897 | Train evalMetric: 3.31%\n",
      "\t Round: 6 |Train Loss: 126446.103 | Train evalMetric: -6.85%\n",
      "\t Round: 7 |Train Loss: 145990.043 | Train evalMetric: -23.92%\n",
      "\t Round: 8 |Train Loss: 146522.311 | Train evalMetric: -24.48%\n",
      "\t Round: 9 |Train Loss: 216459.147 | Train evalMetric: -85.32%\n",
      "\t Round: 10 |Train Loss: 115822.605 | Train evalMetric: 2.18%\n",
      "\t Round: 11 |Train Loss: 76383.790 | Train evalMetric: 36.39%\n",
      "\t Round: 12 |Train Loss: 52952.540 | Train evalMetric: 56.36%\n",
      "\t Round: 13 |Train Loss: 69199.260 | Train evalMetric: 42.58%\n",
      "\t Round: 14 |Train Loss: 165403.170 | Train evalMetric: -40.74%\n",
      "\t Round: 15 |Train Loss: 97488.528 | Train evalMetric: 17.94%\n",
      "\t Round: 16 |Train Loss: 111417.773 | Train evalMetric: 5.73%\n",
      "\t Round: 17 |Train Loss: 72406.379 | Train evalMetric: 39.71%\n",
      "\t Round: 18 |Train Loss: 84198.362 | Train evalMetric: 29.65%\n",
      "\t Round: 19 |Train Loss: 70128.514 | Train evalMetric: 41.64%\n",
      "\t Round: 20 |Train Loss: 89357.720 | Train evalMetric: 25.05%\n",
      "\t Round: 21 |Train Loss: 48837.429 | Train evalMetric: 59.76%\n",
      "\t Round: 22 |Train Loss: 104003.532 | Train evalMetric: 12.15%\n",
      "\t Round: 23 |Train Loss: 96128.934 | Train evalMetric: 19.28%\n",
      "\t Round: 24 |Train Loss: 49457.959 | Train evalMetric: 59.23%\n",
      "\t Round: 25 |Train Loss: 59054.395 | Train evalMetric: 51.07%\n",
      "\t Round: 26 |Train Loss: 98571.358 | Train evalMetric: 17.06%\n",
      "\t Round: 27 |Train Loss: 68814.850 | Train evalMetric: 42.55%\n",
      "\t Round: 28 |Train Loss: 50806.643 | Train evalMetric: 58.17%\n",
      "\t Round: 29 |Train Loss: 114799.938 | Train evalMetric: 2.92%\n",
      "\t Round: 30 |Train Loss: 66514.575 | Train evalMetric: 44.96%\n",
      "\t Round: 31 |Train Loss: 51103.974 | Train evalMetric: 57.90%\n",
      "\t Round: 32 |Train Loss: 92274.201 | Train evalMetric: 22.43%\n",
      "\t Round: 33 |Train Loss: 63968.096 | Train evalMetric: 46.91%\n",
      "\t Round: 34 |Train Loss: 56841.063 | Train evalMetric: 53.03%\n",
      "\t Round: 35 |Train Loss: 62389.238 | Train evalMetric: 48.06%\n",
      "\t Round: 36 |Train Loss: 59414.731 | Train evalMetric: 50.79%\n",
      "\t Round: 37 |Train Loss: 55814.953 | Train evalMetric: 53.88%\n",
      "\t Round: 38 |Train Loss: 68602.037 | Train evalMetric: 42.91%\n",
      "\t Round: 39 |Train Loss: 86001.708 | Train evalMetric: 28.01%\n",
      "\t Round: 40 |Train Loss: 62394.668 | Train evalMetric: 48.05%\n",
      "\t Round: 41 |Train Loss: 49851.411 | Train evalMetric: 58.90%\n",
      "\t Round: 42 |Train Loss: 49982.525 | Train evalMetric: 58.83%\n",
      "\t Round: 43 |Train Loss: 94605.521 | Train evalMetric: 20.46%\n",
      "\t Round: 44 |Train Loss: 54977.507 | Train evalMetric: 54.46%\n",
      "\t Round: 45 |Train Loss: 66885.858 | Train evalMetric: 44.36%\n",
      "\t Round: 46 |Train Loss: 86419.313 | Train evalMetric: 27.43%\n",
      "\t Round: 47 |Train Loss: 54915.286 | Train evalMetric: 54.72%\n",
      "\t Round: 48 |Train Loss: 61077.736 | Train evalMetric: 49.21%\n",
      "\t Round: 49 |Train Loss: 72446.997 | Train evalMetric: 39.77%\n",
      "\t Round: 50 |Train Loss: 46675.799 | Train evalMetric: 61.62%\n",
      "\t Round: 51 |Train Loss: 49402.937 | Train evalMetric: 59.08%\n",
      "\t Round: 52 |Train Loss: 48621.954 | Train evalMetric: 59.96%\n",
      "\t Round: 53 |Train Loss: 54577.039 | Train evalMetric: 54.97%\n",
      "\t Round: 54 |Train Loss: 44062.037 | Train evalMetric: 63.66%\n",
      "\t Round: 55 |Train Loss: 60982.837 | Train evalMetric: 49.44%\n",
      "\t Round: 56 |Train Loss: 49616.351 | Train evalMetric: 59.10%\n",
      "\t Round: 57 |Train Loss: 57271.566 | Train evalMetric: 52.69%\n",
      "\t Round: 58 |Train Loss: 55118.173 | Train evalMetric: 54.49%\n",
      "\t Round: 59 |Train Loss: 60855.144 | Train evalMetric: 49.64%\n",
      "\t Round: 60 |Train Loss: 48434.433 | Train evalMetric: 60.15%\n",
      "\t Round: 61 |Train Loss: 96048.313 | Train evalMetric: 19.11%\n",
      "\t Round: 62 |Train Loss: 45230.817 | Train evalMetric: 62.88%\n",
      "\t Round: 63 |Train Loss: 53719.104 | Train evalMetric: 55.77%\n",
      "\t Round: 64 |Train Loss: 56904.729 | Train evalMetric: 53.01%\n",
      "\t Round: 65 |Train Loss: 48678.815 | Train evalMetric: 59.91%\n",
      "\t Round: 66 |Train Loss: 50917.007 | Train evalMetric: 58.00%\n",
      "\t Round: 67 |Train Loss: 65087.856 | Train evalMetric: 45.52%\n",
      "\t Round: 68 |Train Loss: 73551.235 | Train evalMetric: 38.68%\n",
      "\t Round: 69 |Train Loss: 52176.722 | Train evalMetric: 56.92%\n",
      "\t Round: 70 |Train Loss: 42489.657 | Train evalMetric: 64.80%\n",
      "\t Round: 71 |Train Loss: 57598.851 | Train evalMetric: 52.06%\n",
      "\t Round: 72 |Train Loss: 56186.783 | Train evalMetric: 53.46%\n",
      "\t Round: 73 |Train Loss: 46327.567 | Train evalMetric: 61.87%\n",
      "\t Round: 74 |Train Loss: 44772.539 | Train evalMetric: 62.99%\n",
      "\t Round: 75 |Train Loss: 43802.846 | Train evalMetric: 63.85%\n",
      "\t Round: 76 |Train Loss: 42234.153 | Train evalMetric: 64.86%\n",
      "\t Round: 77 |Train Loss: 48055.013 | Train evalMetric: 60.47%\n",
      "\t Round: 78 |Train Loss: 59447.325 | Train evalMetric: 50.58%\n",
      "\t Round: 79 |Train Loss: 44977.650 | Train evalMetric: 62.93%\n",
      "\t Round: 80 |Train Loss: 44485.440 | Train evalMetric: 63.22%\n",
      "\t Round: 81 |Train Loss: 52156.626 | Train evalMetric: 56.97%\n",
      "\t Round: 82 |Train Loss: 42764.111 | Train evalMetric: 64.54%\n",
      "\t Round: 83 |Train Loss: 43246.829 | Train evalMetric: 64.34%\n",
      "\t Round: 84 |Train Loss: 46997.770 | Train evalMetric: 61.14%\n",
      "\t Round: 85 |Train Loss: 48162.456 | Train evalMetric: 60.36%\n",
      "\t Round: 86 |Train Loss: 49942.904 | Train evalMetric: 58.85%\n",
      "\t Round: 87 |Train Loss: 48185.841 | Train evalMetric: 60.27%\n",
      "\t Round: 88 |Train Loss: 42787.696 | Train evalMetric: 64.62%\n",
      "\t Round: 89 |Train Loss: 44203.080 | Train evalMetric: 63.64%\n",
      "\t Round: 90 |Train Loss: 46942.933 | Train evalMetric: 61.40%\n",
      "\t Round: 91 |Train Loss: 46807.762 | Train evalMetric: 61.49%\n",
      "\t Round: 92 |Train Loss: 75886.125 | Train evalMetric: 36.81%\n",
      "\t Round: 93 |Train Loss: 44384.062 | Train evalMetric: 63.50%\n",
      "\t Round: 94 |Train Loss: 51309.317 | Train evalMetric: 57.67%\n",
      "\t Round: 95 |Train Loss: 42262.157 | Train evalMetric: 64.98%\n",
      "\t Round: 96 |Train Loss: 57153.621 | Train evalMetric: 52.76%\n",
      "\t Round: 97 |Train Loss: 54931.508 | Train evalMetric: 54.62%\n",
      "\t Round: 98 |Train Loss: 42255.977 | Train evalMetric: 65.16%\n",
      "\t Round: 99 |Train Loss: 41693.330 | Train evalMetric: 65.44%\n",
      "\t Round: 100 |Train Loss: 43200.604 | Train evalMetric: 64.24%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.8296400258205577, test_acc:0.8490928223433436\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.6884313737543813, test_acc:0.6802012398487886\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.7495490016096069, test_acc:0.7088825014209181\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.8397517411191587, test_acc:0.8453278550005249\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.7324143491512981, test_acc:0.7329646549616671\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:-inf, test_acc:-0.04861791948329525\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.577384401726349, test_acc:0.5614931536174236\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.474929814558328, test_acc:0.5246107817081335\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.7404812572928036, test_acc:0.751064973146001\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7814828839408751, test_acc:0.8031151326234339\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:116033.9453125, test_acc:116695.046875, Extrac_acc:235802.4375\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:14933.53515625, test_acc:15852.9462890625, Extrac_acc:50499.671875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:148281.125, test_acc:147322.609375, Extrac_acc:228960.9375\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:175083.84375, test_acc:175150.03125, Extrac_acc:298982.625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:71419.8359375, test_acc:77899.5, Extrac_acc:108532.0703125\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:84440.203125, test_acc:90837.6015625, Extrac_acc:128866.8515625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:69974.9453125, test_acc:68826.4609375, Extrac_acc:95839.65625\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:109681.9453125, test_acc:108054.640625, Extrac_acc:180251.875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:413326.4375, test_acc:427585.78125, Extrac_acc:439540.65625\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:593981.0, test_acc:609149.1875, Extrac_acc:982332.6875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:47069.91796875, test_acc:48942.90625, Extrac_acc:179440.046875\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:31949.513671875, test_acc:34303.39453125, Extrac_acc:150763.5625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:810999.375, test_acc:838177.8125, Extrac_acc:532098.6875\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:1031499.3125, test_acc:1055182.375, Extrac_acc:1374800.75\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:128280.390625, test_acc:130228.40625, Extrac_acc:341177.25\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:72720.96875, test_acc:72098.984375, Extrac_acc:194213.28125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:172452.484375, test_acc:168023.15625, Extrac_acc:459944.3125\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:152360.5, test_acc:148134.359375, Extrac_acc:458395.59375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:71001.8515625, test_acc:71173.5703125, Extrac_acc:212573.703125\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:53012.3125, test_acc:52801.70703125, Extrac_acc:133284.0\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 5981522100224.0 || Test loss: 661524250624.0\n",
      "Epoch: 1000 | | Train Loss: 5979980169216.0 || Test loss: 661374894080.0\n",
      "Client 0 prediction: mean tensor([-0.0241,  0.1502,  0.0222,  ...,  0.0464,  0.0287, -0.0328],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.0011, 1.0691, 0.5784,  ..., 0.0385, 0.0671, 0.1002],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([ -1.8038, -28.3210,  -0.0591,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 2.2809, 15.9392,  0.0622,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[9, 10, 27, 39, 43, 58, 62, 71, 85, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 13001460547584.0 || Test loss: 1149307715584.0\n",
      "Epoch: 1000 | | Train Loss: 12998801358848.0 || Test loss: 1149228941312.0\n",
      "Client 1 prediction: mean tensor([ 0.0226,  0.0522,  0.0753,  ...,  0.0419,  0.0039, -0.0355],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.1065, 1.3062, 0.1683,  ..., 0.0383, 0.0397, 0.0186],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([ 0.7075, 24.5404,  0.0783,  ...,  0.0000,  0.0000,  0.0000]), std tensor([ 2.0954, 18.4080,  0.8825,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 5088912343040.0 || Test loss: 414439735296.0\n",
      "Epoch: 1000 | | Train Loss: 5087262932992.0 || Test loss: 414378426368.0\n",
      "Client 2 prediction: mean tensor([-0.0624,  0.2232,  0.2126,  ..., -0.0340, -0.0287, -0.1049],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.2811, 0.9164, 0.5159,  ..., 0.0568, 0.0250, 0.0534],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([ 3.5427, 72.4359,  2.9747,  ...,  0.0000,  0.0000,  0.0000]), std tensor([13.3457, 52.9618,  2.9317,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 14, 24, 34, 42, 56, 67, 74, 81, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 6378475749376.0 || Test loss: 843127390208.0\n",
      "Epoch: 1000 | | Train Loss: 6376684781568.0 || Test loss: 842893754368.0\n",
      "Client 3 prediction: mean tensor([ 0.0745,  0.0727, -0.0265,  ...,  0.0049,  0.0388, -0.2639],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.5723, 0.8420, 0.2021,  ..., 0.0203, 0.0495, 0.0541],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([ 34.2100, 191.7170,   8.5022,  ...,   0.0000,   0.0000,   0.0000]), std tensor([14.6837, 53.5369,  2.6240,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 4:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 19476342898688.0 || Test loss: 3522312798208.0\n",
      "Epoch: 1000 | | Train Loss: 19473291542528.0 || Test loss: 3521861648384.0\n",
      "Client 4 prediction: mean tensor([ 0.0553,  0.0892,  0.0786,  ..., -0.0023, -0.0015, -0.0461],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.5984, 0.6160, 0.2630,  ..., 0.0213, 0.0535, 0.0815],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 4 y: mean tensor([-10.4096, -47.1673,  -3.0438,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 5.2072, 35.8711,  1.3906,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 5:\n",
      "[1, 12, 23, 31, 43, 51, 60, 78, 84, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 2761014640640.0 || Test loss: 399056961536.0\n",
      "Epoch: 1000 | | Train Loss: 2759391707136.0 || Test loss: 398929035264.0\n",
      "Client 5 prediction: mean tensor([-0.0031,  0.0019, -0.0135,  ...,  0.0484, -0.0493, -0.0832],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.3030, 0.5066, 0.1100,  ..., 0.0346, 0.0873, 0.0879],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 5 y: mean tensor([-0.3659, -4.0209, -0.0760,  ...,  0.0000,  0.0000,  0.0000]), std tensor([2.0489, 9.4832, 0.3908,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 6:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 103137868251136.0 || Test loss: 8923174141952.0\n",
      "Epoch: 1000 | | Train Loss: 103130570162176.0 || Test loss: 8923018952704.0\n",
      "Client 6 prediction: mean tensor([-0.7448,  0.0162,  0.3388,  ..., -0.3675, -0.4517, -0.4856],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.1882, 1.0674, 0.1721,  ..., 0.0491, 0.2301, 0.0878],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 6 y: mean tensor([-16.7652,   5.2414,  -5.0375,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 8.8090, 30.7228,  3.1486,  ...,  0.0000,  0.0000,  0.0000])\n",
      "Starting getting gradient network of Worker 7:\n",
      "[9, 15, 22, 31, 43, 57, 64, 73, 80, 98]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 3933259431936.0 || Test loss: 453563908096.0\n",
      "Epoch: 1000 | | Train Loss: 3930930282496.0 || Test loss: 453355831296.0\n",
      "Client 7 prediction: mean tensor([-0.1448,  0.4265,  0.1108,  ...,  0.0153,  0.0611, -0.3163],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.2268, 0.1397, 0.0329,  ..., 0.0204, 0.0947, 0.0509],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 7 y: mean tensor([ 0.7542,  0.4539, -0.0682,  ...,  0.0000,  0.0000,  0.0000]), std tensor([0.2168, 0.2684, 0.0961,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 8:\n",
      "[6, 13, 25, 31, 45, 53, 67, 73, 85, 93]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 4908816269312.0 || Test loss: 305876271104.0\n",
      "Epoch: 1000 | | Train Loss: 4906851237888.0 || Test loss: 305841864704.0\n",
      "Client 8 prediction: mean tensor([ 0.0854,  0.0314, -0.0137,  ...,  0.0050, -0.0168, -0.0941],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.0707, 0.2794, 0.2353,  ..., 0.0242, 0.0228, 0.1872],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 8 y: mean tensor([ -0.2128, -21.7130,  -1.2451,  ...,   0.0000,   0.0000,   0.0000]), std tensor([0.1394, 9.7611, 0.5478,  ..., 0.0000, 0.0000, 0.0000])\n",
      "Starting getting gradient network of Worker 9:\n",
      "[5, 10, 22, 39, 42, 53, 69, 72, 88, 95]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 5544770273280.0 || Test loss: 320174751744.0\n",
      "Epoch: 1000 | | Train Loss: 5542172950528.0 || Test loss: 320127107072.0\n",
      "Client 9 prediction: mean tensor([-0.0084, -0.0376,  0.0143,  ...,  0.0103, -0.0393, -0.0649],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.3410, 1.5361, 0.5868,  ..., 0.0225, 0.0165, 0.0377],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 9 y: mean tensor([ -2.7494, -52.1363,  -1.3007,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 5.1508, 51.7654,  1.0396,  ...,  0.0000,  0.0000,  0.0000])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:116033.95, Test accuracy:116695.05, Extraction Accuracy:235802.44\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:14933.54, Test accuracy:15852.95, Extraction Accuracy:50499.67\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:0.83, Test accuracy:0.85\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1102430.8750, Training accuracy: 14933.54, Test Accuracy: 15852.95\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 705788.1875, Training accuracy: 14955.10, Test Accuracy: 15931.34\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 455475.0000, Training accuracy: 21181534.00, Test Accuracy: 22624444.00\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 382022.9375, Training accuracy: 6619125.00, Test Accuracy: 7287730.00\n",
      "Best: Gradient norm:346243.8750\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:5977388089344.00, Test loss: 661070413824.00,Training accuracy: 6619125.00, Test accuracy: 7287730.00, Extraction accuracy: 7959812.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:148281.12, Test accuracy:147322.61, Extraction Accuracy:228960.94\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:175083.84, Test accuracy:175150.03, Extraction Accuracy:298982.62\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.69, Test accuracy:0.68\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 794461.3125, Training accuracy: 175083.84, Test Accuracy: 175150.03\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 450850.0625, Training accuracy: 206356.97, Test Accuracy: 207043.39\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 300869.1250, Training accuracy: 398605.94, Test Accuracy: 404578.78\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 200760.7500, Training accuracy: 774287.12, Test Accuracy: 791007.88\n",
      "Best: Gradient norm:200760.7500\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:12994957279232.00, Test loss: 1148764028928.00,Training accuracy: 774287.12, Test accuracy: 791007.88, Extraction accuracy: 1526208.25\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:71419.84, Test accuracy:77899.50, Extraction Accuracy:108532.07\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:84440.20, Test accuracy:90837.60, Extraction Accuracy:128866.85\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.75, Test accuracy:0.71\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1306840.2500, Training accuracy: 84440.20, Test Accuracy: 90837.60\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1574503.0000, Training accuracy: 76394.34, Test Accuracy: 82892.37\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 1055294.5000, Training accuracy: 70116.69, Test Accuracy: 76706.14\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 707322.0625, Training accuracy: 65954.55, Test Accuracy: 72638.77\n",
      "Best: Gradient norm:707322.0625\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:5084142370816.00, Test loss: 414075092992.00,Training accuracy: 65954.55, Test accuracy: 72638.77, Extraction accuracy: 91601.12\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:69974.95, Test accuracy:68826.46, Extraction Accuracy:95839.66\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:109681.95, Test accuracy:108054.64, Extraction Accuracy:180251.88\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.84, Test accuracy:0.85\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 931073.0000, Training accuracy: 109681.95, Test Accuracy: 108054.64\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 418632.9375, Training accuracy: 126529.29, Test Accuracy: 125031.61\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 279891.1250, Training accuracy: 176899.12, Test Accuracy: 174501.55\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 187373.7188, Training accuracy: 246143.02, Test Accuracy: 242415.27\n",
      "Best: Gradient norm:187373.7188\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:6372959715328.00, Test loss: 842497327104.00,Training accuracy: 246143.02, Test accuracy: 242415.27, Extraction accuracy: 443902.88\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:4, Training accuracy:413326.44, Test accuracy:427585.78, Extraction Accuracy:439540.66\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:4, Training accuracy:593981.00, Test accuracy:609149.19, Extraction Accuracy:982332.69\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:4, Training accuracy:0.73, Test accuracy:0.73\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1860313.5000, Training accuracy: 593981.00, Test Accuracy: 609149.19\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1239978.0000, Training accuracy: 591342.75, Test Accuracy: 604522.19\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 826112.5000, Training accuracy: 618872.81, Test Accuracy: 630036.12\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 550228.5625, Training accuracy: 664577.25, Test Accuracy: 674165.19\n",
      "Best: Gradient norm:550228.5625\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:4, Used Gradient Network Train loss:19468365332480.00, Test loss: 3521329233920.00,Training accuracy: 664577.25, Test accuracy: 674165.19, Extraction accuracy: 1233879.75\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:5, Training accuracy:47069.92, Test accuracy:48942.91, Extraction Accuracy:179440.05\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:5, Training accuracy:31949.51, Test accuracy:34303.39, Extraction Accuracy:150763.56\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:5, Training accuracy:-inf, Test accuracy:-0.05\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1748612.1250, Training accuracy: 31949.51, Test Accuracy: 34303.39\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 1111781.3750, Training accuracy: 33040.95, Test Accuracy: 35459.79\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 705992.6875, Training accuracy: 41951.09, Test Accuracy: 44327.12\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 448347.0625, Training accuracy: 56286.80, Test Accuracy: 58450.91\n",
      "Best: Gradient norm:448347.0625\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:5, Used Gradient Network Train loss:2757249990656.00, Test loss: 398708375552.00,Training accuracy: 56286.80, Test accuracy: 58450.91, Extraction accuracy: 20057.21\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:6, Training accuracy:810999.38, Test accuracy:838177.81, Extraction Accuracy:532098.69\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:6, Training accuracy:1031499.31, Test accuracy:1055182.38, Extraction Accuracy:1374800.75\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:6, Training accuracy:0.58, Test accuracy:0.56\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 8105788.5000, Training accuracy: 1031499.31, Test Accuracy: 1055182.38\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 5474486.5000, Training accuracy: 1022743.44, Test Accuracy: 1046430.38\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 3685584.0000, Training accuracy: 1014041.69, Test Accuracy: 1037729.56\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 2472698.2500, Training accuracy: 1007125.88, Test Accuracy: 1030815.88\n",
      "Best: Gradient norm:2472698.2500\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:6, Used Gradient Network Train loss:103130167508992.00, Test loss: 8922942406656.00,Training accuracy: 1007125.88, Test accuracy: 1030815.88, Extraction accuracy: 1312816.50\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:7, Training accuracy:128280.39, Test accuracy:130228.41, Extraction Accuracy:341177.25\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:7, Training accuracy:72720.97, Test accuracy:72098.98, Extraction Accuracy:194213.28\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:7, Training accuracy:0.47, Test accuracy:0.52\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 953001.3125, Training accuracy: 72720.97, Test Accuracy: 72098.98\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 587471.3750, Training accuracy: 100795.67, Test Accuracy: 98353.13\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 393487.7812, Training accuracy: 128015.95, Test Accuracy: 124845.25\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 263588.8125, Training accuracy: 141745.20, Test Accuracy: 137978.75\n",
      "Best: Gradient norm:263588.8125\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:7, Used Gradient Network Train loss:3928667193344.00, Test loss: 453110497280.00,Training accuracy: 141745.20, Test accuracy: 137978.75, Extraction accuracy: 15269.13\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:8, Training accuracy:172452.48, Test accuracy:168023.16, Extraction Accuracy:459944.31\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:8, Training accuracy:152360.50, Test accuracy:148134.36, Extraction Accuracy:458395.59\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:8, Training accuracy:0.74, Test accuracy:0.75\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 947588.1250, Training accuracy: 152360.50, Test Accuracy: 148134.36\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 473910.3438, Training accuracy: 262889.81, Test Accuracy: 249514.77\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 317104.9375, Training accuracy: 457476.44, Test Accuracy: 435067.47\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 212201.4688, Training accuracy: 699150.56, Test Accuracy: 668594.62\n",
      "Best: Gradient norm:212201.4688\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:8, Used Gradient Network Train loss:4905144680448.00, Test loss: 305661968384.00,Training accuracy: 699150.56, Test accuracy: 668594.62, Extraction accuracy: 1514487.62\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:9, Training accuracy:71001.85, Test accuracy:71173.57, Extraction Accuracy:212573.70\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:9, Training accuracy:53012.31, Test accuracy:52801.71, Extraction Accuracy:133284.00\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:9, Training accuracy:0.78, Test accuracy:0.80\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1805.3613, Training accuracy: 53012.31, Test Accuracy: 52801.71\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 11247.9980, Training accuracy: 54295.72, Test Accuracy: 54110.60\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 7657.7427, Training accuracy: 54480.09, Test Accuracy: 54293.60\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 5251.6626, Training accuracy: 54640.86, Test Accuracy: 54453.21\n",
      "Best: Gradient norm:1805.3613\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:9, Used Gradient Network Train loss:5542172950528.00, Test loss: 320127107072.00,Training accuracy: 54640.86, Test accuracy: 54453.21, Extraction accuracy: 144535.78\n",
      "rm logs/none/experiment_flightPrices_bz_256_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_1_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 256 --num_local_steps 1 --device \"cpu\" --gnetwork_num_epochs 1001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 128 --start_point global_model --decoded_epochs 3001 --model neuralReg --fit_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-20 21:38:37.043 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:16568 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-20 21:38:37.180 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:16568 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\t Round: 1 |Train Loss: 120997.294 | Train evalMetric: -1.36%\n",
      "\t Round: 2 |Train Loss: 139409.047 | Train evalMetric: -17.43%\n",
      "\t Round: 3 |Train Loss: 81382.220 | Train evalMetric: 32.14%\n",
      "\t Round: 4 |Train Loss: 50507.850 | Train evalMetric: 58.21%\n",
      "\t Round: 5 |Train Loss: 190062.619 | Train evalMetric: -60.83%\n",
      "\t Round: 6 |Train Loss: 77515.952 | Train evalMetric: 35.30%\n",
      "\t Round: 7 |Train Loss: 53510.445 | Train evalMetric: 55.64%\n",
      "\t Round: 8 |Train Loss: 62597.778 | Train evalMetric: 47.98%\n",
      "\t Round: 9 |Train Loss: 66927.114 | Train evalMetric: 44.37%\n",
      "\t Round: 10 |Train Loss: 58984.489 | Train evalMetric: 51.02%\n",
      "\t Round: 11 |Train Loss: 48080.218 | Train evalMetric: 60.20%\n",
      "\t Round: 12 |Train Loss: 50739.339 | Train evalMetric: 57.99%\n",
      "\t Round: 13 |Train Loss: 56492.649 | Train evalMetric: 53.13%\n",
      "\t Round: 14 |Train Loss: 44648.384 | Train evalMetric: 62.92%\n",
      "\t Round: 15 |Train Loss: 55038.255 | Train evalMetric: 54.39%\n",
      "\t Round: 16 |Train Loss: 58147.380 | Train evalMetric: 51.71%\n",
      "\t Round: 17 |Train Loss: 43685.474 | Train evalMetric: 63.79%\n",
      "\t Round: 18 |Train Loss: 49684.218 | Train evalMetric: 58.86%\n",
      "\t Round: 19 |Train Loss: 45854.405 | Train evalMetric: 62.00%\n",
      "\t Round: 20 |Train Loss: 76949.799 | Train evalMetric: 35.83%\n",
      "\t Round: 21 |Train Loss: 45467.169 | Train evalMetric: 62.27%\n",
      "\t Round: 22 |Train Loss: 44918.351 | Train evalMetric: 62.75%\n",
      "\t Round: 23 |Train Loss: 43028.235 | Train evalMetric: 64.21%\n",
      "\t Round: 24 |Train Loss: 43645.746 | Train evalMetric: 63.79%\n",
      "\t Round: 25 |Train Loss: 47429.200 | Train evalMetric: 60.76%\n",
      "\t Round: 26 |Train Loss: 45381.280 | Train evalMetric: 62.35%\n",
      "\t Round: 27 |Train Loss: 68640.445 | Train evalMetric: 42.76%\n",
      "\t Round: 28 |Train Loss: 45055.469 | Train evalMetric: 62.64%\n",
      "\t Round: 29 |Train Loss: 43069.622 | Train evalMetric: 64.31%\n",
      "\t Round: 30 |Train Loss: 42487.444 | Train evalMetric: 64.67%\n",
      "\t Round: 31 |Train Loss: 43523.694 | Train evalMetric: 63.83%\n",
      "\t Round: 32 |Train Loss: 42707.995 | Train evalMetric: 64.46%\n",
      "\t Round: 33 |Train Loss: 54925.146 | Train evalMetric: 54.38%\n",
      "\t Round: 34 |Train Loss: 42481.791 | Train evalMetric: 64.73%\n",
      "\t Round: 35 |Train Loss: 43216.162 | Train evalMetric: 64.19%\n",
      "\t Round: 36 |Train Loss: 43957.003 | Train evalMetric: 63.55%\n",
      "\t Round: 37 |Train Loss: 42385.142 | Train evalMetric: 64.84%\n",
      "\t Round: 38 |Train Loss: 41703.469 | Train evalMetric: 65.40%\n",
      "\t Round: 39 |Train Loss: 41788.017 | Train evalMetric: 65.22%\n",
      "\t Round: 40 |Train Loss: 42506.658 | Train evalMetric: 64.75%\n",
      "\t Round: 41 |Train Loss: 42016.909 | Train evalMetric: 65.16%\n",
      "\t Round: 42 |Train Loss: 107500.387 | Train evalMetric: 9.90%\n",
      "\t Round: 60 |Train Loss: 45410.974 | Train evalMetric: 62.39%\n",
      "\t Round: 61 |Train Loss: 42050.782 | Train evalMetric: 64.97%\n",
      "\t Round: 62 |Train Loss: 41847.766 | Train evalMetric: 65.14%\n",
      "\t Round: 63 |Train Loss: 43025.130 | Train evalMetric: 64.24%\n",
      "\t Round: 64 |Train Loss: 42505.001 | Train evalMetric: 64.51%\n",
      "\t Round: 65 |Train Loss: 49162.549 | Train evalMetric: 59.27%\n",
      "\t Round: 66 |Train Loss: 42295.096 | Train evalMetric: 64.87%\n",
      "\t Round: 67 |Train Loss: 41846.508 | Train evalMetric: 65.10%\n",
      "\t Round: 68 |Train Loss: 41556.291 | Train evalMetric: 65.49%\n",
      "\t Round: 69 |Train Loss: 43083.308 | Train evalMetric: 64.23%\n",
      "\t Round: 70 |Train Loss: 41806.768 | Train evalMetric: 65.25%\n",
      "\t Round: 71 |Train Loss: 42073.417 | Train evalMetric: 65.10%\n",
      "\t Round: 72 |Train Loss: 42532.882 | Train evalMetric: 64.65%\n",
      "\t Round: 73 |Train Loss: 45712.987 | Train evalMetric: 62.03%\n",
      "\t Round: 74 |Train Loss: 42965.546 | Train evalMetric: 64.37%\n",
      "\t Round: 75 |Train Loss: 45407.587 | Train evalMetric: 62.01%\n",
      "\t Round: 76 |Train Loss: 42335.995 | Train evalMetric: 64.82%\n",
      "\t Round: 77 |Train Loss: 46545.642 | Train evalMetric: 61.38%\n",
      "\t Round: 78 |Train Loss: 42900.397 | Train evalMetric: 64.38%\n",
      "\t Round: 79 |Train Loss: 42901.983 | Train evalMetric: 64.17%\n",
      "\t Round: 80 |Train Loss: 43604.447 | Train evalMetric: 63.81%\n",
      "\t Round: 81 |Train Loss: 42116.389 | Train evalMetric: 64.94%\n",
      "\t Round: 82 |Train Loss: 42683.898 | Train evalMetric: 64.50%\n",
      "\t Round: 83 |Train Loss: 41958.174 | Train evalMetric: 65.09%\n",
      "\t Round: 84 |Train Loss: 41984.321 | Train evalMetric: 64.95%\n",
      "\t Round: 85 |Train Loss: 41680.425 | Train evalMetric: 65.32%\n",
      "\t Round: 86 |Train Loss: 44351.217 | Train evalMetric: 63.19%\n",
      "\t Round: 87 |Train Loss: 42942.895 | Train evalMetric: 64.35%\n",
      "\t Round: 88 |Train Loss: 44472.488 | Train evalMetric: 63.10%\n",
      "\t Round: 89 |Train Loss: 43317.323 | Train evalMetric: 63.73%\n",
      "\t Round: 90 |Train Loss: 50991.271 | Train evalMetric: 57.68%\n",
      "\t Round: 91 |Train Loss: 42447.504 | Train evalMetric: 64.60%\n",
      "\t Round: 92 |Train Loss: 44055.731 | Train evalMetric: 63.24%\n",
      "\t Round: 93 |Train Loss: 42298.041 | Train evalMetric: 64.79%\n",
      "\t Round: 94 |Train Loss: 42219.702 | Train evalMetric: 64.79%\n",
      "\t Round: 95 |Train Loss: 59885.632 | Train evalMetric: 49.98%\n",
      "\t Round: 96 |Train Loss: 71094.743 | Train evalMetric: 40.55%\n",
      "\t Round: 97 |Train Loss: 75520.773 | Train evalMetric: 36.96%\n",
      "\t Round: 98 |Train Loss: 43897.823 | Train evalMetric: 63.49%\n",
      "\t Round: 99 |Train Loss: 43566.936 | Train evalMetric: 63.55%\n",
      "\t Round: 100 |Train Loss: 64523.782 | Train evalMetric: 46.10%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.8409292867223594, test_acc:0.8607747487001196\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.7372248909125387, test_acc:0.7316491208921391\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.8039732074643285, test_acc:0.758472003915895\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.7519481723303115, test_acc:0.7372473211442789\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.011156662969642501, test_acc:0.01038280924716032\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:0.5415118843512875, test_acc:0.5098318034109742\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.9416969204759522, test_acc:0.9382337030442506\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.5294682881268455, test_acc:0.5630256113790348\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.8375571819361518, test_acc:0.8250791214967965\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7012776944281977, test_acc:0.7254134399393397\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:130654.734375, test_acc:132503.109375, Extrac_acc:262021.921875\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:15732.60546875, test_acc:16637.669921875, Extrac_acc:50413.9375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:149677.671875, test_acc:148738.4375, Extrac_acc:251763.171875\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:173577.78125, test_acc:173637.1875, Extrac_acc:251330.171875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:76859.3359375, test_acc:83290.28125, Extrac_acc:122411.921875\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:98600.8125, test_acc:104675.265625, Extrac_acc:168790.390625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:70852.0859375, test_acc:69821.1015625, Extrac_acc:101245.0390625\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:94388.2890625, test_acc:93609.53125, Extrac_acc:131753.265625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:453005.59375, test_acc:467978.15625, Extrac_acc:547684.0625\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:811169.5, test_acc:840313.5625, Extrac_acc:1675920.25\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:62419.94140625, test_acc:63833.27734375, Extrac_acc:223592.078125\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:28575.822265625, test_acc:31085.6171875, Extrac_acc:109985.046875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:837262.3125, test_acc:865561.8125, Extrac_acc:615913.5\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:850129.3125, test_acc:879370.875, Extrac_acc:788448.75\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:156109.609375, test_acc:157913.453125, Extrac_acc:427589.71875\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:79761.5234375, test_acc:78863.375, Extrac_acc:202151.53125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:173485.28125, test_acc:167166.203125, Extrac_acc:451487.03125\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:157723.609375, test_acc:152172.609375, Extrac_acc:433979.71875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:99265.8046875, test_acc:98771.34375, Extrac_acc:279948.53125\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:66996.2265625, test_acc:66358.1640625, Extrac_acc:212431.03125\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 7872731152384.0 || Test loss: 803965501440.0\n",
      "Epoch: 1000 | | Train Loss: 7870583144448.0 || Test loss: 803809853440.0\n",
      "Client 0 prediction: mean tensor([ 0.0482,  0.0649,  0.0436,  ..., -0.0051, -0.0140, -0.0575],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.6628, 0.3977, 0.5875,  ..., 0.0608, 0.0498, 0.0498],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([  -1.7999, -295.5450,    0.9874,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([125.0552, 423.0344,   2.8930,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[9, 10, 27, 39, 43, 58, 62, 71, 85, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 27932250603520.0 || Test loss: 1965175865344.0\n",
      "Epoch: 1000 | | Train Loss: 27928400232448.0 || Test loss: 1965029588992.0\n",
      "Client 1 prediction: mean tensor([ 0.0496,  0.0786,  0.0154,  ...,  0.0144, -0.0306, -0.0710],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.5264, 0.8786, 0.2670,  ..., 0.0224, 0.2379, 0.0547],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([-106.5234,  -63.7685,  -22.5138,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([174.5553, 770.7484,  27.8014,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 14233107431424.0 || Test loss: 1234130173952.0\n",
      "Epoch: 1000 | | Train Loss: 14230023569408.0 || Test loss: 1234027806720.0\n",
      "Client 2 prediction: mean tensor([ 0.0447,  0.1203,  0.0580,  ..., -0.0021,  0.0092, -0.0718],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.2672, 0.4073, 0.6931,  ..., 0.0292, 0.6315, 0.0887],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([-101.6887,  658.5195,  -18.6456,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([126.6461, 743.3049,  92.6884,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 14, 24, 34, 42, 56, 67, 74, 81, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 13492380762112.0 || Test loss: 2126537162752.0\n",
      "Epoch: 1000 | | Train Loss: 13489350377472.0 || Test loss: 2126238580736.0\n",
      "Client 3 prediction: mean tensor([ 0.0772,  0.0864,  0.0690,  ...,  0.0406, -0.0243, -0.0890],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.6534, 0.4852, 0.5061,  ..., 0.0323, 0.1064, 0.0274],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([ 214.2574, 1303.7144,  115.5587,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([173.3575, 585.8962,  57.7626,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 4:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 253572251910144.0 || Test loss: 44095472926720.0\n",
      "Epoch: 1000 | | Train Loss: 253562454016000.0 || Test loss: 44094965415936.0\n",
      "Client 4 prediction: mean tensor([ 0.0332,  0.0510, -0.0412,  ..., -0.0150,  0.0426, -0.0723],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.3212, 0.4314, 0.2745,  ..., 0.2881, 0.1153, 0.2226],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 4 y: mean tensor([-1081.0223, -1100.6394,  -350.6848,  ...,     0.0000,     0.0000,\n",
      "            0.0000]), std tensor([1565.6318, 2832.8525,  585.7761,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 5:\n",
      "[1, 12, 23, 31, 43, 51, 60, 78, 84, 91]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 6447599452160.0 || Test loss: 511985352704.0\n",
      "Epoch: 1000 | | Train Loss: 6445264797696.0 || Test loss: 511935447040.0\n",
      "Client 5 prediction: mean tensor([-0.0345,  0.0568,  0.0056,  ...,  0.0214, -0.0260, -0.0222],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.8651, 0.4583, 0.8239,  ..., 0.0323, 0.1792, 0.2158],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 5 y: mean tensor([-203.3591, -782.1696,  -44.6387,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([253.7769, 671.0402,  47.0805,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 6:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 185421086588928.0 || Test loss: 28262136807424.0\n",
      "Epoch: 1000 | | Train Loss: 185412630872064.0 || Test loss: 28261941772288.0\n",
      "Client 6 prediction: mean tensor([ 0.3721,  0.4478,  0.0555,  ..., -0.0381,  0.1166, -0.1408],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.1886, 0.3682, 0.8527,  ..., 0.0563, 0.1395, 0.1274],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 6 y: mean tensor([-209.3712,  812.9301,  -20.0075,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([ 287.7053, 1113.2262,   66.1959,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 7:\n",
      "[9, 15, 22, 31, 43, 57, 64, 73, 80, 98]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 11429717475328.0 || Test loss: 1081060425728.0\n",
      "Epoch: 1000 | | Train Loss: 11427068772352.0 || Test loss: 1080907137024.0\n",
      "Client 7 prediction: mean tensor([ 0.1122,  0.0861, -0.0644,  ...,  0.0129, -0.0670, -0.0793],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.5728, 0.2419, 0.8597,  ..., 0.0258, 0.0418, 0.3492],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 7 y: mean tensor([ 66.0595, 362.2982,  -2.7689,  ...,   0.0000,   0.0000,   0.0000]), std tensor([ 65.0058, 398.3195,   9.7416,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 8:\n",
      "[6, 13, 25, 31, 45, 53, 67, 73, 85, 93]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 15056691527680.0 || Test loss: 1210206650368.0\n",
      "Epoch: 1000 | | Train Loss: 15053849886720.0 || Test loss: 1210139017216.0\n",
      "Client 8 prediction: mean tensor([ 0.0091,  0.0419,  0.0398,  ...,  0.0126, -0.0210, -0.0759],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.4299, 0.3645, 0.3066,  ..., 0.0228, 0.0848, 0.1316],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 8 y: mean tensor([ -215.5223, -1364.9468,  -167.3185,  ...,     0.0000,     0.0000,\n",
      "            0.0000]), std tensor([ 355.0938, 1802.3965,  250.2863,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 9:\n",
      "[5, 10, 22, 39, 42, 53, 69, 72, 88, 95]\n",
      "134657 128 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 12666943832064.0 || Test loss: 952669241344.0\n",
      "Epoch: 1000 | | Train Loss: 12663842144256.0 || Test loss: 952588042240.0\n",
      "Client 9 prediction: mean tensor([ 0.4237, -0.0445,  0.1052,  ..., -0.0535, -0.0412, -0.0591],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([0.2930, 0.6061, 0.2799,  ..., 0.0666, 0.1326, 0.1206],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 9 y: mean tensor([ 33.5667, -53.2134,   5.8992,  ...,   0.0000,   0.0000,   0.0000]), std tensor([300.5098, 618.4970,  15.4624,  ...,   0.0000,   0.0000,   0.0000])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:130654.73, Test accuracy:132503.11, Extraction Accuracy:262021.92\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:15732.61, Test accuracy:16637.67, Extraction Accuracy:50413.94\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:0.84, Test accuracy:0.86\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1201652.5000, Training accuracy: 15732.61, Test Accuracy: 16637.67\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 786404.7500, Training accuracy: 11790.39, Test Accuracy: 12764.33\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 64923352.0000, Training accuracy: 299010816.00, Test Accuracy: 290764320.00\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 64923352.0000, Training accuracy: 299010816.00, Test Accuracy: 290764320.00\n",
      "Best: Gradient norm:548102.8125\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:7867744649216.00, Test loss: 803495608320.00,Training accuracy: 299010816.00, Test accuracy: 290764320.00, Extraction accuracy: 295042080.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:149677.67, Test accuracy:148738.44, Extraction Accuracy:251763.17\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:173577.78, Test accuracy:173637.19, Extraction Accuracy:251330.17\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.74, Test accuracy:0.73\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 24845.5781, Training accuracy: 173577.78, Test Accuracy: 173637.19\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 16937.3496, Training accuracy: 169900.50, Test Accuracy: 169816.59\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 11637.6543, Training accuracy: 167079.36, Test Accuracy: 166885.25\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 8085.8540, Training accuracy: 164918.41, Test Accuracy: 164639.50\n",
      "Best: Gradient norm:8085.8540\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:27928400232448.00, Test loss: 1965029588992.00,Training accuracy: 164918.41, Test accuracy: 164639.50, Extraction accuracy: 228358.42\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:76859.34, Test accuracy:83290.28, Extraction Accuracy:122411.92\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:98600.81, Test accuracy:104675.27, Extraction Accuracy:168790.39\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.80, Test accuracy:0.76\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1005646.3750, Training accuracy: 98600.81, Test Accuracy: 104675.27\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 566939.8750, Training accuracy: 64070.75, Test Accuracy: 70929.71\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 787648.6250, Training accuracy: 2847686.50, Test Accuracy: 2809730.75\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 517510.4688, Training accuracy: 10044702.00, Test Accuracy: 9904844.00\n",
      "Best: Gradient norm:382693.0000\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:14228011352064.00, Test loss: 1233748099072.00,Training accuracy: 10044702.00, Test accuracy: 9904844.00, Extraction accuracy: 11682074.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:70852.09, Test accuracy:69821.10, Extraction Accuracy:101245.04\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:94388.29, Test accuracy:93609.53, Extraction Accuracy:131753.27\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.75, Test accuracy:0.74\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 40810.4609, Training accuracy: 94388.29, Test Accuracy: 93609.53\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 28348.6953, Training accuracy: 90991.02, Test Accuracy: 90196.76\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 19751.5176, Training accuracy: 88436.60, Test Accuracy: 87625.85\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 13599.8398, Training accuracy: 86527.41, Test Accuracy: 85700.84\n",
      "Best: Gradient norm:13599.8398\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:13489350377472.00, Test loss: 2126238580736.00,Training accuracy: 86527.41, Test accuracy: 85700.84, Extraction accuracy: 116684.44\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:4, Training accuracy:453005.59, Test accuracy:467978.16, Extraction Accuracy:547684.06\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:4, Training accuracy:811169.50, Test accuracy:840313.56, Extraction Accuracy:1675920.25\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:4, Training accuracy:0.01, Test accuracy:0.01\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 11303555.0000, Training accuracy: 811169.50, Test Accuracy: 840313.56\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 7953445.0000, Training accuracy: 609605.25, Test Accuracy: 633773.94\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 5571433.0000, Training accuracy: 481371.03, Test Accuracy: 501613.00\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 3911706.7500, Training accuracy: 408080.78, Test Accuracy: 425598.53\n",
      "Best: Gradient norm:3911706.7500\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:4, Used Gradient Network Train loss:253554434506752.00, Test loss: 44094038474752.00,Training accuracy: 408080.78, Test accuracy: 425598.53, Extraction accuracy: 788066.81\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:5, Training accuracy:62419.94, Test accuracy:63833.28, Extraction Accuracy:223592.08\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:5, Training accuracy:28575.82, Test accuracy:31085.62, Extraction Accuracy:109985.05\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:5, Training accuracy:0.54, Test accuracy:0.51\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 2815.5095, Training accuracy: 28575.82, Test Accuracy: 31085.62\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 10537.6611, Training accuracy: 29382.71, Test Accuracy: 31900.27\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 7342.8613, Training accuracy: 29167.17, Test Accuracy: 31681.89\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 5141.4785, Training accuracy: 29002.96, Test Accuracy: 31514.80\n",
      "Best: Gradient norm:2815.5095\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:5, Used Gradient Network Train loss:6445264797696.00, Test loss: 511935447040.00,Training accuracy: 29002.96, Test accuracy: 31514.80, Extraction accuracy: 112165.71\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:6, Training accuracy:837262.31, Test accuracy:865561.81, Extraction Accuracy:615913.50\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:6, Training accuracy:850129.31, Test accuracy:879370.88, Extraction Accuracy:788448.75\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:6, Training accuracy:0.94, Test accuracy:0.94\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 168899.3906, Training accuracy: 850129.31, Test Accuracy: 879370.88\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 113756.0781, Training accuracy: 848254.50, Test Accuracy: 877455.75\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 76582.3672, Training accuracy: 839134.56, Test Accuracy: 868201.50\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 51647.7617, Training accuracy: 829570.06, Test Accuracy: 858518.38\n",
      "Best: Gradient norm:51647.7617\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:6, Used Gradient Network Train loss:185412630872064.00, Test loss: 28261941772288.00,Training accuracy: 829570.06, Test accuracy: 858518.38, Extraction accuracy: 735985.62\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:7, Training accuracy:156109.61, Test accuracy:157913.45, Extraction Accuracy:427589.72\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:7, Training accuracy:79761.52, Test accuracy:78863.38, Extraction Accuracy:202151.53\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:7, Training accuracy:0.53, Test accuracy:0.56\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 985556.5000, Training accuracy: 79761.52, Test Accuracy: 78863.38\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 560315.6250, Training accuracy: 268766.97, Test Accuracy: 259077.16\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 398611.9375, Training accuracy: 56876672.00, Test Accuracy: 54652436.00\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 393663.6250, Training accuracy: 59792040.00, Test Accuracy: 57454936.00\n",
      "Best: Gradient norm:393663.6250\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:7, Used Gradient Network Train loss:11425236910080.00, Test loss: 1080647286784.00,Training accuracy: 59792040.00, Test accuracy: 57454936.00, Extraction accuracy: 63335736.00\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:8, Training accuracy:173485.28, Test accuracy:167166.20, Extraction Accuracy:451487.03\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:8, Training accuracy:157723.61, Test accuracy:152172.61, Extraction Accuracy:433979.72\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:8, Training accuracy:0.84, Test accuracy:0.83\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 10860.8125, Training accuracy: 157721.72, Test Accuracy: 152170.95\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 7460.7388, Training accuracy: 153958.44, Test Accuracy: 148900.36\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 5181.7935, Training accuracy: 151248.95, Test Accuracy: 146577.30\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 3654.7258, Training accuracy: 149285.02, Test Accuracy: 144917.30\n",
      "Best: Gradient norm:3654.7258\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:8, Used Gradient Network Train loss:15053849886720.00, Test loss: 1210139017216.00,Training accuracy: 149285.02, Test accuracy: 144917.30, Extraction accuracy: 389717.12\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:9, Training accuracy:99265.80, Test accuracy:98771.34, Extraction Accuracy:279948.53\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:9, Training accuracy:66996.23, Test accuracy:66358.16, Extraction Accuracy:212431.03\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:9, Training accuracy:0.70, Test accuracy:0.73\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 1077741.5000, Training accuracy: 66996.23, Test Accuracy: 66358.16\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 682335.8750, Training accuracy: 43735.08, Test Accuracy: 43408.10\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 431385.3750, Training accuracy: 55666.98, Test Accuracy: 55372.53\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 273774.2812, Training accuracy: 78225.90, Test Accuracy: 77847.32\n",
      "Best: Gradient norm:273774.2812\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:9, Used Gradient Network Train loss:12662631038976.00, Test loss: 952404869120.00,Training accuracy: 78225.90, Test accuracy: 77847.32, Extraction accuracy: 23677.29\n",
      "rm logs/none/experiment_flightPrices_bz_512_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_10_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 512 --num_local_steps 10 --device \"cpu\" --gnetwork_num_epochs 1001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 128 --start_point global_model --decoded_epochs 3001 --model neuralReg --fit_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-21 04:29:57.393 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:7289 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-21 04:29:57.536 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:7289 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\t Round: 1 |Train Loss: 140668.525 | Train evalMetric: -18.02%\n",
      "\t Round: 2 |Train Loss: 173600.174 | Train evalMetric: -46.62%\n",
      "\t Round: 3 |Train Loss: 96323.149 | Train evalMetric: 19.35%\n",
      "\t Round: 4 |Train Loss: 108404.841 | Train evalMetric: 9.10%\n",
      "\t Round: 5 |Train Loss: 78056.159 | Train evalMetric: 34.96%\n",
      "\t Round: 6 |Train Loss: 84102.670 | Train evalMetric: 29.69%\n",
      "\t Round: 7 |Train Loss: 68041.469 | Train evalMetric: 43.38%\n",
      "\t Round: 8 |Train Loss: 48421.318 | Train evalMetric: 59.94%\n",
      "\t Round: 9 |Train Loss: 61675.942 | Train evalMetric: 48.80%\n",
      "\t Round: 10 |Train Loss: 48353.348 | Train evalMetric: 59.90%\n",
      "\t Round: 11 |Train Loss: 53568.891 | Train evalMetric: 55.64%\n",
      "\t Round: 12 |Train Loss: 48282.244 | Train evalMetric: 60.01%\n",
      "\t Round: 13 |Train Loss: 46255.666 | Train evalMetric: 61.66%\n",
      "\t Round: 14 |Train Loss: 45996.886 | Train evalMetric: 61.80%\n",
      "\t Round: 15 |Train Loss: 47775.785 | Train evalMetric: 60.37%\n",
      "\t Round: 16 |Train Loss: 59435.559 | Train evalMetric: 50.72%\n",
      "\t Round: 17 |Train Loss: 68530.575 | Train evalMetric: 42.98%\n",
      "\t Round: 18 |Train Loss: 47884.140 | Train evalMetric: 60.37%\n",
      "\t Round: 19 |Train Loss: 45454.780 | Train evalMetric: 62.21%\n",
      "\t Round: 20 |Train Loss: 54098.468 | Train evalMetric: 55.15%\n",
      "\t Round: 21 |Train Loss: 47193.484 | Train evalMetric: 60.91%\n",
      "\t Round: 22 |Train Loss: 45179.407 | Train evalMetric: 62.66%\n",
      "\t Round: 23 |Train Loss: 54438.441 | Train evalMetric: 54.86%\n",
      "\t Round: 24 |Train Loss: 44475.345 | Train evalMetric: 63.10%\n",
      "\t Round: 25 |Train Loss: 44459.488 | Train evalMetric: 63.13%\n",
      "\t Round: 26 |Train Loss: 44570.509 | Train evalMetric: 63.08%\n",
      "\t Round: 27 |Train Loss: 53275.874 | Train evalMetric: 55.87%\n",
      "\t Round: 28 |Train Loss: 45646.042 | Train evalMetric: 62.13%\n",
      "\t Round: 29 |Train Loss: 48349.738 | Train evalMetric: 59.93%\n",
      "\t Round: 30 |Train Loss: 45763.439 | Train evalMetric: 62.08%\n",
      "\t Round: 31 |Train Loss: 43996.226 | Train evalMetric: 63.59%\n",
      "\t Round: 32 |Train Loss: 43559.666 | Train evalMetric: 63.88%\n",
      "\t Round: 33 |Train Loss: 44267.475 | Train evalMetric: 63.35%\n",
      "\t Round: 34 |Train Loss: 49930.815 | Train evalMetric: 58.61%\n",
      "\t Round: 35 |Train Loss: 49613.762 | Train evalMetric: 58.90%\n",
      "\t Round: 36 |Train Loss: 43364.462 | Train evalMetric: 64.00%\n",
      "\t Round: 37 |Train Loss: 42992.950 | Train evalMetric: 64.31%\n",
      "\t Round: 38 |Train Loss: 45442.109 | Train evalMetric: 62.40%\n",
      "\t Round: 39 |Train Loss: 47303.613 | Train evalMetric: 60.84%\n",
      "\t Round: 40 |Train Loss: 43183.224 | Train evalMetric: 64.13%\n",
      "\t Round: 41 |Train Loss: 44112.079 | Train evalMetric: 63.50%\n",
      "\t Round: 42 |Train Loss: 42276.316 | Train evalMetric: 64.83%\n",
      "\t Round: 43 |Train Loss: 42880.735 | Train evalMetric: 64.44%\n",
      "\t Round: 44 |Train Loss: 45456.673 | Train evalMetric: 62.35%\n",
      "\t Round: 45 |Train Loss: 42425.045 | Train evalMetric: 64.72%\n",
      "\t Round: 46 |Train Loss: 42233.588 | Train evalMetric: 64.83%\n",
      "\t Round: 47 |Train Loss: 43854.416 | Train evalMetric: 63.63%\n",
      "\t Round: 48 |Train Loss: 45047.346 | Train evalMetric: 62.62%\n",
      "\t Round: 49 |Train Loss: 45652.029 | Train evalMetric: 62.21%\n",
      "\t Round: 50 |Train Loss: 43581.466 | Train evalMetric: 63.93%\n",
      "\t Round: 51 |Train Loss: 41961.342 | Train evalMetric: 65.13%\n",
      "\t Round: 52 |Train Loss: 45748.425 | Train evalMetric: 62.16%\n",
      "\t Round: 53 |Train Loss: 42059.340 | Train evalMetric: 64.98%\n",
      "\t Round: 54 |Train Loss: 42840.814 | Train evalMetric: 64.26%\n",
      "\t Round: 55 |Train Loss: 73876.175 | Train evalMetric: 38.33%\n",
      "\t Round: 56 |Train Loss: 42561.783 | Train evalMetric: 64.61%\n",
      "\t Round: 57 |Train Loss: 43357.061 | Train evalMetric: 64.11%\n",
      "\t Round: 58 |Train Loss: 42871.730 | Train evalMetric: 64.42%\n",
      "\t Round: 59 |Train Loss: 42249.222 | Train evalMetric: 64.95%\n",
      "\t Round: 60 |Train Loss: 41734.189 | Train evalMetric: 65.17%\n",
      "\t Round: 61 |Train Loss: 41859.823 | Train evalMetric: 65.13%\n",
      "\t Round: 62 |Train Loss: 41927.181 | Train evalMetric: 65.06%\n",
      "\t Round: 63 |Train Loss: 41941.563 | Train evalMetric: 65.12%\n",
      "\t Round: 64 |Train Loss: 41860.348 | Train evalMetric: 65.35%\n",
      "\t Round: 65 |Train Loss: 41778.809 | Train evalMetric: 65.24%\n",
      "\t Round: 66 |Train Loss: 43626.164 | Train evalMetric: 63.82%\n",
      "\t Round: 67 |Train Loss: 42862.646 | Train evalMetric: 64.54%\n",
      "\t Round: 68 |Train Loss: 41433.321 | Train evalMetric: 65.54%\n",
      "\t Round: 69 |Train Loss: 41500.810 | Train evalMetric: 65.45%\n",
      "\t Round: 70 |Train Loss: 41661.665 | Train evalMetric: 65.54%\n",
      "\t Round: 71 |Train Loss: 41266.163 | Train evalMetric: 65.65%\n",
      "\t Round: 72 |Train Loss: 40867.518 | Train evalMetric: 65.91%\n",
      "\t Round: 73 |Train Loss: 41130.983 | Train evalMetric: 65.86%\n",
      "\t Round: 74 |Train Loss: 41435.292 | Train evalMetric: 65.49%\n",
      "\t Round: 75 |Train Loss: 41336.781 | Train evalMetric: 65.58%\n",
      "\t Round: 76 |Train Loss: 42601.984 | Train evalMetric: 64.36%\n",
      "\t Round: 77 |Train Loss: 41155.734 | Train evalMetric: 65.81%\n",
      "\t Round: 78 |Train Loss: 41559.824 | Train evalMetric: 65.44%\n",
      "\t Round: 79 |Train Loss: 42182.803 | Train evalMetric: 65.03%\n",
      "\t Round: 80 |Train Loss: 45242.991 | Train evalMetric: 62.51%\n",
      "\t Round: 81 |Train Loss: 41030.958 | Train evalMetric: 65.87%\n",
      "\t Round: 82 |Train Loss: 41393.595 | Train evalMetric: 65.63%\n",
      "\t Round: 83 |Train Loss: 41289.079 | Train evalMetric: 65.72%\n",
      "\t Round: 84 |Train Loss: 40962.352 | Train evalMetric: 65.99%\n",
      "\t Round: 85 |Train Loss: 40678.896 | Train evalMetric: 66.16%\n",
      "\t Round: 86 |Train Loss: 40953.794 | Train evalMetric: 65.98%\n",
      "\t Round: 87 |Train Loss: 40760.909 | Train evalMetric: 66.07%\n",
      "\t Round: 88 |Train Loss: 41109.247 | Train evalMetric: 65.83%\n",
      "\t Round: 89 |Train Loss: 40775.797 | Train evalMetric: 66.12%\n",
      "\t Round: 90 |Train Loss: 40839.773 | Train evalMetric: 66.04%\n",
      "\t Round: 91 |Train Loss: 40991.843 | Train evalMetric: 66.02%\n",
      "\t Round: 92 |Train Loss: 42953.179 | Train evalMetric: 64.39%\n",
      "\t Round: 93 |Train Loss: 40932.969 | Train evalMetric: 65.92%\n",
      "\t Round: 94 |Train Loss: 41210.658 | Train evalMetric: 65.80%\n",
      "\t Round: 95 |Train Loss: 41955.456 | Train evalMetric: 65.17%\n",
      "\t Round: 96 |Train Loss: 41305.542 | Train evalMetric: 65.73%\n",
      "\t Round: 97 |Train Loss: 40711.194 | Train evalMetric: 66.04%\n",
      "\t Round: 98 |Train Loss: 40591.362 | Train evalMetric: 66.21%\n",
      "\t Round: 99 |Train Loss: 40907.737 | Train evalMetric: 66.00%\n",
      "\t Round: 100 |Train Loss: 40898.166 | Train evalMetric: 66.02%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.8356190500463379, test_acc:0.8552732270298196\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.7043488967983242, test_acc:0.7072226396492357\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.6783245467066843, test_acc:0.6467496434432307\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:0.7799791881078207, test_acc:0.7856143393069606\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.7615511360262733, test_acc:0.7490572614835276\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:0.5580064928749128, test_acc:0.5319572031448655\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.9378954463543051, test_acc:0.9318513686041069\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.47643177899678946, test_acc:0.5203490504733195\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.7753260577594533, test_acc:0.785537772921563\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7902475360265319, test_acc:0.8174639916973215\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:106020.5703125, test_acc:107284.0703125, Extrac_acc:223035.65625\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:15814.166015625, test_acc:16862.16796875, Extrac_acc:50002.00390625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:144916.9375, test_acc:143795.109375, Extrac_acc:220016.828125\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:169552.6875, test_acc:168884.453125, Extrac_acc:246697.3125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:72003.0234375, test_acc:78524.2109375, Extrac_acc:108663.890625\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:88334.3359375, test_acc:94817.875, Extrac_acc:136997.703125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:69776.8125, test_acc:68438.2890625, Extrac_acc:94680.8984375\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:95105.59375, test_acc:94206.6875, Extrac_acc:122062.5546875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:423917.375, test_acc:438363.96875, Extrac_acc:453537.28125\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:438117.21875, test_acc:452451.6875, Extrac_acc:479647.03125\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:45206.76953125, test_acc:46835.2109375, Extrac_acc:175844.734375\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:29087.5234375, test_acc:31526.84375, Extrac_acc:128580.5390625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:820983.3125, test_acc:848957.625, Extrac_acc:553797.125\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:870345.75, test_acc:900017.4375, Extrac_acc:793434.1875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:125358.515625, test_acc:127378.96875, Extrac_acc:344100.6875\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:76800.4453125, test_acc:76112.171875, Extrac_acc:187414.671875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:165434.265625, test_acc:160891.5, Extrac_acc:404620.5\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:162838.65625, test_acc:156624.6875, Extrac_acc:475368.90625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:74807.3671875, test_acc:74855.65625, Extrac_acc:220324.609375\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:57270.51171875, test_acc:57109.62109375, Extrac_acc:157720.015625\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 7392864501760.0 || Test loss: 842201497600.0\n",
      "Epoch: 1000 | | Train Loss: 7377316216832.0 || Test loss: 840864759808.0\n",
      "Client 0 prediction: mean tensor([-0.3643, -0.9257, -0.4509,  ...,  0.0721, -0.1205,  0.0435],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([4.6680, 5.1555, 1.7446,  ..., 0.0081, 0.0087, 0.0150],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 0 y: mean tensor([  34.0318, -903.5305,   -2.9219,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([311.0161, 790.5327,   9.2910,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 1:\n",
      "[9, 10, 27, 39, 43, 58, 62, 71, 85, 90]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 19156413972480.0 || Test loss: 1186351284224.0\n",
      "Epoch: 1000 | | Train Loss: 19133305454592.0 || Test loss: 1185777582080.0\n",
      "Client 1 prediction: mean tensor([0.1020, 0.1966, 0.3284,  ..., 0.0676, 0.0177, 0.0649],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([4.2987, 4.2217, 4.1816,  ..., 0.0093, 0.0228, 0.0149],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 1 y: mean tensor([ 279.8574, 1138.7170,   87.5401,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([1046.0719, 1815.2806,  189.0550,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 2:\n",
      "[3, 11, 28, 37, 42, 54, 63, 73, 81, 94]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 9284974804992.0 || Test loss: 730481295360.0\n",
      "Epoch: 1000 | | Train Loss: 9265631723520.0 || Test loss: 730210369536.0\n",
      "Client 2 prediction: mean tensor([-0.4502,  0.3744, -0.2649,  ..., -0.0678, -0.0044,  0.0052],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([1.9377, 4.6732, 2.2311,  ..., 0.0083, 0.0284, 0.0109],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 2 y: mean tensor([ -62.1039, 2198.5532,  -17.3541,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([ 123.0715, 1506.9727,   35.3574,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 3:\n",
      "[1, 14, 24, 34, 42, 56, 67, 74, 81, 91]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 8658605309952.0 || Test loss: 1304226824192.0\n",
      "Epoch: 1000 | | Train Loss: 8644545478656.0 || Test loss: 1302555262976.0\n",
      "Client 3 prediction: mean tensor([ 0.3256,  0.4869,  0.3074,  ..., -0.0599, -0.0311, -0.0770],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([3.2028, 3.7166, 3.7246,  ..., 0.0115, 0.0057, 0.0099],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 3 y: mean tensor([ 311.3155, 2016.8955,  138.9124,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([ 285.1994, 1235.6599,   93.4359,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 4:\n",
      "[1, 15, 21, 33, 46, 59, 66, 78, 80, 96]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 48743927775232.0 || Test loss: 6835054051328.0\n",
      "Epoch: 1000 | | Train Loss: 48711614857216.0 || Test loss: 6830684110848.0\n",
      "Client 4 prediction: mean tensor([-1.6093, -1.4417, -1.2575,  ...,  0.0434,  0.3038, -0.0503],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([5.3346, 4.7246, 4.1006,  ..., 0.0365, 0.0125, 0.0420],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 4 y: mean tensor([-4891.4956, -5820.6807, -1901.6672,  ...,     0.0000,     0.0000,\n",
      "            0.0000]), std tensor([3285.7585, 4284.7319, 1335.1527,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 5:\n",
      "[1, 12, 23, 31, 43, 51, 60, 78, 84, 91]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 3821814677504.0 || Test loss: 353963638784.0\n",
      "Epoch: 1000 | | Train Loss: 3806855168000.0 || Test loss: 353180352512.0\n",
      "Client 5 prediction: mean tensor([ 0.0539, -0.0576,  0.1955,  ..., -0.1095,  0.1480, -0.0721],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([2.6370, 2.9032, 1.7351,  ..., 0.0090, 0.0229, 0.0053],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 5 y: mean tensor([516.4478,  86.1471,  45.2431,  ...,   0.0000,   0.0000,   0.0000]), std tensor([677.2204, 570.2331,  81.4127,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 6:\n",
      "[1, 12, 24, 32, 42, 55, 66, 76, 89, 90]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 81537227816960.0 || Test loss: 12190468800512.0\n",
      "Epoch: 1000 | | Train Loss: 81500636708864.0 || Test loss: 12185405227008.0\n",
      "Client 6 prediction: mean tensor([ 0.7195,  0.5697,  0.0264,  ..., -0.3250,  0.5973,  0.0776],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([7.0476, 4.9821, 5.6613,  ..., 0.0973, 0.0813, 0.0954],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 6 y: mean tensor([ 190.5375, 2249.5603,  157.4268,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([ 489.8146, 1610.5229,  222.8304,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 7:\n",
      "[9, 15, 22, 31, 43, 57, 64, 73, 80, 98]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 6996989313024.0 || Test loss: 707306192896.0\n",
      "Epoch: 1000 | | Train Loss: 6980346314752.0 || Test loss: 706332852224.0\n",
      "Client 7 prediction: mean tensor([ 0.6901,  1.0395,  0.9440,  ..., -0.0070,  0.1295, -0.0675],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([3.8978, 4.0073, 3.8919,  ..., 0.0160, 0.0251, 0.0213],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 7 y: mean tensor([ 316.4859, 1404.3784,   42.9742,  ...,    0.0000,    0.0000,\n",
      "           0.0000]), std tensor([202.6521, 923.6703,  29.8855,  ...,   0.0000,   0.0000,   0.0000])\n",
      "Starting getting gradient network of Worker 8:\n",
      "[6, 13, 25, 31, 45, 53, 67, 73, 85, 93]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 9548043649024.0 || Test loss: 730509410304.0\n",
      "Epoch: 1000 | | Train Loss: 9529537331200.0 || Test loss: 730180288512.0\n",
      "Client 8 prediction: mean tensor([-1.0035, -0.7618, -0.7449,  ...,  0.1642, -0.1163, -0.0098],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([4.8595, 5.2172, 3.6665,  ..., 0.0235, 0.0337, 0.0299],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 8 y: mean tensor([ -497.6635, -3693.0234,  -549.5740,  ...,     0.0000,     0.0000,\n",
      "            0.0000]), std tensor([ 653.7133, 2347.0154,  353.4805,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "Starting getting gradient network of Worker 9:\n",
      "[5, 10, 22, 39, 42, 53, 69, 72, 88, 95]\n",
      "134657 150 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 7437212450816.0 || Test loss: 532195311616.0\n",
      "Epoch: 1000 | | Train Loss: 7418722385920.0 || Test loss: 531750354944.0\n",
      "Client 9 prediction: mean tensor([-1.0116, -0.9703, -0.7860,  ...,  0.0308,  0.0041, -0.0035],\n",
      "       grad_fn=<StdMeanBackward0>), std tensor([4.4448, 4.8419, 3.1142,  ..., 0.0057, 0.0097, 0.0066],\n",
      "       grad_fn=<StdMeanBackward0>)\n",
      "Client 9 y: mean tensor([ -149.7852, -1783.9409,   -19.3660,  ...,     0.0000,     0.0000,\n",
      "            0.0000]), std tensor([ 428.0779, 1068.7631,   19.6230,  ...,    0.0000,    0.0000,\n",
      "           0.0000])\n",
      "----------- Phase II: decoding the local optimum for workers --------------------\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:0, Training accuracy:106020.57, Test accuracy:107284.07, Extraction Accuracy:223035.66\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:0, Training accuracy:15814.17, Test accuracy:16862.17, Extraction Accuracy:50002.00\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:0, Training accuracy:0.84, Test accuracy:0.86\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 6087503.0000, Training accuracy: 15818.48, Test Accuracy: 16866.32\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 829567.0000, Training accuracy: 20287.82, Test Accuracy: 21238.18\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 117955.9844, Training accuracy: 23281.78, Test Accuracy: 24199.67\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 21649.2812, Training accuracy: 24784.73, Test Accuracy: 25692.69\n",
      "Best: Gradient norm:21649.2812\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:0, Used Gradient Network Train loss:7377208213504.00, Test loss: 840850800640.00,Training accuracy: 24784.73, Test accuracy: 25692.69, Extraction accuracy: 80213.52\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:1, Training accuracy:144916.94, Test accuracy:143795.11, Extraction Accuracy:220016.83\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:1, Training accuracy:169552.69, Test accuracy:168884.45, Extraction Accuracy:246697.31\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:1, Training accuracy:0.70, Test accuracy:0.71\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 959792.2500, Training accuracy: 169544.72, Test Accuracy: 168876.20\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 142039.5312, Training accuracy: 162557.69, Test Accuracy: 161713.78\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 31231.3633, Training accuracy: 160423.30, Test Accuracy: 159546.14\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 16226.2070, Training accuracy: 160047.48, Test Accuracy: 159178.72\n",
      "Best: Gradient norm:16226.2070\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:1, Used Gradient Network Train loss:19133305454592.00, Test loss: 1185777582080.00,Training accuracy: 160047.48, Test accuracy: 159178.72, Extraction accuracy: 224929.59\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:2, Training accuracy:72003.02, Test accuracy:78524.21, Extraction Accuracy:108663.89\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:2, Training accuracy:88334.34, Test accuracy:94817.88, Extraction Accuracy:136997.70\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:2, Training accuracy:0.68, Test accuracy:0.65\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 240003.1094, Training accuracy: 88332.00, Test Accuracy: 94815.59\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 38506.4609, Training accuracy: 88072.17, Test Accuracy: 94550.08\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 11172.7480, Training accuracy: 88434.03, Test Accuracy: 94897.85\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 7467.5386, Training accuracy: 88785.99, Test Accuracy: 95237.95\n",
      "Best: Gradient norm:7467.5386\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:2, Used Gradient Network Train loss:9265631723520.00, Test loss: 730210369536.00,Training accuracy: 88785.99, Test accuracy: 95237.95, Extraction accuracy: 141179.12\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:3, Training accuracy:69776.81, Test accuracy:68438.29, Extraction Accuracy:94680.90\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:3, Training accuracy:95105.59, Test accuracy:94206.69, Extraction Accuracy:122062.55\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:3, Training accuracy:0.78, Test accuracy:0.79\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 956460.0000, Training accuracy: 95096.12, Test Accuracy: 94197.23\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 142581.1875, Training accuracy: 90031.25, Test Accuracy: 89221.22\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 32133.9590, Training accuracy: 88845.11, Test Accuracy: 88061.34\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 17185.5312, Training accuracy: 88487.36, Test Accuracy: 87713.15\n",
      "Best: Gradient norm:17185.5312\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:3, Used Gradient Network Train loss:8644545478656.00, Test loss: 1302555262976.00,Training accuracy: 88487.36, Test accuracy: 87713.15, Extraction accuracy: 98582.24\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:4, Training accuracy:423917.38, Test accuracy:438363.97, Extraction Accuracy:453537.28\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:4, Training accuracy:438117.22, Test accuracy:452451.69, Extraction Accuracy:479647.03\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:4, Training accuracy:0.76, Test accuracy:0.75\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 5446512.0000, Training accuracy: 438114.09, Test Accuracy: 452448.47\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 748051.3125, Training accuracy: 436324.09, Test Accuracy: 450533.78\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 111491.4844, Training accuracy: 436470.38, Test Accuracy: 450597.88\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 25279.0449, Training accuracy: 436831.44, Test Accuracy: 450920.62\n",
      "Best: Gradient norm:25279.0449\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:4, Used Gradient Network Train loss:48711489028096.00, Test loss: 6830664712192.00,Training accuracy: 436831.44, Test accuracy: 450920.62, Extraction accuracy: 494528.78\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:5, Training accuracy:45206.77, Test accuracy:46835.21, Extraction Accuracy:175844.73\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:5, Training accuracy:29087.52, Test accuracy:31526.84, Extraction Accuracy:128580.54\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:5, Training accuracy:0.56, Test accuracy:0.53\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 486486.9688, Training accuracy: 29089.27, Test Accuracy: 31528.55\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 71579.7656, Training accuracy: 28882.92, Test Accuracy: 31347.18\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 15372.3877, Training accuracy: 28651.05, Test Accuracy: 31127.55\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 7758.8135, Training accuracy: 28571.12, Test Accuracy: 31057.30\n",
      "Best: Gradient norm:7758.8135\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:5, Used Gradient Network Train loss:3806855168000.00, Test loss: 353180352512.00,Training accuracy: 28571.12, Test accuracy: 31057.30, Extraction accuracy: 118790.45\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:6, Training accuracy:820983.31, Test accuracy:848957.62, Extraction Accuracy:553797.12\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:6, Training accuracy:870345.75, Test accuracy:900017.44, Extraction Accuracy:793434.19\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:6, Training accuracy:0.94, Test accuracy:0.93\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 3531625.5000, Training accuracy: 870345.69, Test Accuracy: 900017.31\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 489812.5625, Training accuracy: 869274.06, Test Accuracy: 898915.62\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 74560.1094, Training accuracy: 868564.50, Test Accuracy: 898185.38\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 17945.0547, Training accuracy: 868116.88, Test Accuracy: 897726.56\n",
      "Best: Gradient norm:17945.0547\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:6, Used Gradient Network Train loss:81500636708864.00, Test loss: 12185405227008.00,Training accuracy: 868116.88, Test accuracy: 897726.56, Extraction accuracy: 786827.75\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:7, Training accuracy:125358.52, Test accuracy:127378.97, Extraction Accuracy:344100.69\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:7, Training accuracy:76800.45, Test accuracy:76112.17, Extraction Accuracy:187414.67\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:7, Training accuracy:0.48, Test accuracy:0.52\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 966908.9375, Training accuracy: 76803.37, Test Accuracy: 76115.30\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 136938.6719, Training accuracy: 77672.30, Test Accuracy: 77031.91\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 24567.8125, Training accuracy: 77792.49, Test Accuracy: 77154.67\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 9352.9004, Training accuracy: 77713.21, Test Accuracy: 77064.02\n",
      "Best: Gradient norm:9352.9004\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:7, Used Gradient Network Train loss:6980346314752.00, Test loss: 706332852224.00,Training accuracy: 77713.21, Test accuracy: 77064.02, Extraction accuracy: 184908.38\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:8, Training accuracy:165434.27, Test accuracy:160891.50, Extraction Accuracy:404620.50\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:8, Training accuracy:162838.66, Test accuracy:156624.69, Extraction Accuracy:475368.91\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:8, Training accuracy:0.78, Test accuracy:0.79\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 184654.0000, Training accuracy: 162837.59, Test Accuracy: 156623.75\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 31802.9219, Training accuracy: 161522.86, Test Accuracy: 155385.17\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 10987.8018, Training accuracy: 160117.42, Test Accuracy: 154078.70\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 8144.2686, Training accuracy: 159107.17, Test Accuracy: 153135.30\n",
      "Best: Gradient norm:8144.2686\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:8, Used Gradient Network Train loss:9529510068224.00, Test loss: 730175242240.00,Training accuracy: 159107.17, Test accuracy: 153135.30, Extraction accuracy: 468637.09\n",
      "\n",
      "\n",
      "------------------- Server model Performance ---------------------\n",
      "Worker:9, Training accuracy:74807.37, Test accuracy:74855.66, Extraction Accuracy:220324.61\n",
      "------------------- Server local model Performance ---------------------\n",
      "Worker:9, Training accuracy:57270.51, Test accuracy:57109.62, Extraction Accuracy:157720.02\n",
      "------------------- Optimum model Performance ---------------------\n",
      "Worker:9, Training accuracy:0.79, Test accuracy:0.82\n",
      "------------------- Decoding procedure starts --------------------\n",
      "torch.Size([1, 134657])\n",
      "MSELoss()\n",
      "Epoch:1, Gradient norm: 12255.8184, Training accuracy: 57270.62, Test Accuracy: 57109.73\n",
      "MSELoss()\n",
      "Epoch:1001, Gradient norm: 10250.7207, Training accuracy: 56037.57, Test Accuracy: 55865.81\n",
      "MSELoss()\n",
      "Epoch:2001, Gradient norm: 9969.7305, Training accuracy: 55452.73, Test Accuracy: 55268.39\n",
      "MSELoss()\n",
      "Epoch:3001, Gradient norm: 9944.6602, Training accuracy: 55353.32, Test Accuracy: 55165.47\n",
      "Best: Gradient norm:9944.6602\n",
      "MSELoss()\n",
      "------------------- Decoded optimum Performance ---------------------\n",
      "Worker:9, Used Gradient Network Train loss:7418722385920.00, Test loss: 531750354944.00,Training accuracy: 55353.32, Test accuracy: 55165.47, Extraction accuracy: 142469.66\n",
      "rm logs/none/experiment_flightPrices_bz_511_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_True_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0/inter*.json\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 511 --num_local_steps 5 --device \"cpu\" --gnetwork_num_epochs 1001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00005 --sigma 0.1 --gnetwork_features 150 --start_point global_model --decoded_epochs 3001 --model neuralReg --fit_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "0 8065\n",
      "8\n",
      "1 47741\n",
      "8\n",
      "2 31869\n",
      "8\n",
      "3 26693\n",
      "8\n",
      "4 22558\n",
      "8\n",
      "5 21761\n",
      "8\n",
      "6 11354\n",
      "8\n",
      "7 11137\n",
      "8\n",
      "8 10625\n",
      "8\n",
      "9 52740\n",
      "[2023-05-21 09:59:29.288 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:13603 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2023-05-21 09:59:29.423 pytorch-1-12-gpu-p-ml-g4dn-4xlarge-43ab4e683924fe944301b0b2327d:13603 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "/root/privacy-preserving-fl/break_model_privacy_in_fl_PhD/federated_learning/model/neural_network_regression.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=self.device)\n",
      "\t Round: 1 |Train Loss: 293892.694 | Train evalMetric: -177.82%\n",
      "\t Round: 2 |Train Loss: 293328.506 | Train evalMetric: -177.47%\n",
      "\t Round: 3 |Train Loss: 292311.934 | Train evalMetric: -175.54%\n",
      "\t Round: 4 |Train Loss: 290008.913 | Train evalMetric: -173.16%\n",
      "\t Round: 5 |Train Loss: 283345.552 | Train evalMetric: -167.24%\n",
      "\t Round: 6 |Train Loss: 253115.589 | Train evalMetric: -134.62%\n",
      "\t Round: 7 |Train Loss: 156480.283 | Train evalMetric: -37.28%\n",
      "\t Round: 8 |Train Loss: 147398.947 | Train evalMetric: -31.91%\n",
      "\t Round: 9 |Train Loss: 145410.723 | Train evalMetric: -29.16%\n",
      "\t Round: 10 |Train Loss: 143552.329 | Train evalMetric: -26.83%\n",
      "\t Round: 11 |Train Loss: 142138.181 | Train evalMetric: -24.75%\n",
      "\t Round: 12 |Train Loss: 143462.758 | Train evalMetric: -25.12%\n",
      "\t Round: 13 |Train Loss: 137419.232 | Train evalMetric: -21.33%\n",
      "\t Round: 14 |Train Loss: 136823.779 | Train evalMetric: -19.03%\n",
      "\t Round: 15 |Train Loss: 132124.381 | Train evalMetric: -14.68%\n",
      "\t Round: 16 |Train Loss: 127700.748 | Train evalMetric: -11.66%\n",
      "\t Round: 17 |Train Loss: 124074.847 | Train evalMetric: -6.93%\n",
      "\t Round: 18 |Train Loss: 129547.639 | Train evalMetric: -10.52%\n",
      "\t Round: 19 |Train Loss: 113304.455 | Train evalMetric: 3.30%\n",
      "\t Round: 20 |Train Loss: 108816.492 | Train evalMetric: 8.54%\n",
      "\t Round: 21 |Train Loss: 165698.338 | Train evalMetric: -46.23%\n",
      "\t Round: 22 |Train Loss: 142271.283 | Train evalMetric: -22.89%\n",
      "\t Round: 23 |Train Loss: 110708.426 | Train evalMetric: 7.71%\n",
      "\t Round: 24 |Train Loss: 129387.387 | Train evalMetric: -10.36%\n",
      "\t Round: 25 |Train Loss: 234428.323 | Train evalMetric: -117.12%\n",
      "\t Round: 26 |Train Loss: 94823.772 | Train evalMetric: 20.24%\n",
      "\t Round: 27 |Train Loss: 135746.863 | Train evalMetric: -16.92%\n",
      "\t Round: 28 |Train Loss: 147737.474 | Train evalMetric: -29.06%\n",
      "\t Round: 29 |Train Loss: 88270.530 | Train evalMetric: 28.09%\n",
      "\t Round: 30 |Train Loss: 83967.132 | Train evalMetric: 28.42%\n",
      "\t Round: 31 |Train Loss: 106376.642 | Train evalMetric: 11.35%\n",
      "\t Round: 32 |Train Loss: 117190.443 | Train evalMetric: 0.71%\n",
      "\t Round: 33 |Train Loss: 149200.511 | Train evalMetric: -31.00%\n",
      "\t Round: 34 |Train Loss: 151722.562 | Train evalMetric: -33.63%\n",
      "\t Round: 35 |Train Loss: 160322.900 | Train evalMetric: -42.62%\n",
      "\t Round: 36 |Train Loss: 83797.876 | Train evalMetric: 31.96%\n",
      "\t Round: 37 |Train Loss: 92072.453 | Train evalMetric: 24.69%\n",
      "\t Round: 38 |Train Loss: 92170.858 | Train evalMetric: 24.53%\n",
      "\t Round: 39 |Train Loss: 101265.391 | Train evalMetric: 16.02%\n",
      "\t Round: 40 |Train Loss: 73808.442 | Train evalMetric: 39.96%\n",
      "\t Round: 41 |Train Loss: 155188.054 | Train evalMetric: -37.84%\n",
      "\t Round: 42 |Train Loss: 127926.225 | Train evalMetric: -10.21%\n",
      "\t Round: 43 |Train Loss: 138052.681 | Train evalMetric: -20.28%\n",
      "\t Round: 44 |Train Loss: 78353.688 | Train evalMetric: 36.58%\n",
      "\t Round: 45 |Train Loss: 88737.732 | Train evalMetric: 27.44%\n",
      "\t Round: 46 |Train Loss: 82054.103 | Train evalMetric: 33.36%\n",
      "\t Round: 47 |Train Loss: 97796.576 | Train evalMetric: 18.80%\n",
      "\t Round: 48 |Train Loss: 104943.134 | Train evalMetric: 12.23%\n",
      "\t Round: 49 |Train Loss: 125985.873 | Train evalMetric: -8.88%\n",
      "\t Round: 50 |Train Loss: 83189.668 | Train evalMetric: 32.53%\n",
      "\t Round: 51 |Train Loss: 133830.778 | Train evalMetric: -16.78%\n",
      "\t Round: 52 |Train Loss: 77907.158 | Train evalMetric: 37.15%\n",
      "\t Round: 53 |Train Loss: 128493.314 | Train evalMetric: -11.33%\n",
      "\t Round: 54 |Train Loss: 98500.939 | Train evalMetric: 18.11%\n",
      "\t Round: 55 |Train Loss: 136176.591 | Train evalMetric: -19.30%\n",
      "\t Round: 56 |Train Loss: 75825.729 | Train evalMetric: 39.01%\n",
      "\t Round: 57 |Train Loss: 154985.383 | Train evalMetric: -38.29%\n",
      "\t Round: 58 |Train Loss: 70165.380 | Train evalMetric: 42.41%\n",
      "\t Round: 59 |Train Loss: 70049.239 | Train evalMetric: 43.26%\n",
      "\t Round: 60 |Train Loss: 69091.427 | Train evalMetric: 41.29%\n",
      "\t Round: 61 |Train Loss: 117716.137 | Train evalMetric: -1.36%\n",
      "\t Round: 62 |Train Loss: 107346.042 | Train evalMetric: 9.06%\n",
      "\t Round: 63 |Train Loss: 68125.308 | Train evalMetric: 44.54%\n",
      "\t Round: 64 |Train Loss: 94397.144 | Train evalMetric: 21.11%\n",
      "\t Round: 65 |Train Loss: 88968.654 | Train evalMetric: 26.56%\n",
      "\t Round: 66 |Train Loss: 107147.890 | Train evalMetric: 8.88%\n",
      "\t Round: 67 |Train Loss: 81539.570 | Train evalMetric: 33.60%\n",
      "\t Round: 68 |Train Loss: 174070.390 | Train evalMetric: -58.10%\n",
      "\t Round: 69 |Train Loss: 98635.934 | Train evalMetric: 17.73%\n",
      "\t Round: 70 |Train Loss: 82864.552 | Train evalMetric: 32.37%\n",
      "\t Round: 71 |Train Loss: 66097.215 | Train evalMetric: 44.47%\n",
      "\t Round: 72 |Train Loss: 135996.537 | Train evalMetric: -19.69%\n",
      "\t Round: 73 |Train Loss: 66490.348 | Train evalMetric: 44.02%\n",
      "\t Round: 74 |Train Loss: 95379.865 | Train evalMetric: 20.11%\n",
      "\t Round: 75 |Train Loss: 63940.093 | Train evalMetric: 47.15%\n",
      "\t Round: 76 |Train Loss: 110664.348 | Train evalMetric: 5.38%\n",
      "\t Round: 77 |Train Loss: 66307.061 | Train evalMetric: 46.72%\n",
      "\t Round: 78 |Train Loss: 63463.175 | Train evalMetric: 48.54%\n",
      "\t Round: 79 |Train Loss: 137363.010 | Train evalMetric: -21.65%\n",
      "\t Round: 80 |Train Loss: 127479.749 | Train evalMetric: -11.39%\n",
      "\t Round: 81 |Train Loss: 83925.705 | Train evalMetric: 31.35%\n",
      "\t Round: 82 |Train Loss: 70270.507 | Train evalMetric: 43.44%\n",
      "\t Round: 83 |Train Loss: 73122.800 | Train evalMetric: 40.93%\n",
      "\t Round: 84 |Train Loss: 68788.192 | Train evalMetric: 44.75%\n",
      "\t Round: 85 |Train Loss: 62437.982 | Train evalMetric: 48.33%\n",
      "\t Round: 86 |Train Loss: 180043.799 | Train evalMetric: -64.95%\n",
      "\t Round: 87 |Train Loss: 75919.659 | Train evalMetric: 38.79%\n",
      "\t Round: 88 |Train Loss: 62649.646 | Train evalMetric: 48.88%\n",
      "\t Round: 89 |Train Loss: 76251.657 | Train evalMetric: 37.88%\n",
      "\t Round: 90 |Train Loss: 134255.286 | Train evalMetric: -18.91%\n",
      "\t Round: 91 |Train Loss: 63612.974 | Train evalMetric: 48.36%\n",
      "\t Round: 92 |Train Loss: 89283.217 | Train evalMetric: 25.71%\n",
      "\t Round: 93 |Train Loss: 63593.176 | Train evalMetric: 48.77%\n",
      "\t Round: 94 |Train Loss: 62719.222 | Train evalMetric: 49.45%\n",
      "\t Round: 95 |Train Loss: 131203.716 | Train evalMetric: -15.66%\n",
      "\t Round: 96 |Train Loss: 75521.854 | Train evalMetric: 38.79%\n",
      "\t Round: 97 |Train Loss: 134566.339 | Train evalMetric: -18.74%\n",
      "\t Round: 98 |Train Loss: 67321.470 | Train evalMetric: 46.05%\n",
      "\t Round: 99 |Train Loss: 103133.785 | Train evalMetric: 12.11%\n",
      "\t Round: 100 |Train Loss: 63977.379 | Train evalMetric: 48.66%\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "Finish writing to logs/none/experiment_flightPrices_bz_61_lr_5e-06_lr_scheduler_constant_optimizer_sgd_fit_by_epoch_False_num_local_steps_5_precentage_attack_0.1_DP_False_epsilon_1.0\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:0, train_acc:0.7131616873543084, test_acc:0.7012001819568069\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:1, train_acc:0.3892907043428346, test_acc:0.38406008878594633\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:2, train_acc:0.5592002639596495, test_acc:0.5405191065934511\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:3, train_acc:-0.31199888919688057, test_acc:-0.3021334527677085\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:4, train_acc:0.44642624783752677, test_acc:0.4370556614243941\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:5, train_acc:0.2892879592211532, test_acc:0.28817677160153415\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:6, train_acc:0.568962474282577, test_acc:0.557991198664044\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:7, train_acc:0.07562385692281313, test_acc:0.11940441902889382\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:8, train_acc:0.6917100694992963, test_acc:0.6946624299411951\n",
      "8\n",
      "8\n",
      "8\n",
      "optimum worker:9, train_acc:0.7327958135644188, test_acc:0.7384165603946529\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([8065])) that is different to the input size (torch.Size([8065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([897])) that is different to the input size (torch.Size([897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:0, train_acc:28500.3828125, test_acc:29583.625, Extrac_acc:76915.6015625\n",
      "MSELoss()\n",
      "--server local model worker:0, train_acc:21897.267578125, test_acc:23044.1328125, Extrac_acc:56037.875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([47741])) that is different to the input size (torch.Size([47741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5305])) that is different to the input size (torch.Size([5305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:1, train_acc:155272.515625, test_acc:154491.921875, Extrac_acc:77673.640625\n",
      "MSELoss()\n",
      "--server local model worker:1, train_acc:124905.984375, test_acc:122987.8046875, Extrac_acc:250390.921875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([31869])) that is different to the input size (torch.Size([31869, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3541])) that is different to the input size (torch.Size([3541, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:2, train_acc:76026.7734375, test_acc:83025.578125, Extrac_acc:43452.7578125\n",
      "MSELoss()\n",
      "--server local model worker:2, train_acc:65008.85546875, test_acc:71329.6015625, Extrac_acc:123108.3359375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([26693])) that is different to the input size (torch.Size([26693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2966])) that is different to the input size (torch.Size([2966, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:3, train_acc:66541.75, test_acc:65420.5390625, Extrac_acc:37916.953125\n",
      "MSELoss()\n",
      "--server local model worker:3, train_acc:60527.1484375, test_acc:59432.15625, Extrac_acc:92822.9296875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([22558])) that is different to the input size (torch.Size([22558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2507])) that is different to the input size (torch.Size([2507, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:4, train_acc:437367.96875, test_acc:456868.09375, Extrac_acc:117862.1015625\n",
      "MSELoss()\n",
      "--server local model worker:4, train_acc:360730.28125, test_acc:374356.53125, Extrac_acc:432925.625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([21761])) that is different to the input size (torch.Size([21761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2418])) that is different to the input size (torch.Size([2418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:5, train_acc:36236.34375, test_acc:38080.640625, Extrac_acc:62082.26953125\n",
      "MSELoss()\n",
      "--server local model worker:5, train_acc:25673.55078125, test_acc:27687.08984375, Extrac_acc:109065.484375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11354])) that is different to the input size (torch.Size([11354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1262])) that is different to the input size (torch.Size([1262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:6, train_acc:886033.9375, test_acc:924845.8125, Extrac_acc:132701.203125\n",
      "MSELoss()\n",
      "--server local model worker:6, train_acc:742673.1875, test_acc:773450.3125, Extrac_acc:303988.65625\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([11137])) that is different to the input size (torch.Size([11137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1238])) that is different to the input size (torch.Size([1238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:7, train_acc:83276.2265625, test_acc:81930.5078125, Extrac_acc:103771.1953125\n",
      "MSELoss()\n",
      "--server local model worker:7, train_acc:72449.09375, test_acc:72931.109375, Extrac_acc:206028.859375\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10625])) that is different to the input size (torch.Size([10625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1181])) that is different to the input size (torch.Size([1181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:8, train_acc:200924.59375, test_acc:203657.796875, Extrac_acc:130468.28125\n",
      "MSELoss()\n",
      "--server local model worker:8, train_acc:135680.984375, test_acc:131419.609375, Extrac_acc:506945.46875\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([52740])) that is different to the input size (torch.Size([52740, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "MSELoss()\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([5861])) that is different to the input size (torch.Size([5861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "server worker:9, train_acc:58807.67578125, test_acc:58657.109375, Extrac_acc:83898.9609375\n",
      "MSELoss()\n",
      "--server local model worker:9, train_acc:49482.7421875, test_acc:49534.8984375, Extrac_acc:151065.890625\n",
      "----------- Phase I: simulates the gradient networks for workers --------------------\n",
      "Starting getting gradient network of Worker 0:\n",
      "[3, 19, 26, 37, 43, 51, 65, 78, 82, 96]\n",
      "134657 258 torch.Size([90, 134657]) torch.Size([90, 134657]) torch.Size([10, 134657]) torch.Size([10, 134657])\n",
      "Epoch: 0 | | Train Loss: 1008416980992.0 || Test loss: 119757996032.0\n"
     ]
    }
   ],
   "source": [
    "!python main.py flightPrices --num_workers 10 --num_rounds 100 --bz 61 --num_local_steps 5 --device \"cpu\" --gnetwork_num_epochs 1001 --num_trials_to_decode 1 --lr 0.000005 --adv_lr 0.00001 --sigma 0.1 --gnetwork_features 258 --start_point global_model --decoded_epochs 3001 --model neuralReg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
